AVIARY DIM [-1 -1  0  1  1  1]
Attempting to open: C:\Files\Egyetem\Szakdolgozat\RL\Sol/resources
[INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:
[INFO] m 0.027000, L 0.039700,
[INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,
[INFO] kf 0.000000, km 0.000000,
[INFO] t2w 2.250000, max_speed_kmh 30.000000,
[INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,
[INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,
[INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000
Using cuda device
Logging to ./logs/ppo_tensorboard/PPO_107
Eval num_timesteps=1992, episode_reward=-250.32 +/- 25.10
Episode length: 222.60 +/- 61.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 223      |
|    mean_reward     | -250     |
| time/              |          |
|    total_timesteps | 1992     |
---------------------------------
New best mean reward!
Eval num_timesteps=3984, episode_reward=-255.84 +/- 22.41
Episode length: 261.80 +/- 89.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 262      |
|    mean_reward     | -256     |
| time/              |          |
|    total_timesteps | 3984     |
---------------------------------
Eval num_timesteps=5976, episode_reward=-241.27 +/- 36.35
Episode length: 231.00 +/- 53.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -241     |
| time/              |          |
|    total_timesteps | 5976     |
---------------------------------
New best mean reward!
Eval num_timesteps=7968, episode_reward=-259.25 +/- 12.45
Episode length: 209.20 +/- 56.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 209      |
|    mean_reward     | -259     |
| time/              |          |
|    total_timesteps | 7968     |
---------------------------------
Eval num_timesteps=9960, episode_reward=-276.26 +/- 18.18
Episode length: 223.60 +/- 56.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 224      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 9960     |
---------------------------------
Eval num_timesteps=11952, episode_reward=-279.14 +/- 14.04
Episode length: 248.80 +/- 54.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 249      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 11952    |
---------------------------------
Eval num_timesteps=13944, episode_reward=-284.63 +/- 4.89
Episode length: 254.20 +/- 64.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 254      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 13944    |
---------------------------------
Eval num_timesteps=15936, episode_reward=-270.62 +/- 14.60
Episode length: 231.60 +/- 53.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 15936    |
---------------------------------
Eval num_timesteps=17928, episode_reward=-283.29 +/- 17.05
Episode length: 195.00 +/- 33.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 195      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 17928    |
---------------------------------
Eval num_timesteps=19920, episode_reward=-274.42 +/- 10.04
Episode length: 255.40 +/- 71.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 255      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 19920    |
---------------------------------
Eval num_timesteps=21912, episode_reward=-282.21 +/- 7.65
Episode length: 172.00 +/- 20.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 172      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 21912    |
---------------------------------
Eval num_timesteps=23904, episode_reward=-259.37 +/- 33.16
Episode length: 256.40 +/- 32.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 256      |
|    mean_reward     | -259     |
| time/              |          |
|    total_timesteps | 23904    |
---------------------------------
Eval num_timesteps=25896, episode_reward=-270.01 +/- 16.19
Episode length: 233.00 +/- 46.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 25896    |
---------------------------------
Eval num_timesteps=27888, episode_reward=-243.92 +/- 59.62
Episode length: 237.00 +/- 57.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | -244     |
| time/              |          |
|    total_timesteps | 27888    |
---------------------------------
Eval num_timesteps=29880, episode_reward=-284.40 +/- 8.77
Episode length: 232.80 +/- 43.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 29880    |
---------------------------------
Eval num_timesteps=31872, episode_reward=-285.97 +/- 9.96
Episode length: 180.60 +/- 31.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 181      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 31872    |
---------------------------------
Eval num_timesteps=33864, episode_reward=-283.38 +/- 17.46
Episode length: 200.80 +/- 23.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 33864    |
---------------------------------
Eval num_timesteps=35856, episode_reward=-278.64 +/- 13.85
Episode length: 240.00 +/- 64.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 35856    |
---------------------------------
Eval num_timesteps=37848, episode_reward=-268.78 +/- 6.47
Episode length: 198.60 +/- 40.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 199      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 37848    |
---------------------------------
Eval num_timesteps=39840, episode_reward=-264.17 +/- 46.46
Episode length: 240.20 +/- 59.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -264     |
| time/              |          |
|    total_timesteps | 39840    |
---------------------------------
Eval num_timesteps=41832, episode_reward=-254.45 +/- 34.55
Episode length: 271.20 +/- 35.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 271      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 41832    |
---------------------------------
Eval num_timesteps=43824, episode_reward=-277.33 +/- 9.47
Episode length: 218.00 +/- 72.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 218      |
|    mean_reward     | -277     |
| time/              |          |
|    total_timesteps | 43824    |
---------------------------------
Eval num_timesteps=45816, episode_reward=-283.31 +/- 7.56
Episode length: 201.60 +/- 14.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 202      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 45816    |
---------------------------------
Eval num_timesteps=47808, episode_reward=-258.24 +/- 52.40
Episode length: 284.00 +/- 62.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 284      |
|    mean_reward     | -258     |
| time/              |          |
|    total_timesteps | 47808    |
---------------------------------
Eval num_timesteps=49800, episode_reward=-269.62 +/- 29.32
Episode length: 230.00 +/- 66.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 230         |
|    mean_reward          | -270        |
| time/                   |             |
|    total_timesteps      | 49800       |
| train/                  |             |
|    approx_kl            | 0.003811116 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.69       |
|    explained_variance   | -0.251      |
|    learning_rate        | 0.001       |
|    loss                 | 1.03        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00179    |
|    std                  | 1.01        |
|    value_loss           | 2.82        |
-----------------------------------------
Eval num_timesteps=51792, episode_reward=-277.54 +/- 14.50
Episode length: 177.80 +/- 19.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 178      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 51792    |
---------------------------------
Eval num_timesteps=53784, episode_reward=-233.03 +/- 73.47
Episode length: 231.00 +/- 67.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -233     |
| time/              |          |
|    total_timesteps | 53784    |
---------------------------------
New best mean reward!
Eval num_timesteps=55776, episode_reward=-269.93 +/- 18.77
Episode length: 243.20 +/- 58.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 55776    |
---------------------------------
Eval num_timesteps=57768, episode_reward=-278.11 +/- 8.84
Episode length: 197.60 +/- 32.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 198      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 57768    |
---------------------------------
Eval num_timesteps=59760, episode_reward=-273.87 +/- 15.58
Episode length: 205.20 +/- 44.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 205      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 59760    |
---------------------------------
Eval num_timesteps=61752, episode_reward=-287.85 +/- 6.89
Episode length: 184.20 +/- 22.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 184      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 61752    |
---------------------------------
Eval num_timesteps=63744, episode_reward=-268.99 +/- 14.45
Episode length: 193.60 +/- 15.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 63744    |
---------------------------------
Eval num_timesteps=65736, episode_reward=-271.99 +/- 26.76
Episode length: 203.60 +/- 21.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 204      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 65736    |
---------------------------------
Eval num_timesteps=67728, episode_reward=-275.57 +/- 14.08
Episode length: 183.60 +/- 31.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 184      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 67728    |
---------------------------------
Eval num_timesteps=69720, episode_reward=-272.45 +/- 26.15
Episode length: 206.80 +/- 37.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 207      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 69720    |
---------------------------------
Eval num_timesteps=71712, episode_reward=-271.93 +/- 14.03
Episode length: 200.20 +/- 11.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 71712    |
---------------------------------
Eval num_timesteps=73704, episode_reward=-281.11 +/- 10.02
Episode length: 228.80 +/- 86.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 229      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 73704    |
---------------------------------
Eval num_timesteps=75696, episode_reward=-278.10 +/- 11.94
Episode length: 220.20 +/- 79.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 220      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 75696    |
---------------------------------
Eval num_timesteps=77688, episode_reward=-243.42 +/- 32.04
Episode length: 237.20 +/- 47.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | -243     |
| time/              |          |
|    total_timesteps | 77688    |
---------------------------------
Eval num_timesteps=79680, episode_reward=-280.52 +/- 10.03
Episode length: 177.00 +/- 19.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 177      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 79680    |
---------------------------------
Eval num_timesteps=81672, episode_reward=-278.60 +/- 13.00
Episode length: 174.40 +/- 20.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 174      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 81672    |
---------------------------------
Eval num_timesteps=83664, episode_reward=-278.86 +/- 10.47
Episode length: 192.60 +/- 36.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 193      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 83664    |
---------------------------------
Eval num_timesteps=85656, episode_reward=-277.76 +/- 18.37
Episode length: 162.40 +/- 36.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 162      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 85656    |
---------------------------------
Eval num_timesteps=87648, episode_reward=-262.78 +/- 21.46
Episode length: 223.60 +/- 36.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 224      |
|    mean_reward     | -263     |
| time/              |          |
|    total_timesteps | 87648    |
---------------------------------
Eval num_timesteps=89640, episode_reward=-285.56 +/- 14.53
Episode length: 219.00 +/- 53.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 219      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 89640    |
---------------------------------
Eval num_timesteps=91632, episode_reward=-267.13 +/- 25.11
Episode length: 207.40 +/- 30.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 207      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 91632    |
---------------------------------
Eval num_timesteps=93624, episode_reward=-285.63 +/- 3.88
Episode length: 178.20 +/- 31.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 178      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 93624    |
---------------------------------
Eval num_timesteps=95616, episode_reward=-266.18 +/- 18.20
Episode length: 229.40 +/- 54.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 229      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 95616    |
---------------------------------
Eval num_timesteps=97608, episode_reward=-275.12 +/- 9.01
Episode length: 206.20 +/- 44.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 206      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 97608    |
---------------------------------
Eval num_timesteps=99600, episode_reward=-273.62 +/- 10.73
Episode length: 236.40 +/- 73.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 236         |
|    mean_reward          | -274        |
| time/                   |             |
|    total_timesteps      | 99600       |
| train/                  |             |
|    approx_kl            | 0.004067657 |
|    clip_fraction        | 0.027       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.72       |
|    explained_variance   | 0.561       |
|    learning_rate        | 0.001       |
|    loss                 | 0.302       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00122    |
|    std                  | 1.02        |
|    value_loss           | 1.32        |
-----------------------------------------
Eval num_timesteps=101592, episode_reward=-271.23 +/- 15.73
Episode length: 220.40 +/- 35.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 220      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 101592   |
---------------------------------
Eval num_timesteps=103584, episode_reward=-268.86 +/- 30.11
Episode length: 201.60 +/- 25.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 202      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 103584   |
---------------------------------
Eval num_timesteps=105576, episode_reward=-278.00 +/- 7.35
Episode length: 199.00 +/- 24.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 199      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 105576   |
---------------------------------
Eval num_timesteps=107568, episode_reward=-277.76 +/- 2.85
Episode length: 194.40 +/- 35.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 107568   |
---------------------------------
Eval num_timesteps=109560, episode_reward=-278.11 +/- 11.36
Episode length: 190.00 +/- 25.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 190      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 109560   |
---------------------------------
Eval num_timesteps=111552, episode_reward=-243.29 +/- 57.69
Episode length: 247.60 +/- 88.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 248      |
|    mean_reward     | -243     |
| time/              |          |
|    total_timesteps | 111552   |
---------------------------------
Eval num_timesteps=113544, episode_reward=-283.83 +/- 8.56
Episode length: 208.80 +/- 41.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 209      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 113544   |
---------------------------------
Eval num_timesteps=115536, episode_reward=-267.48 +/- 16.11
Episode length: 255.00 +/- 56.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 255      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 115536   |
---------------------------------
Eval num_timesteps=117528, episode_reward=-270.07 +/- 12.29
Episode length: 181.60 +/- 29.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 182      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 117528   |
---------------------------------
Eval num_timesteps=119520, episode_reward=-271.37 +/- 15.35
Episode length: 224.00 +/- 59.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 224      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 119520   |
---------------------------------
Eval num_timesteps=121512, episode_reward=-282.74 +/- 7.06
Episode length: 194.40 +/- 31.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 121512   |
---------------------------------
Eval num_timesteps=123504, episode_reward=-281.17 +/- 5.41
Episode length: 208.40 +/- 28.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 208      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 123504   |
---------------------------------
Eval num_timesteps=125496, episode_reward=-269.73 +/- 37.42
Episode length: 267.20 +/- 72.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 267      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 125496   |
---------------------------------
Eval num_timesteps=127488, episode_reward=-284.76 +/- 13.75
Episode length: 217.80 +/- 42.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 218      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 127488   |
---------------------------------
Eval num_timesteps=129480, episode_reward=-278.32 +/- 7.76
Episode length: 211.40 +/- 49.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 211      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 129480   |
---------------------------------
Eval num_timesteps=131472, episode_reward=-271.29 +/- 16.09
Episode length: 242.20 +/- 73.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 131472   |
---------------------------------
Eval num_timesteps=133464, episode_reward=-279.86 +/- 7.08
Episode length: 214.20 +/- 70.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 214      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 133464   |
---------------------------------
Eval num_timesteps=135456, episode_reward=-274.17 +/- 26.76
Episode length: 212.60 +/- 77.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 213      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 135456   |
---------------------------------
Eval num_timesteps=137448, episode_reward=-271.00 +/- 12.28
Episode length: 280.60 +/- 43.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 281      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 137448   |
---------------------------------
Eval num_timesteps=139440, episode_reward=-285.99 +/- 9.06
Episode length: 243.40 +/- 58.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 139440   |
---------------------------------
Eval num_timesteps=141432, episode_reward=-278.51 +/- 8.92
Episode length: 196.00 +/- 34.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 196      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 141432   |
---------------------------------
Eval num_timesteps=143424, episode_reward=-265.38 +/- 17.62
Episode length: 195.00 +/- 37.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 195      |
|    mean_reward     | -265     |
| time/              |          |
|    total_timesteps | 143424   |
---------------------------------
Eval num_timesteps=145416, episode_reward=-286.01 +/- 12.24
Episode length: 298.20 +/- 153.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 298      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 145416   |
---------------------------------
Eval num_timesteps=147408, episode_reward=-275.21 +/- 12.43
Episode length: 212.20 +/- 23.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 212      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 147408   |
---------------------------------
Eval num_timesteps=149400, episode_reward=-272.65 +/- 10.34
Episode length: 193.40 +/- 16.56
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 193          |
|    mean_reward          | -273         |
| time/                   |              |
|    total_timesteps      | 149400       |
| train/                  |              |
|    approx_kl            | 0.0042648935 |
|    clip_fraction        | 0.0343       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.75        |
|    explained_variance   | 0.939        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0964       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00211     |
|    std                  | 1.02         |
|    value_loss           | 0.39         |
------------------------------------------
Eval num_timesteps=151392, episode_reward=-260.75 +/- 32.76
Episode length: 189.20 +/- 46.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 189      |
|    mean_reward     | -261     |
| time/              |          |
|    total_timesteps | 151392   |
---------------------------------
Eval num_timesteps=153384, episode_reward=-286.96 +/- 14.25
Episode length: 214.20 +/- 50.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 214      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 153384   |
---------------------------------
Eval num_timesteps=155376, episode_reward=-273.80 +/- 18.25
Episode length: 237.20 +/- 65.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 155376   |
---------------------------------
Eval num_timesteps=157368, episode_reward=-275.09 +/- 10.60
Episode length: 235.60 +/- 76.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 236      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 157368   |
---------------------------------
Eval num_timesteps=159360, episode_reward=-285.84 +/- 9.51
Episode length: 221.20 +/- 48.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 159360   |
---------------------------------
Eval num_timesteps=161352, episode_reward=-282.41 +/- 7.34
Episode length: 174.60 +/- 19.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 175      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 161352   |
---------------------------------
Eval num_timesteps=163344, episode_reward=-275.73 +/- 24.91
Episode length: 206.60 +/- 37.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 207      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 163344   |
---------------------------------
Eval num_timesteps=165336, episode_reward=-283.12 +/- 3.66
Episode length: 194.20 +/- 21.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 165336   |
---------------------------------
Eval num_timesteps=167328, episode_reward=-272.37 +/- 19.61
Episode length: 200.60 +/- 78.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 167328   |
---------------------------------
Eval num_timesteps=169320, episode_reward=-274.18 +/- 8.12
Episode length: 220.80 +/- 65.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 169320   |
---------------------------------
Eval num_timesteps=171312, episode_reward=-262.78 +/- 32.22
Episode length: 224.20 +/- 52.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 224      |
|    mean_reward     | -263     |
| time/              |          |
|    total_timesteps | 171312   |
---------------------------------
Eval num_timesteps=173304, episode_reward=-280.09 +/- 9.35
Episode length: 240.00 +/- 48.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 173304   |
---------------------------------
Eval num_timesteps=175296, episode_reward=-279.10 +/- 10.25
Episode length: 239.00 +/- 39.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 239      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 175296   |
---------------------------------
Eval num_timesteps=177288, episode_reward=-278.82 +/- 15.76
Episode length: 201.40 +/- 36.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 177288   |
---------------------------------
Eval num_timesteps=179280, episode_reward=-281.94 +/- 10.33
Episode length: 216.80 +/- 35.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 217      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 179280   |
---------------------------------
Eval num_timesteps=181272, episode_reward=-284.85 +/- 10.86
Episode length: 175.80 +/- 28.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 176      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 181272   |
---------------------------------
Eval num_timesteps=183264, episode_reward=-281.68 +/- 6.83
Episode length: 187.20 +/- 28.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 187      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 183264   |
---------------------------------
Eval num_timesteps=185256, episode_reward=-254.76 +/- 52.88
Episode length: 200.20 +/- 45.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | -255     |
| time/              |          |
|    total_timesteps | 185256   |
---------------------------------
Eval num_timesteps=187248, episode_reward=-279.69 +/- 13.41
Episode length: 190.20 +/- 14.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 190      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 187248   |
---------------------------------
Eval num_timesteps=189240, episode_reward=-280.74 +/- 14.52
Episode length: 225.20 +/- 99.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 225      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 189240   |
---------------------------------
Eval num_timesteps=191232, episode_reward=-282.57 +/- 9.84
Episode length: 181.20 +/- 21.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 181      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 191232   |
---------------------------------
Eval num_timesteps=193224, episode_reward=-288.52 +/- 4.18
Episode length: 182.20 +/- 24.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 182      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 193224   |
---------------------------------
Eval num_timesteps=195216, episode_reward=-283.49 +/- 8.47
Episode length: 200.40 +/- 28.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 200      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 195216   |
---------------------------------
Eval num_timesteps=197208, episode_reward=-273.57 +/- 21.18
Episode length: 209.80 +/- 58.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 210        |
|    mean_reward          | -274       |
| time/                   |            |
|    total_timesteps      | 197208     |
| train/                  |            |
|    approx_kl            | 0.00477567 |
|    clip_fraction        | 0.0753     |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.78      |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0593     |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.00256   |
|    std                  | 1.03       |
|    value_loss           | 0.292      |
----------------------------------------
Eval num_timesteps=199200, episode_reward=-282.60 +/- 15.60
Episode length: 248.00 +/- 75.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 248      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 199200   |
---------------------------------
Eval num_timesteps=201192, episode_reward=-274.95 +/- 10.20
Episode length: 212.60 +/- 27.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 213      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 201192   |
---------------------------------
Eval num_timesteps=203184, episode_reward=-292.99 +/- 5.55
Episode length: 222.00 +/- 46.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 222      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 203184   |
---------------------------------
Eval num_timesteps=205176, episode_reward=-286.16 +/- 6.97
Episode length: 202.80 +/- 25.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 203      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 205176   |
---------------------------------
Eval num_timesteps=207168, episode_reward=-287.97 +/- 11.35
Episode length: 237.40 +/- 58.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 207168   |
---------------------------------
Eval num_timesteps=209160, episode_reward=-283.33 +/- 5.88
Episode length: 169.80 +/- 17.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 170      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 209160   |
---------------------------------
Eval num_timesteps=211152, episode_reward=-289.06 +/- 3.82
Episode length: 189.40 +/- 8.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 189      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 211152   |
---------------------------------
Eval num_timesteps=213144, episode_reward=-286.26 +/- 7.79
Episode length: 221.60 +/- 59.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 222      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 213144   |
---------------------------------
Eval num_timesteps=215136, episode_reward=-286.09 +/- 6.18
Episode length: 231.20 +/- 29.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 215136   |
---------------------------------
Eval num_timesteps=217128, episode_reward=-279.44 +/- 11.17
Episode length: 191.00 +/- 33.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 191      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 217128   |
---------------------------------
Eval num_timesteps=219120, episode_reward=-275.50 +/- 13.33
Episode length: 252.80 +/- 42.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 253      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 219120   |
---------------------------------
Eval num_timesteps=221112, episode_reward=-278.75 +/- 21.87
Episode length: 241.00 +/- 75.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 221112   |
---------------------------------
Eval num_timesteps=223104, episode_reward=-272.35 +/- 16.89
Episode length: 239.20 +/- 55.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 239      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 223104   |
---------------------------------
Eval num_timesteps=225096, episode_reward=-262.85 +/- 32.02
Episode length: 209.80 +/- 36.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 210      |
|    mean_reward     | -263     |
| time/              |          |
|    total_timesteps | 225096   |
---------------------------------
Eval num_timesteps=227088, episode_reward=-279.24 +/- 15.24
Episode length: 236.80 +/- 38.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 227088   |
---------------------------------
Eval num_timesteps=229080, episode_reward=-282.48 +/- 4.40
Episode length: 233.40 +/- 34.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 229080   |
---------------------------------
Eval num_timesteps=231072, episode_reward=-252.65 +/- 39.23
Episode length: 194.60 +/- 56.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 195      |
|    mean_reward     | -253     |
| time/              |          |
|    total_timesteps | 231072   |
---------------------------------
Eval num_timesteps=233064, episode_reward=-276.13 +/- 12.88
Episode length: 254.60 +/- 44.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 255      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 233064   |
---------------------------------
Eval num_timesteps=235056, episode_reward=-259.21 +/- 49.42
Episode length: 203.60 +/- 43.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 204      |
|    mean_reward     | -259     |
| time/              |          |
|    total_timesteps | 235056   |
---------------------------------
Eval num_timesteps=237048, episode_reward=-274.43 +/- 19.03
Episode length: 230.60 +/- 48.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 237048   |
---------------------------------
Eval num_timesteps=239040, episode_reward=-263.39 +/- 25.96
Episode length: 222.20 +/- 22.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 222      |
|    mean_reward     | -263     |
| time/              |          |
|    total_timesteps | 239040   |
---------------------------------
Eval num_timesteps=241032, episode_reward=-252.39 +/- 19.11
Episode length: 227.20 +/- 59.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 227      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 241032   |
---------------------------------
Eval num_timesteps=243024, episode_reward=-290.43 +/- 3.44
Episode length: 180.20 +/- 40.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 180      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 243024   |
---------------------------------
Eval num_timesteps=245016, episode_reward=-286.30 +/- 6.14
Episode length: 173.60 +/- 23.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 174      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 245016   |
---------------------------------
Eval num_timesteps=247008, episode_reward=-288.30 +/- 2.17
Episode length: 204.60 +/- 27.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 205         |
|    mean_reward          | -288        |
| time/                   |             |
|    total_timesteps      | 247008      |
| train/                  |             |
|    approx_kl            | 0.007716786 |
|    clip_fraction        | 0.044       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.79       |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0345      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00169    |
|    std                  | 1.03        |
|    value_loss           | 0.269       |
-----------------------------------------
Eval num_timesteps=249000, episode_reward=-290.88 +/- 6.18
Episode length: 241.60 +/- 51.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 249000   |
---------------------------------
Eval num_timesteps=250992, episode_reward=-293.03 +/- 8.70
Episode length: 258.80 +/- 53.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 259      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 250992   |
---------------------------------
Eval num_timesteps=252984, episode_reward=-286.82 +/- 4.38
Episode length: 213.40 +/- 46.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 213      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 252984   |
---------------------------------
Eval num_timesteps=254976, episode_reward=-291.64 +/- 6.71
Episode length: 214.60 +/- 38.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 215      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 254976   |
---------------------------------
Eval num_timesteps=256968, episode_reward=-290.17 +/- 1.27
Episode length: 206.00 +/- 28.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 206      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 256968   |
---------------------------------
Eval num_timesteps=258960, episode_reward=-294.74 +/- 4.75
Episode length: 220.20 +/- 41.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 220      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 258960   |
---------------------------------
Eval num_timesteps=260952, episode_reward=-289.97 +/- 1.88
Episode length: 205.00 +/- 35.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 205      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 260952   |
---------------------------------
Eval num_timesteps=262944, episode_reward=-291.36 +/- 7.78
Episode length: 202.00 +/- 42.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 202      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 262944   |
---------------------------------
Eval num_timesteps=264936, episode_reward=-281.74 +/- 25.36
Episode length: 229.00 +/- 75.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 229      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 264936   |
---------------------------------
Eval num_timesteps=266928, episode_reward=-294.25 +/- 5.42
Episode length: 201.00 +/- 36.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 266928   |
---------------------------------
Eval num_timesteps=268920, episode_reward=-291.98 +/- 2.27
Episode length: 180.40 +/- 16.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 180      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 268920   |
---------------------------------
Eval num_timesteps=270912, episode_reward=-281.42 +/- 12.93
Episode length: 239.00 +/- 45.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 239      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 270912   |
---------------------------------
Eval num_timesteps=272904, episode_reward=-287.16 +/- 7.57
Episode length: 205.40 +/- 32.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 205      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 272904   |
---------------------------------
Eval num_timesteps=274896, episode_reward=-289.67 +/- 3.23
Episode length: 211.00 +/- 27.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 211      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 274896   |
---------------------------------
Eval num_timesteps=276888, episode_reward=-290.31 +/- 7.58
Episode length: 203.40 +/- 26.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 203      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 276888   |
---------------------------------
Eval num_timesteps=278880, episode_reward=-288.75 +/- 4.93
Episode length: 258.00 +/- 66.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 258      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 278880   |
---------------------------------
Eval num_timesteps=280872, episode_reward=-290.77 +/- 3.70
Episode length: 183.00 +/- 31.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 183      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 280872   |
---------------------------------
Eval num_timesteps=282864, episode_reward=-278.83 +/- 12.97
Episode length: 222.60 +/- 37.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 223      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 282864   |
---------------------------------
Eval num_timesteps=284856, episode_reward=-288.81 +/- 13.93
Episode length: 239.60 +/- 42.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 284856   |
---------------------------------
Eval num_timesteps=286848, episode_reward=-286.57 +/- 7.50
Episode length: 194.20 +/- 44.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 286848   |
---------------------------------
Eval num_timesteps=288840, episode_reward=-284.21 +/- 5.73
Episode length: 214.00 +/- 59.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 214      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 288840   |
---------------------------------
Eval num_timesteps=290832, episode_reward=-282.28 +/- 9.73
Episode length: 194.20 +/- 31.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 290832   |
---------------------------------
Eval num_timesteps=292824, episode_reward=-292.46 +/- 2.61
Episode length: 186.60 +/- 31.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 187      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 292824   |
---------------------------------
Eval num_timesteps=294816, episode_reward=-290.15 +/- 3.77
Episode length: 191.00 +/- 22.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 191      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 294816   |
---------------------------------
Eval num_timesteps=296808, episode_reward=-294.36 +/- 5.75
Episode length: 242.20 +/- 52.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 242         |
|    mean_reward          | -294        |
| time/                   |             |
|    total_timesteps      | 296808      |
| train/                  |             |
|    approx_kl            | 0.009333882 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.79       |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0235      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0027     |
|    std                  | 1.03        |
|    value_loss           | 0.263       |
-----------------------------------------
Eval num_timesteps=298800, episode_reward=-282.60 +/- 13.76
Episode length: 205.80 +/- 57.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 206      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 298800   |
---------------------------------
Eval num_timesteps=300792, episode_reward=-290.13 +/- 4.06
Episode length: 231.40 +/- 38.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 300792   |
---------------------------------
Eval num_timesteps=302784, episode_reward=-291.03 +/- 5.57
Episode length: 241.20 +/- 25.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 302784   |
---------------------------------
Eval num_timesteps=304776, episode_reward=-291.94 +/- 2.55
Episode length: 187.40 +/- 26.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 187      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 304776   |
---------------------------------
Eval num_timesteps=306768, episode_reward=-289.79 +/- 10.43
Episode length: 240.60 +/- 97.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 306768   |
---------------------------------
Eval num_timesteps=308760, episode_reward=-292.32 +/- 5.77
Episode length: 211.60 +/- 45.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 212      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 308760   |
---------------------------------
Eval num_timesteps=310752, episode_reward=-289.88 +/- 5.89
Episode length: 243.60 +/- 34.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 244      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 310752   |
---------------------------------
Eval num_timesteps=312744, episode_reward=-289.25 +/- 3.64
Episode length: 211.00 +/- 36.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 211      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 312744   |
---------------------------------
Eval num_timesteps=314736, episode_reward=-285.71 +/- 8.43
Episode length: 223.20 +/- 44.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 223      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 314736   |
---------------------------------
Eval num_timesteps=316728, episode_reward=-289.72 +/- 5.49
Episode length: 193.60 +/- 18.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 194      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 316728   |
---------------------------------
Eval num_timesteps=318720, episode_reward=-284.53 +/- 3.88
Episode length: 202.00 +/- 32.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 202      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 318720   |
---------------------------------
Eval num_timesteps=320712, episode_reward=-284.45 +/- 14.10
Episode length: 229.00 +/- 40.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 229      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 320712   |
---------------------------------
Eval num_timesteps=322704, episode_reward=-285.85 +/- 8.61
Episode length: 250.60 +/- 32.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 322704   |
---------------------------------
Eval num_timesteps=324696, episode_reward=-289.91 +/- 4.78
Episode length: 228.40 +/- 18.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 228      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 324696   |
---------------------------------
Eval num_timesteps=326688, episode_reward=-294.63 +/- 3.61
Episode length: 241.00 +/- 47.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 326688   |
---------------------------------
Eval num_timesteps=328680, episode_reward=-289.00 +/- 3.74
Episode length: 201.00 +/- 14.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 328680   |
---------------------------------
Eval num_timesteps=330672, episode_reward=-289.29 +/- 2.12
Episode length: 176.20 +/- 18.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 176      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 330672   |
---------------------------------
Eval num_timesteps=332664, episode_reward=-285.05 +/- 5.03
Episode length: 211.60 +/- 45.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 212      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 332664   |
---------------------------------
Eval num_timesteps=334656, episode_reward=-292.92 +/- 2.58
Episode length: 197.00 +/- 21.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 197      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 334656   |
---------------------------------
Eval num_timesteps=336648, episode_reward=-292.49 +/- 3.14
Episode length: 208.00 +/- 42.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 208      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 336648   |
---------------------------------
Eval num_timesteps=338640, episode_reward=-285.59 +/- 4.98
Episode length: 220.40 +/- 60.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 220      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 338640   |
---------------------------------
Eval num_timesteps=340632, episode_reward=-289.15 +/- 2.09
Episode length: 195.60 +/- 24.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 196      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 340632   |
---------------------------------
Eval num_timesteps=342624, episode_reward=-291.01 +/- 6.11
Episode length: 225.20 +/- 69.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 225      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 342624   |
---------------------------------
Eval num_timesteps=344616, episode_reward=-290.82 +/- 7.65
Episode length: 263.60 +/- 51.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 264         |
|    mean_reward          | -291        |
| time/                   |             |
|    total_timesteps      | 344616      |
| train/                  |             |
|    approx_kl            | 0.008471816 |
|    clip_fraction        | 0.0627      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.8        |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00812     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0025     |
|    std                  | 1.03        |
|    value_loss           | 0.237       |
-----------------------------------------
Eval num_timesteps=346608, episode_reward=-304.81 +/- 9.28
Episode length: 286.80 +/- 36.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 287      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 346608   |
---------------------------------
Eval num_timesteps=348600, episode_reward=-291.16 +/- 7.36
Episode length: 269.20 +/- 46.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 269      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 348600   |
---------------------------------
Eval num_timesteps=350592, episode_reward=-301.51 +/- 13.74
Episode length: 286.20 +/- 140.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 286      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 350592   |
---------------------------------
Eval num_timesteps=352584, episode_reward=-295.29 +/- 11.74
Episode length: 274.80 +/- 55.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 275      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 352584   |
---------------------------------
Eval num_timesteps=354576, episode_reward=-290.83 +/- 2.74
Episode length: 221.40 +/- 39.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 354576   |
---------------------------------
Eval num_timesteps=356568, episode_reward=-292.93 +/- 1.92
Episode length: 247.20 +/- 65.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 247      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 356568   |
---------------------------------
Eval num_timesteps=358560, episode_reward=-298.97 +/- 24.48
Episode length: 294.60 +/- 117.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 295      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 358560   |
---------------------------------
Eval num_timesteps=360552, episode_reward=-297.25 +/- 5.00
Episode length: 227.60 +/- 45.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 228      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 360552   |
---------------------------------
Eval num_timesteps=362544, episode_reward=-289.44 +/- 5.90
Episode length: 224.80 +/- 38.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 225      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 362544   |
---------------------------------
Eval num_timesteps=364536, episode_reward=-298.52 +/- 6.10
Episode length: 264.40 +/- 55.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 264      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 364536   |
---------------------------------
Eval num_timesteps=366528, episode_reward=-292.02 +/- 4.29
Episode length: 236.20 +/- 50.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 236      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 366528   |
---------------------------------
Eval num_timesteps=368520, episode_reward=-293.04 +/- 6.52
Episode length: 256.80 +/- 58.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 257      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 368520   |
---------------------------------
Eval num_timesteps=370512, episode_reward=-294.66 +/- 13.35
Episode length: 238.60 +/- 56.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 239      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 370512   |
---------------------------------
Eval num_timesteps=372504, episode_reward=-302.89 +/- 25.08
Episode length: 298.60 +/- 101.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 299      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 372504   |
---------------------------------
Eval num_timesteps=374496, episode_reward=-296.98 +/- 6.57
Episode length: 254.60 +/- 54.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 255      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 374496   |
---------------------------------
Eval num_timesteps=376488, episode_reward=-292.79 +/- 6.18
Episode length: 245.60 +/- 30.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 246      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 376488   |
---------------------------------
Eval num_timesteps=378480, episode_reward=-293.60 +/- 2.62
Episode length: 219.20 +/- 14.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 219      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 378480   |
---------------------------------
Eval num_timesteps=380472, episode_reward=-294.53 +/- 9.89
Episode length: 252.20 +/- 26.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 252      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 380472   |
---------------------------------
Eval num_timesteps=382464, episode_reward=-294.32 +/- 9.32
Episode length: 256.40 +/- 68.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 256      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 382464   |
---------------------------------
Eval num_timesteps=384456, episode_reward=-304.84 +/- 16.83
Episode length: 302.00 +/- 35.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 302      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 384456   |
---------------------------------
Eval num_timesteps=386448, episode_reward=-290.56 +/- 5.15
Episode length: 241.40 +/- 82.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 386448   |
---------------------------------
Eval num_timesteps=388440, episode_reward=-295.45 +/- 11.20
Episode length: 234.80 +/- 62.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 235      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 388440   |
---------------------------------
Eval num_timesteps=390432, episode_reward=-291.77 +/- 4.84
Episode length: 245.60 +/- 46.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 246      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 390432   |
---------------------------------
Eval num_timesteps=392424, episode_reward=-290.18 +/- 3.18
Episode length: 262.00 +/- 51.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 262      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 392424   |
---------------------------------
Eval num_timesteps=394416, episode_reward=-304.07 +/- 16.59
Episode length: 298.80 +/- 68.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 299         |
|    mean_reward          | -304        |
| time/                   |             |
|    total_timesteps      | 394416      |
| train/                  |             |
|    approx_kl            | 0.010615123 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.81       |
|    explained_variance   | 0.976       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0192      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00226    |
|    std                  | 1.04        |
|    value_loss           | 0.248       |
-----------------------------------------
Eval num_timesteps=396408, episode_reward=-293.79 +/- 4.84
Episode length: 299.80 +/- 75.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 300      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 396408   |
---------------------------------
Eval num_timesteps=398400, episode_reward=-307.85 +/- 17.29
Episode length: 316.00 +/- 117.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 316      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 398400   |
---------------------------------
Eval num_timesteps=400392, episode_reward=-292.35 +/- 7.79
Episode length: 271.40 +/- 83.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 271      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 400392   |
---------------------------------
Eval num_timesteps=402384, episode_reward=-294.29 +/- 13.24
Episode length: 325.80 +/- 101.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 326      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 402384   |
---------------------------------
Eval num_timesteps=404376, episode_reward=-291.46 +/- 7.78
Episode length: 291.60 +/- 99.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 292      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 404376   |
---------------------------------
Eval num_timesteps=406368, episode_reward=-304.70 +/- 27.41
Episode length: 385.20 +/- 96.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 385      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 406368   |
---------------------------------
Eval num_timesteps=408360, episode_reward=-299.68 +/- 12.83
Episode length: 319.60 +/- 84.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 320      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 408360   |
---------------------------------
Eval num_timesteps=410352, episode_reward=-305.35 +/- 14.68
Episode length: 324.40 +/- 70.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 324      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 410352   |
---------------------------------
Eval num_timesteps=412344, episode_reward=-296.70 +/- 10.76
Episode length: 318.20 +/- 93.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 318      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 412344   |
---------------------------------
Eval num_timesteps=414336, episode_reward=-298.88 +/- 14.19
Episode length: 373.60 +/- 114.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 374      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 414336   |
---------------------------------
Eval num_timesteps=416328, episode_reward=-285.50 +/- 6.55
Episode length: 215.00 +/- 32.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 215      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 416328   |
---------------------------------
Eval num_timesteps=418320, episode_reward=-306.30 +/- 15.10
Episode length: 364.60 +/- 72.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 365      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 418320   |
---------------------------------
Eval num_timesteps=420312, episode_reward=-296.67 +/- 11.82
Episode length: 309.80 +/- 46.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 310      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 420312   |
---------------------------------
Eval num_timesteps=422304, episode_reward=-305.12 +/- 22.36
Episode length: 318.40 +/- 114.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 318      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 422304   |
---------------------------------
Eval num_timesteps=424296, episode_reward=-290.02 +/- 9.14
Episode length: 258.80 +/- 59.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 259      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 424296   |
---------------------------------
Eval num_timesteps=426288, episode_reward=-291.95 +/- 1.70
Episode length: 258.60 +/- 31.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 259      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 426288   |
---------------------------------
Eval num_timesteps=428280, episode_reward=-296.20 +/- 16.60
Episode length: 289.00 +/- 102.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 289      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 428280   |
---------------------------------
Eval num_timesteps=430272, episode_reward=-296.17 +/- 13.38
Episode length: 326.00 +/- 97.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 326      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 430272   |
---------------------------------
Eval num_timesteps=432264, episode_reward=-312.39 +/- 19.87
Episode length: 352.20 +/- 130.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 352      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 432264   |
---------------------------------
Eval num_timesteps=434256, episode_reward=-300.85 +/- 13.22
Episode length: 308.20 +/- 78.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 308      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 434256   |
---------------------------------
Eval num_timesteps=436248, episode_reward=-295.17 +/- 8.60
Episode length: 258.00 +/- 68.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 258      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 436248   |
---------------------------------
Eval num_timesteps=438240, episode_reward=-307.73 +/- 13.66
Episode length: 427.80 +/- 125.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 438240   |
---------------------------------
Eval num_timesteps=440232, episode_reward=-292.84 +/- 13.38
Episode length: 301.40 +/- 88.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 301      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 440232   |
---------------------------------
Eval num_timesteps=442224, episode_reward=-297.34 +/- 11.39
Episode length: 312.20 +/- 108.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 312      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 442224   |
---------------------------------
Eval num_timesteps=444216, episode_reward=-178.80 +/- 98.06
Episode length: 388.20 +/- 52.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 388         |
|    mean_reward          | -179        |
| time/                   |             |
|    total_timesteps      | 444216      |
| train/                  |             |
|    approx_kl            | 0.020764055 |
|    clip_fraction        | 0.0935      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.82       |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0487      |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.000661   |
|    std                  | 1.04        |
|    value_loss           | 0.271       |
-----------------------------------------
New best mean reward!
Eval num_timesteps=446208, episode_reward=-189.16 +/- 71.01
Episode length: 363.20 +/- 46.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 363      |
|    mean_reward     | -189     |
| time/              |          |
|    total_timesteps | 446208   |
---------------------------------
Eval num_timesteps=448200, episode_reward=-182.86 +/- 93.16
Episode length: 387.40 +/- 78.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 387      |
|    mean_reward     | -183     |
| time/              |          |
|    total_timesteps | 448200   |
---------------------------------
Eval num_timesteps=450192, episode_reward=-160.27 +/- 68.40
Episode length: 381.80 +/- 26.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 382      |
|    mean_reward     | -160     |
| time/              |          |
|    total_timesteps | 450192   |
---------------------------------
New best mean reward!
Eval num_timesteps=452184, episode_reward=-190.86 +/- 67.89
Episode length: 390.80 +/- 89.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | -191     |
| time/              |          |
|    total_timesteps | 452184   |
---------------------------------
Eval num_timesteps=454176, episode_reward=-204.08 +/- 48.82
Episode length: 392.20 +/- 26.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 392      |
|    mean_reward     | -204     |
| time/              |          |
|    total_timesteps | 454176   |
---------------------------------
Eval num_timesteps=456168, episode_reward=-243.55 +/- 39.31
Episode length: 407.80 +/- 44.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | -244     |
| time/              |          |
|    total_timesteps | 456168   |
---------------------------------
Eval num_timesteps=458160, episode_reward=-188.12 +/- 104.15
Episode length: 372.00 +/- 87.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 372      |
|    mean_reward     | -188     |
| time/              |          |
|    total_timesteps | 458160   |
---------------------------------
Eval num_timesteps=460152, episode_reward=-219.38 +/- 26.54
Episode length: 380.40 +/- 65.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | -219     |
| time/              |          |
|    total_timesteps | 460152   |
---------------------------------
Eval num_timesteps=462144, episode_reward=-250.22 +/- 39.49
Episode length: 358.00 +/- 54.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 358      |
|    mean_reward     | -250     |
| time/              |          |
|    total_timesteps | 462144   |
---------------------------------
Eval num_timesteps=464136, episode_reward=-176.72 +/- 46.05
Episode length: 411.00 +/- 79.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 411      |
|    mean_reward     | -177     |
| time/              |          |
|    total_timesteps | 464136   |
---------------------------------
Eval num_timesteps=466128, episode_reward=-225.00 +/- 118.12
Episode length: 354.40 +/- 68.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 354      |
|    mean_reward     | -225     |
| time/              |          |
|    total_timesteps | 466128   |
---------------------------------
Eval num_timesteps=468120, episode_reward=-254.16 +/- 46.29
Episode length: 387.20 +/- 38.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 387      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 468120   |
---------------------------------
Eval num_timesteps=470112, episode_reward=-246.83 +/- 52.12
Episode length: 352.60 +/- 81.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 353      |
|    mean_reward     | -247     |
| time/              |          |
|    total_timesteps | 470112   |
---------------------------------
Eval num_timesteps=472104, episode_reward=-270.01 +/- 33.92
Episode length: 331.60 +/- 72.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 332      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 472104   |
---------------------------------
Eval num_timesteps=474096, episode_reward=-173.05 +/- 66.54
Episode length: 378.40 +/- 56.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | -173     |
| time/              |          |
|    total_timesteps | 474096   |
---------------------------------
Eval num_timesteps=476088, episode_reward=-234.19 +/- 53.71
Episode length: 379.60 +/- 78.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | -234     |
| time/              |          |
|    total_timesteps | 476088   |
---------------------------------
Eval num_timesteps=478080, episode_reward=-262.39 +/- 46.27
Episode length: 378.00 +/- 46.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | -262     |
| time/              |          |
|    total_timesteps | 478080   |
---------------------------------
Eval num_timesteps=480072, episode_reward=-251.36 +/- 65.56
Episode length: 343.80 +/- 90.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 344      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 480072   |
---------------------------------
Eval num_timesteps=482064, episode_reward=-275.19 +/- 37.01
Episode length: 401.20 +/- 40.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 482064   |
---------------------------------
Eval num_timesteps=484056, episode_reward=-267.27 +/- 33.85
Episode length: 304.40 +/- 18.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 304      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 484056   |
---------------------------------
Eval num_timesteps=486048, episode_reward=-200.26 +/- 118.51
Episode length: 389.60 +/- 84.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 390      |
|    mean_reward     | -200     |
| time/              |          |
|    total_timesteps | 486048   |
---------------------------------
Eval num_timesteps=488040, episode_reward=-255.54 +/- 37.77
Episode length: 359.00 +/- 75.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 359      |
|    mean_reward     | -256     |
| time/              |          |
|    total_timesteps | 488040   |
---------------------------------
Eval num_timesteps=490032, episode_reward=-193.58 +/- 79.85
Episode length: 429.40 +/- 50.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 429      |
|    mean_reward     | -194     |
| time/              |          |
|    total_timesteps | 490032   |
---------------------------------
Eval num_timesteps=492024, episode_reward=-206.71 +/- 57.80
Episode length: 315.20 +/- 40.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 315         |
|    mean_reward          | -207        |
| time/                   |             |
|    total_timesteps      | 492024      |
| train/                  |             |
|    approx_kl            | 0.009946429 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.83       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.001       |
|    loss                 | 0.102       |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00231    |
|    std                  | 1.04        |
|    value_loss           | 0.499       |
-----------------------------------------
Eval num_timesteps=494016, episode_reward=-77.20 +/- 135.43
Episode length: 356.20 +/- 74.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 356      |
|    mean_reward     | -77.2    |
| time/              |          |
|    total_timesteps | 494016   |
---------------------------------
New best mean reward!
Eval num_timesteps=496008, episode_reward=-101.12 +/- 110.90
Episode length: 342.00 +/- 56.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 342      |
|    mean_reward     | -101     |
| time/              |          |
|    total_timesteps | 496008   |
---------------------------------
Eval num_timesteps=498000, episode_reward=-91.15 +/- 63.06
Episode length: 434.40 +/- 93.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 434      |
|    mean_reward     | -91.1    |
| time/              |          |
|    total_timesteps | 498000   |
---------------------------------
Eval num_timesteps=499992, episode_reward=-167.05 +/- 58.24
Episode length: 357.80 +/- 46.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 358      |
|    mean_reward     | -167     |
| time/              |          |
|    total_timesteps | 499992   |
---------------------------------
Eval num_timesteps=501984, episode_reward=-155.85 +/- 103.50
Episode length: 383.20 +/- 36.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | -156     |
| time/              |          |
|    total_timesteps | 501984   |
---------------------------------
Eval num_timesteps=503976, episode_reward=-157.78 +/- 103.05
Episode length: 378.40 +/- 39.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | -158     |
| time/              |          |
|    total_timesteps | 503976   |
---------------------------------
Eval num_timesteps=505968, episode_reward=-172.17 +/- 55.43
Episode length: 348.80 +/- 63.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 349      |
|    mean_reward     | -172     |
| time/              |          |
|    total_timesteps | 505968   |
---------------------------------
Eval num_timesteps=507960, episode_reward=-202.15 +/- 41.36
Episode length: 326.40 +/- 28.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 326      |
|    mean_reward     | -202     |
| time/              |          |
|    total_timesteps | 507960   |
---------------------------------
Eval num_timesteps=509952, episode_reward=-141.43 +/- 90.13
Episode length: 362.80 +/- 92.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 363      |
|    mean_reward     | -141     |
| time/              |          |
|    total_timesteps | 509952   |
---------------------------------
Eval num_timesteps=511944, episode_reward=-219.25 +/- 44.50
Episode length: 322.80 +/- 41.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 323      |
|    mean_reward     | -219     |
| time/              |          |
|    total_timesteps | 511944   |
---------------------------------
Eval num_timesteps=513936, episode_reward=-204.76 +/- 52.91
Episode length: 282.20 +/- 32.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 282      |
|    mean_reward     | -205     |
| time/              |          |
|    total_timesteps | 513936   |
---------------------------------
Eval num_timesteps=515928, episode_reward=-114.23 +/- 125.93
Episode length: 376.60 +/- 61.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 377      |
|    mean_reward     | -114     |
| time/              |          |
|    total_timesteps | 515928   |
---------------------------------
Eval num_timesteps=517920, episode_reward=-220.16 +/- 25.48
Episode length: 333.00 +/- 49.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 333      |
|    mean_reward     | -220     |
| time/              |          |
|    total_timesteps | 517920   |
---------------------------------
Eval num_timesteps=519912, episode_reward=-177.89 +/- 90.01
Episode length: 319.00 +/- 46.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 319      |
|    mean_reward     | -178     |
| time/              |          |
|    total_timesteps | 519912   |
---------------------------------
Eval num_timesteps=521904, episode_reward=-235.36 +/- 31.23
Episode length: 327.60 +/- 14.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 328      |
|    mean_reward     | -235     |
| time/              |          |
|    total_timesteps | 521904   |
---------------------------------
Eval num_timesteps=523896, episode_reward=-190.04 +/- 33.91
Episode length: 336.60 +/- 54.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 337      |
|    mean_reward     | -190     |
| time/              |          |
|    total_timesteps | 523896   |
---------------------------------
Eval num_timesteps=525888, episode_reward=-144.88 +/- 76.57
Episode length: 317.60 +/- 32.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 318      |
|    mean_reward     | -145     |
| time/              |          |
|    total_timesteps | 525888   |
---------------------------------
Eval num_timesteps=527880, episode_reward=-207.10 +/- 49.28
Episode length: 323.00 +/- 66.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 323      |
|    mean_reward     | -207     |
| time/              |          |
|    total_timesteps | 527880   |
---------------------------------
Eval num_timesteps=529872, episode_reward=-192.52 +/- 91.89
Episode length: 342.20 +/- 39.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 342      |
|    mean_reward     | -193     |
| time/              |          |
|    total_timesteps | 529872   |
---------------------------------
Eval num_timesteps=531864, episode_reward=-159.15 +/- 38.53
Episode length: 362.20 +/- 70.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 362      |
|    mean_reward     | -159     |
| time/              |          |
|    total_timesteps | 531864   |
---------------------------------
Eval num_timesteps=533856, episode_reward=-150.01 +/- 43.43
Episode length: 345.00 +/- 62.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 345      |
|    mean_reward     | -150     |
| time/              |          |
|    total_timesteps | 533856   |
---------------------------------
Eval num_timesteps=535848, episode_reward=-214.08 +/- 28.43
Episode length: 308.20 +/- 27.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 308      |
|    mean_reward     | -214     |
| time/              |          |
|    total_timesteps | 535848   |
---------------------------------
Eval num_timesteps=537840, episode_reward=-90.58 +/- 211.60
Episode length: 476.60 +/- 222.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | -90.6    |
| time/              |          |
|    total_timesteps | 537840   |
---------------------------------
Eval num_timesteps=539832, episode_reward=-171.74 +/- 109.51
Episode length: 327.40 +/- 22.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 327      |
|    mean_reward     | -172     |
| time/              |          |
|    total_timesteps | 539832   |
---------------------------------
Eval num_timesteps=541824, episode_reward=-115.29 +/- 101.25
Episode length: 329.00 +/- 71.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 329         |
|    mean_reward          | -115        |
| time/                   |             |
|    total_timesteps      | 541824      |
| train/                  |             |
|    approx_kl            | 0.008423569 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.84       |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0589      |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00224    |
|    std                  | 1.04        |
|    value_loss           | 0.414       |
-----------------------------------------
Eval num_timesteps=543816, episode_reward=-159.94 +/- 57.07
Episode length: 304.60 +/- 34.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 305      |
|    mean_reward     | -160     |
| time/              |          |
|    total_timesteps | 543816   |
---------------------------------
Eval num_timesteps=545808, episode_reward=-154.50 +/- 70.70
Episode length: 282.00 +/- 66.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 282      |
|    mean_reward     | -155     |
| time/              |          |
|    total_timesteps | 545808   |
---------------------------------
Eval num_timesteps=547800, episode_reward=-120.20 +/- 56.24
Episode length: 316.80 +/- 57.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 317      |
|    mean_reward     | -120     |
| time/              |          |
|    total_timesteps | 547800   |
---------------------------------
Eval num_timesteps=549792, episode_reward=-138.61 +/- 54.22
Episode length: 297.60 +/- 46.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 298      |
|    mean_reward     | -139     |
| time/              |          |
|    total_timesteps | 549792   |
---------------------------------
Eval num_timesteps=551784, episode_reward=-113.25 +/- 91.69
Episode length: 313.80 +/- 63.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 314      |
|    mean_reward     | -113     |
| time/              |          |
|    total_timesteps | 551784   |
---------------------------------
Eval num_timesteps=553776, episode_reward=-197.20 +/- 39.47
Episode length: 296.20 +/- 46.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 296      |
|    mean_reward     | -197     |
| time/              |          |
|    total_timesteps | 553776   |
---------------------------------
Eval num_timesteps=555768, episode_reward=-128.61 +/- 53.44
Episode length: 382.00 +/- 93.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 382      |
|    mean_reward     | -129     |
| time/              |          |
|    total_timesteps | 555768   |
---------------------------------
Eval num_timesteps=557760, episode_reward=-178.70 +/- 27.30
Episode length: 294.40 +/- 26.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 294      |
|    mean_reward     | -179     |
| time/              |          |
|    total_timesteps | 557760   |
---------------------------------
Eval num_timesteps=559752, episode_reward=-133.53 +/- 27.49
Episode length: 342.00 +/- 51.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 342      |
|    mean_reward     | -134     |
| time/              |          |
|    total_timesteps | 559752   |
---------------------------------
Eval num_timesteps=561744, episode_reward=-111.58 +/- 56.36
Episode length: 334.40 +/- 49.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 334      |
|    mean_reward     | -112     |
| time/              |          |
|    total_timesteps | 561744   |
---------------------------------
Eval num_timesteps=563736, episode_reward=-183.70 +/- 67.57
Episode length: 331.40 +/- 95.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 331      |
|    mean_reward     | -184     |
| time/              |          |
|    total_timesteps | 563736   |
---------------------------------
Eval num_timesteps=565728, episode_reward=-90.55 +/- 117.20
Episode length: 359.80 +/- 33.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 360      |
|    mean_reward     | -90.6    |
| time/              |          |
|    total_timesteps | 565728   |
---------------------------------
Eval num_timesteps=567720, episode_reward=-102.61 +/- 86.44
Episode length: 343.60 +/- 63.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 344      |
|    mean_reward     | -103     |
| time/              |          |
|    total_timesteps | 567720   |
---------------------------------
Eval num_timesteps=569712, episode_reward=-113.90 +/- 58.96
Episode length: 349.80 +/- 44.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | -114     |
| time/              |          |
|    total_timesteps | 569712   |
---------------------------------
Eval num_timesteps=571704, episode_reward=-107.43 +/- 82.14
Episode length: 320.20 +/- 58.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 320      |
|    mean_reward     | -107     |
| time/              |          |
|    total_timesteps | 571704   |
---------------------------------
Eval num_timesteps=573696, episode_reward=-148.18 +/- 62.96
Episode length: 299.60 +/- 40.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 300      |
|    mean_reward     | -148     |
| time/              |          |
|    total_timesteps | 573696   |
---------------------------------
Eval num_timesteps=575688, episode_reward=-175.73 +/- 86.38
Episode length: 312.80 +/- 102.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 313      |
|    mean_reward     | -176     |
| time/              |          |
|    total_timesteps | 575688   |
---------------------------------
Eval num_timesteps=577680, episode_reward=-93.83 +/- 70.93
Episode length: 347.40 +/- 61.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 347      |
|    mean_reward     | -93.8    |
| time/              |          |
|    total_timesteps | 577680   |
---------------------------------
Eval num_timesteps=579672, episode_reward=-168.06 +/- 27.75
Episode length: 312.60 +/- 62.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 313      |
|    mean_reward     | -168     |
| time/              |          |
|    total_timesteps | 579672   |
---------------------------------
Eval num_timesteps=581664, episode_reward=-123.59 +/- 82.14
Episode length: 314.00 +/- 87.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 314      |
|    mean_reward     | -124     |
| time/              |          |
|    total_timesteps | 581664   |
---------------------------------
Eval num_timesteps=583656, episode_reward=-142.42 +/- 104.41
Episode length: 325.40 +/- 58.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 325      |
|    mean_reward     | -142     |
| time/              |          |
|    total_timesteps | 583656   |
---------------------------------
Eval num_timesteps=585648, episode_reward=-63.76 +/- 138.32
Episode length: 333.00 +/- 83.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 333      |
|    mean_reward     | -63.8    |
| time/              |          |
|    total_timesteps | 585648   |
---------------------------------
New best mean reward!
Eval num_timesteps=587640, episode_reward=-106.34 +/- 73.07
Episode length: 338.20 +/- 73.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 338      |
|    mean_reward     | -106     |
| time/              |          |
|    total_timesteps | 587640   |
---------------------------------
Eval num_timesteps=589632, episode_reward=-123.26 +/- 81.55
Episode length: 324.00 +/- 62.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 324      |
|    mean_reward     | -123     |
| time/              |          |
|    total_timesteps | 589632   |
---------------------------------
Eval num_timesteps=591624, episode_reward=-114.24 +/- 112.60
Episode length: 286.60 +/- 66.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 287         |
|    mean_reward          | -114        |
| time/                   |             |
|    total_timesteps      | 591624      |
| train/                  |             |
|    approx_kl            | 0.005271594 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.84       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | 0.124       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.000664   |
|    std                  | 1.04        |
|    value_loss           | 0.507       |
-----------------------------------------
Eval num_timesteps=593616, episode_reward=-219.04 +/- 32.72
Episode length: 244.80 +/- 22.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 245      |
|    mean_reward     | -219     |
| time/              |          |
|    total_timesteps | 593616   |
---------------------------------
Eval num_timesteps=595608, episode_reward=-189.24 +/- 54.67
Episode length: 242.80 +/- 39.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | -189     |
| time/              |          |
|    total_timesteps | 595608   |
---------------------------------
Eval num_timesteps=597600, episode_reward=-206.15 +/- 10.74
Episode length: 245.00 +/- 10.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 245      |
|    mean_reward     | -206     |
| time/              |          |
|    total_timesteps | 597600   |
---------------------------------
Eval num_timesteps=599592, episode_reward=-187.83 +/- 61.25
Episode length: 297.60 +/- 60.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 298      |
|    mean_reward     | -188     |
| time/              |          |
|    total_timesteps | 599592   |
---------------------------------
Eval num_timesteps=601584, episode_reward=-228.27 +/- 27.02
Episode length: 248.60 +/- 38.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 249      |
|    mean_reward     | -228     |
| time/              |          |
|    total_timesteps | 601584   |
---------------------------------
Eval num_timesteps=603576, episode_reward=-232.19 +/- 10.64
Episode length: 239.60 +/- 35.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -232     |
| time/              |          |
|    total_timesteps | 603576   |
---------------------------------
Eval num_timesteps=605568, episode_reward=-148.88 +/- 56.87
Episode length: 266.40 +/- 34.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 266      |
|    mean_reward     | -149     |
| time/              |          |
|    total_timesteps | 605568   |
---------------------------------
Eval num_timesteps=607560, episode_reward=-221.31 +/- 17.13
Episode length: 241.60 +/- 33.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | -221     |
| time/              |          |
|    total_timesteps | 607560   |
---------------------------------
Eval num_timesteps=609552, episode_reward=-192.60 +/- 56.07
Episode length: 309.80 +/- 40.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 310      |
|    mean_reward     | -193     |
| time/              |          |
|    total_timesteps | 609552   |
---------------------------------
Eval num_timesteps=611544, episode_reward=-185.96 +/- 34.96
Episode length: 281.40 +/- 57.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 281      |
|    mean_reward     | -186     |
| time/              |          |
|    total_timesteps | 611544   |
---------------------------------
Eval num_timesteps=613536, episode_reward=-182.91 +/- 10.54
Episode length: 281.40 +/- 40.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 281      |
|    mean_reward     | -183     |
| time/              |          |
|    total_timesteps | 613536   |
---------------------------------
Eval num_timesteps=615528, episode_reward=-211.61 +/- 25.39
Episode length: 243.60 +/- 30.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 244      |
|    mean_reward     | -212     |
| time/              |          |
|    total_timesteps | 615528   |
---------------------------------
Eval num_timesteps=617520, episode_reward=-218.50 +/- 22.15
Episode length: 249.80 +/- 27.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | -218     |
| time/              |          |
|    total_timesteps | 617520   |
---------------------------------
Eval num_timesteps=619512, episode_reward=-181.57 +/- 26.92
Episode length: 283.00 +/- 39.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 283      |
|    mean_reward     | -182     |
| time/              |          |
|    total_timesteps | 619512   |
---------------------------------
Eval num_timesteps=621504, episode_reward=-163.84 +/- 68.00
Episode length: 265.00 +/- 67.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 265      |
|    mean_reward     | -164     |
| time/              |          |
|    total_timesteps | 621504   |
---------------------------------
Eval num_timesteps=623496, episode_reward=-170.09 +/- 43.49
Episode length: 274.80 +/- 23.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 275      |
|    mean_reward     | -170     |
| time/              |          |
|    total_timesteps | 623496   |
---------------------------------
Eval num_timesteps=625488, episode_reward=-203.13 +/- 29.09
Episode length: 258.00 +/- 62.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 258      |
|    mean_reward     | -203     |
| time/              |          |
|    total_timesteps | 625488   |
---------------------------------
Eval num_timesteps=627480, episode_reward=-190.59 +/- 37.06
Episode length: 296.00 +/- 54.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 296      |
|    mean_reward     | -191     |
| time/              |          |
|    total_timesteps | 627480   |
---------------------------------
Eval num_timesteps=629472, episode_reward=-197.56 +/- 48.92
Episode length: 281.80 +/- 82.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 282      |
|    mean_reward     | -198     |
| time/              |          |
|    total_timesteps | 629472   |
---------------------------------
Eval num_timesteps=631464, episode_reward=-183.19 +/- 71.15
Episode length: 291.60 +/- 98.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 292      |
|    mean_reward     | -183     |
| time/              |          |
|    total_timesteps | 631464   |
---------------------------------
Eval num_timesteps=633456, episode_reward=-185.11 +/- 24.45
Episode length: 263.00 +/- 37.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 263      |
|    mean_reward     | -185     |
| time/              |          |
|    total_timesteps | 633456   |
---------------------------------
Eval num_timesteps=635448, episode_reward=-205.64 +/- 34.95
Episode length: 255.00 +/- 29.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 255      |
|    mean_reward     | -206     |
| time/              |          |
|    total_timesteps | 635448   |
---------------------------------
Eval num_timesteps=637440, episode_reward=-197.15 +/- 46.83
Episode length: 257.00 +/- 25.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 257      |
|    mean_reward     | -197     |
| time/              |          |
|    total_timesteps | 637440   |
---------------------------------
Eval num_timesteps=639432, episode_reward=-183.28 +/- 57.91
Episode length: 268.40 +/- 55.05
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 268          |
|    mean_reward          | -183         |
| time/                   |              |
|    total_timesteps      | 639432       |
| train/                  |              |
|    approx_kl            | 0.0051293196 |
|    clip_fraction        | 0.0884       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.85        |
|    explained_variance   | 0.955        |
|    learning_rate        | 0.001        |
|    loss                 | 0.105        |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.000676    |
|    std                  | 1.04         |
|    value_loss           | 0.432        |
------------------------------------------
Eval num_timesteps=641424, episode_reward=-157.09 +/- 67.46
Episode length: 303.20 +/- 45.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 303      |
|    mean_reward     | -157     |
| time/              |          |
|    total_timesteps | 641424   |
---------------------------------
Eval num_timesteps=643416, episode_reward=-189.78 +/- 29.51
Episode length: 274.20 +/- 30.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 274      |
|    mean_reward     | -190     |
| time/              |          |
|    total_timesteps | 643416   |
---------------------------------
Eval num_timesteps=645408, episode_reward=-161.86 +/- 57.26
Episode length: 269.80 +/- 36.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 270      |
|    mean_reward     | -162     |
| time/              |          |
|    total_timesteps | 645408   |
---------------------------------
Eval num_timesteps=647400, episode_reward=-144.13 +/- 44.84
Episode length: 287.60 +/- 21.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 288      |
|    mean_reward     | -144     |
| time/              |          |
|    total_timesteps | 647400   |
---------------------------------
Eval num_timesteps=649392, episode_reward=-200.98 +/- 9.28
Episode length: 252.80 +/- 14.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 253      |
|    mean_reward     | -201     |
| time/              |          |
|    total_timesteps | 649392   |
---------------------------------
Eval num_timesteps=651384, episode_reward=-122.29 +/- 52.78
Episode length: 303.60 +/- 37.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 304      |
|    mean_reward     | -122     |
| time/              |          |
|    total_timesteps | 651384   |
---------------------------------
Eval num_timesteps=653376, episode_reward=-165.39 +/- 75.45
Episode length: 266.40 +/- 55.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 266      |
|    mean_reward     | -165     |
| time/              |          |
|    total_timesteps | 653376   |
---------------------------------
Eval num_timesteps=655368, episode_reward=-143.23 +/- 80.17
Episode length: 288.60 +/- 56.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 289      |
|    mean_reward     | -143     |
| time/              |          |
|    total_timesteps | 655368   |
---------------------------------
Eval num_timesteps=657360, episode_reward=-200.87 +/- 27.62
Episode length: 233.40 +/- 12.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | -201     |
| time/              |          |
|    total_timesteps | 657360   |
---------------------------------
Eval num_timesteps=659352, episode_reward=-204.38 +/- 23.19
Episode length: 269.80 +/- 46.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 270      |
|    mean_reward     | -204     |
| time/              |          |
|    total_timesteps | 659352   |
---------------------------------
Eval num_timesteps=661344, episode_reward=-191.47 +/- 25.34
Episode length: 273.40 +/- 38.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 273      |
|    mean_reward     | -191     |
| time/              |          |
|    total_timesteps | 661344   |
---------------------------------
Eval num_timesteps=663336, episode_reward=-207.51 +/- 34.55
Episode length: 243.80 +/- 39.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 244      |
|    mean_reward     | -208     |
| time/              |          |
|    total_timesteps | 663336   |
---------------------------------
Eval num_timesteps=665328, episode_reward=-197.05 +/- 23.81
Episode length: 278.80 +/- 64.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 279      |
|    mean_reward     | -197     |
| time/              |          |
|    total_timesteps | 665328   |
---------------------------------
Eval num_timesteps=667320, episode_reward=-194.04 +/- 16.54
Episode length: 276.40 +/- 54.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 276      |
|    mean_reward     | -194     |
| time/              |          |
|    total_timesteps | 667320   |
---------------------------------
Eval num_timesteps=669312, episode_reward=-215.72 +/- 22.39
Episode length: 239.60 +/- 31.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | -216     |
| time/              |          |
|    total_timesteps | 669312   |
---------------------------------
Eval num_timesteps=671304, episode_reward=-215.82 +/- 19.83
Episode length: 245.20 +/- 39.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 245      |
|    mean_reward     | -216     |
| time/              |          |
|    total_timesteps | 671304   |
---------------------------------
Eval num_timesteps=673296, episode_reward=-213.36 +/- 33.18
Episode length: 235.60 +/- 37.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 236      |
|    mean_reward     | -213     |
| time/              |          |
|    total_timesteps | 673296   |
---------------------------------
Eval num_timesteps=675288, episode_reward=-181.22 +/- 32.19
Episode length: 297.00 +/- 24.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 297      |
|    mean_reward     | -181     |
| time/              |          |
|    total_timesteps | 675288   |
---------------------------------
Eval num_timesteps=677280, episode_reward=-179.71 +/- 55.34
Episode length: 263.80 +/- 51.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 264      |
|    mean_reward     | -180     |
| time/              |          |
|    total_timesteps | 677280   |
---------------------------------
Eval num_timesteps=679272, episode_reward=-131.48 +/- 58.05
Episode length: 316.00 +/- 34.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 316      |
|    mean_reward     | -131     |
| time/              |          |
|    total_timesteps | 679272   |
---------------------------------
Eval num_timesteps=681264, episode_reward=-165.81 +/- 50.11
Episode length: 270.40 +/- 37.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 270      |
|    mean_reward     | -166     |
| time/              |          |
|    total_timesteps | 681264   |
---------------------------------
Eval num_timesteps=683256, episode_reward=-180.34 +/- 57.92
Episode length: 258.60 +/- 36.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 259      |
|    mean_reward     | -180     |
| time/              |          |
|    total_timesteps | 683256   |
---------------------------------
Eval num_timesteps=685248, episode_reward=-147.15 +/- 81.88
Episode length: 299.80 +/- 61.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 300      |
|    mean_reward     | -147     |
| time/              |          |
|    total_timesteps | 685248   |
---------------------------------
Eval num_timesteps=687240, episode_reward=-153.03 +/- 43.89
Episode length: 278.80 +/- 23.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 279      |
|    mean_reward     | -153     |
| time/              |          |
|    total_timesteps | 687240   |
---------------------------------
Eval num_timesteps=689232, episode_reward=-216.34 +/- 56.71
Episode length: 215.60 +/- 39.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 216         |
|    mean_reward          | -216        |
| time/                   |             |
|    total_timesteps      | 689232      |
| train/                  |             |
|    approx_kl            | 0.009787013 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.86       |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0169      |
|    n_updates            | 140         |
|    policy_gradient_loss | 0.000748    |
|    std                  | 1.05        |
|    value_loss           | 0.244       |
-----------------------------------------
Eval num_timesteps=691224, episode_reward=-193.28 +/- 55.95
Episode length: 245.20 +/- 31.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 245      |
|    mean_reward     | -193     |
| time/              |          |
|    total_timesteps | 691224   |
---------------------------------
Eval num_timesteps=693216, episode_reward=-188.96 +/- 40.45
Episode length: 234.00 +/- 35.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 234      |
|    mean_reward     | -189     |
| time/              |          |
|    total_timesteps | 693216   |
---------------------------------
Eval num_timesteps=695208, episode_reward=-172.54 +/- 55.34
Episode length: 253.80 +/- 32.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 254      |
|    mean_reward     | -173     |
| time/              |          |
|    total_timesteps | 695208   |
---------------------------------
Eval num_timesteps=697200, episode_reward=-212.08 +/- 19.09
Episode length: 245.20 +/- 52.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 245      |
|    mean_reward     | -212     |
| time/              |          |
|    total_timesteps | 697200   |
---------------------------------
Eval num_timesteps=699192, episode_reward=-187.56 +/- 31.95
Episode length: 255.60 +/- 41.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 256      |
|    mean_reward     | -188     |
| time/              |          |
|    total_timesteps | 699192   |
---------------------------------
Eval num_timesteps=701184, episode_reward=-181.28 +/- 35.53
Episode length: 263.00 +/- 34.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 263      |
|    mean_reward     | -181     |
| time/              |          |
|    total_timesteps | 701184   |
---------------------------------
Eval num_timesteps=703176, episode_reward=-213.60 +/- 33.78
Episode length: 251.60 +/- 28.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 252      |
|    mean_reward     | -214     |
| time/              |          |
|    total_timesteps | 703176   |
---------------------------------
Eval num_timesteps=705168, episode_reward=-198.42 +/- 22.71
Episode length: 252.60 +/- 25.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 253      |
|    mean_reward     | -198     |
| time/              |          |
|    total_timesteps | 705168   |
---------------------------------
Eval num_timesteps=707160, episode_reward=-221.74 +/- 17.15
Episode length: 247.60 +/- 55.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 248      |
|    mean_reward     | -222     |
| time/              |          |
|    total_timesteps | 707160   |
---------------------------------
Eval num_timesteps=709152, episode_reward=-196.22 +/- 25.36
Episode length: 267.20 +/- 60.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 267      |
|    mean_reward     | -196     |
| time/              |          |
|    total_timesteps | 709152   |
---------------------------------
Eval num_timesteps=711144, episode_reward=-219.50 +/- 21.32
Episode length: 222.80 +/- 29.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 223      |
|    mean_reward     | -219     |
| time/              |          |
|    total_timesteps | 711144   |
---------------------------------
Eval num_timesteps=713136, episode_reward=-196.61 +/- 54.51
Episode length: 260.00 +/- 82.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 260      |
|    mean_reward     | -197     |
| time/              |          |
|    total_timesteps | 713136   |
---------------------------------
Eval num_timesteps=715128, episode_reward=-203.10 +/- 63.47
Episode length: 228.40 +/- 46.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 228      |
|    mean_reward     | -203     |
| time/              |          |
|    total_timesteps | 715128   |
---------------------------------
Eval num_timesteps=717120, episode_reward=-212.96 +/- 33.95
Episode length: 234.00 +/- 36.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 234      |
|    mean_reward     | -213     |
| time/              |          |
|    total_timesteps | 717120   |
---------------------------------
Eval num_timesteps=719112, episode_reward=-228.20 +/- 14.02
Episode length: 228.00 +/- 12.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 228      |
|    mean_reward     | -228     |
| time/              |          |
|    total_timesteps | 719112   |
---------------------------------
Eval num_timesteps=721104, episode_reward=-229.01 +/- 20.33
Episode length: 218.00 +/- 21.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 218      |
|    mean_reward     | -229     |
| time/              |          |
|    total_timesteps | 721104   |
---------------------------------
Eval num_timesteps=723096, episode_reward=-163.33 +/- 130.66
Episode length: 269.80 +/- 101.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 270      |
|    mean_reward     | -163     |
| time/              |          |
|    total_timesteps | 723096   |
---------------------------------
Eval num_timesteps=725088, episode_reward=-235.31 +/- 14.62
Episode length: 231.40 +/- 28.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | -235     |
| time/              |          |
|    total_timesteps | 725088   |
---------------------------------
Eval num_timesteps=727080, episode_reward=-225.99 +/- 16.76
Episode length: 233.80 +/- 15.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 234      |
|    mean_reward     | -226     |
| time/              |          |
|    total_timesteps | 727080   |
---------------------------------
Eval num_timesteps=729072, episode_reward=-172.06 +/- 35.36
Episode length: 293.80 +/- 47.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 294      |
|    mean_reward     | -172     |
| time/              |          |
|    total_timesteps | 729072   |
---------------------------------
Eval num_timesteps=731064, episode_reward=-220.40 +/- 21.43
Episode length: 253.20 +/- 44.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 253      |
|    mean_reward     | -220     |
| time/              |          |
|    total_timesteps | 731064   |
---------------------------------
Eval num_timesteps=733056, episode_reward=-221.83 +/- 28.06
Episode length: 227.60 +/- 23.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 228      |
|    mean_reward     | -222     |
| time/              |          |
|    total_timesteps | 733056   |
---------------------------------
Eval num_timesteps=735048, episode_reward=-217.78 +/- 30.84
Episode length: 227.20 +/- 47.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 227      |
|    mean_reward     | -218     |
| time/              |          |
|    total_timesteps | 735048   |
---------------------------------
Eval num_timesteps=737040, episode_reward=-190.67 +/- 32.78
Episode length: 251.20 +/- 25.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -191     |
| time/              |          |
|    total_timesteps | 737040   |
---------------------------------
Eval num_timesteps=739032, episode_reward=-46.70 +/- 183.27
Episode length: 330.60 +/- 76.57
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 331       |
|    mean_reward          | -46.7     |
| time/                   |           |
|    total_timesteps      | 739032    |
| train/                  |           |
|    approx_kl            | 0.0123591 |
|    clip_fraction        | 0.148     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.88     |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.001     |
|    loss                 | 0.0185    |
|    n_updates            | 150       |
|    policy_gradient_loss | -0.000858 |
|    std                  | 1.05      |
|    value_loss           | 0.244     |
---------------------------------------
New best mean reward!
Eval num_timesteps=741024, episode_reward=-143.53 +/- 46.65
Episode length: 298.80 +/- 57.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 299      |
|    mean_reward     | -144     |
| time/              |          |
|    total_timesteps | 741024   |
---------------------------------
Eval num_timesteps=743016, episode_reward=-39.21 +/- 170.99
Episode length: 332.00 +/- 60.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 332      |
|    mean_reward     | -39.2    |
| time/              |          |
|    total_timesteps | 743016   |
---------------------------------
New best mean reward!
Eval num_timesteps=745008, episode_reward=-100.02 +/- 153.78
Episode length: 333.40 +/- 83.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 333      |
|    mean_reward     | -100     |
| time/              |          |
|    total_timesteps | 745008   |
---------------------------------
Eval num_timesteps=747000, episode_reward=-148.85 +/- 76.33
Episode length: 293.60 +/- 47.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 294      |
|    mean_reward     | -149     |
| time/              |          |
|    total_timesteps | 747000   |
---------------------------------
Eval num_timesteps=748992, episode_reward=-183.17 +/- 20.43
Episode length: 280.80 +/- 66.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 281      |
|    mean_reward     | -183     |
| time/              |          |
|    total_timesteps | 748992   |
---------------------------------
Eval num_timesteps=750984, episode_reward=-90.72 +/- 144.17
Episode length: 345.20 +/- 81.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 345      |
|    mean_reward     | -90.7    |
| time/              |          |
|    total_timesteps | 750984   |
---------------------------------
Eval num_timesteps=752976, episode_reward=-108.20 +/- 108.82
Episode length: 302.20 +/- 70.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 302      |
|    mean_reward     | -108     |
| time/              |          |
|    total_timesteps | 752976   |
---------------------------------
Eval num_timesteps=754968, episode_reward=-149.78 +/- 77.26
Episode length: 284.20 +/- 61.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 284      |
|    mean_reward     | -150     |
| time/              |          |
|    total_timesteps | 754968   |
---------------------------------
Eval num_timesteps=756960, episode_reward=-176.76 +/- 52.00
Episode length: 285.40 +/- 102.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 285      |
|    mean_reward     | -177     |
| time/              |          |
|    total_timesteps | 756960   |
---------------------------------
Eval num_timesteps=758952, episode_reward=-115.40 +/- 88.83
Episode length: 283.60 +/- 55.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 284      |
|    mean_reward     | -115     |
| time/              |          |
|    total_timesteps | 758952   |
---------------------------------
Eval num_timesteps=760944, episode_reward=-159.27 +/- 58.97
Episode length: 326.00 +/- 73.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 326      |
|    mean_reward     | -159     |
| time/              |          |
|    total_timesteps | 760944   |
---------------------------------
Eval num_timesteps=762936, episode_reward=-160.79 +/- 35.89
Episode length: 300.20 +/- 78.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 300      |
|    mean_reward     | -161     |
| time/              |          |
|    total_timesteps | 762936   |
---------------------------------
Eval num_timesteps=764928, episode_reward=-109.88 +/- 124.86
Episode length: 286.40 +/- 86.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 286      |
|    mean_reward     | -110     |
| time/              |          |
|    total_timesteps | 764928   |
---------------------------------
Eval num_timesteps=766920, episode_reward=-170.01 +/- 33.29
Episode length: 282.00 +/- 35.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 282      |
|    mean_reward     | -170     |
| time/              |          |
|    total_timesteps | 766920   |
---------------------------------
Eval num_timesteps=768912, episode_reward=-112.36 +/- 90.52
Episode length: 283.40 +/- 55.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 283      |
|    mean_reward     | -112     |
| time/              |          |
|    total_timesteps | 768912   |
---------------------------------
Eval num_timesteps=770904, episode_reward=-168.28 +/- 30.26
Episode length: 280.40 +/- 36.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 280      |
|    mean_reward     | -168     |
| time/              |          |
|    total_timesteps | 770904   |
---------------------------------
Eval num_timesteps=772896, episode_reward=-124.87 +/- 89.52
Episode length: 297.20 +/- 83.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 297      |
|    mean_reward     | -125     |
| time/              |          |
|    total_timesteps | 772896   |
---------------------------------
Eval num_timesteps=774888, episode_reward=-118.79 +/- 114.43
Episode length: 293.40 +/- 51.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 293      |
|    mean_reward     | -119     |
| time/              |          |
|    total_timesteps | 774888   |
---------------------------------
Eval num_timesteps=776880, episode_reward=-192.44 +/- 58.91
Episode length: 277.20 +/- 80.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 277      |
|    mean_reward     | -192     |
| time/              |          |
|    total_timesteps | 776880   |
---------------------------------
Eval num_timesteps=778872, episode_reward=-116.00 +/- 74.68
Episode length: 295.20 +/- 53.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 295      |
|    mean_reward     | -116     |
| time/              |          |
|    total_timesteps | 778872   |
---------------------------------
Eval num_timesteps=780864, episode_reward=-146.66 +/- 75.04
Episode length: 289.80 +/- 48.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 290      |
|    mean_reward     | -147     |
| time/              |          |
|    total_timesteps | 780864   |
---------------------------------
Eval num_timesteps=782856, episode_reward=-158.30 +/- 52.82
Episode length: 269.20 +/- 54.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 269      |
|    mean_reward     | -158     |
| time/              |          |
|    total_timesteps | 782856   |
---------------------------------
Eval num_timesteps=784848, episode_reward=-198.77 +/- 34.64
Episode length: 291.60 +/- 45.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 292      |
|    mean_reward     | -199     |
| time/              |          |
|    total_timesteps | 784848   |
---------------------------------
Eval num_timesteps=786840, episode_reward=-40.85 +/- 145.09
Episode length: 349.80 +/- 49.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 350         |
|    mean_reward          | -40.8       |
| time/                   |             |
|    total_timesteps      | 786840      |
| train/                  |             |
|    approx_kl            | 0.009764103 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.9        |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0244      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00449    |
|    std                  | 1.06        |
|    value_loss           | 0.243       |
-----------------------------------------
Eval num_timesteps=788832, episode_reward=-134.19 +/- 58.71
Episode length: 332.60 +/- 38.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 333      |
|    mean_reward     | -134     |
| time/              |          |
|    total_timesteps | 788832   |
---------------------------------
Eval num_timesteps=790824, episode_reward=-132.31 +/- 33.84
Episode length: 309.20 +/- 35.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 309      |
|    mean_reward     | -132     |
| time/              |          |
|    total_timesteps | 790824   |
---------------------------------
Eval num_timesteps=792816, episode_reward=-60.24 +/- 117.48
Episode length: 312.00 +/- 83.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 312      |
|    mean_reward     | -60.2    |
| time/              |          |
|    total_timesteps | 792816   |
---------------------------------
Eval num_timesteps=794808, episode_reward=-36.39 +/- 239.35
Episode length: 346.60 +/- 68.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 347      |
|    mean_reward     | -36.4    |
| time/              |          |
|    total_timesteps | 794808   |
---------------------------------
New best mean reward!
Eval num_timesteps=796800, episode_reward=-58.68 +/- 74.75
Episode length: 336.60 +/- 48.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 337      |
|    mean_reward     | -58.7    |
| time/              |          |
|    total_timesteps | 796800   |
---------------------------------
Eval num_timesteps=798792, episode_reward=-93.22 +/- 90.51
Episode length: 306.40 +/- 58.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 306      |
|    mean_reward     | -93.2    |
| time/              |          |
|    total_timesteps | 798792   |
---------------------------------
Eval num_timesteps=800784, episode_reward=-59.46 +/- 40.91
Episode length: 345.40 +/- 38.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 345      |
|    mean_reward     | -59.5    |
| time/              |          |
|    total_timesteps | 800784   |
---------------------------------
Eval num_timesteps=802776, episode_reward=-22.27 +/- 133.97
Episode length: 349.40 +/- 52.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 349      |
|    mean_reward     | -22.3    |
| time/              |          |
|    total_timesteps | 802776   |
---------------------------------
New best mean reward!
Eval num_timesteps=804768, episode_reward=-150.26 +/- 39.98
Episode length: 285.60 +/- 37.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 286      |
|    mean_reward     | -150     |
| time/              |          |
|    total_timesteps | 804768   |
---------------------------------
Eval num_timesteps=806760, episode_reward=-102.38 +/- 74.28
Episode length: 311.00 +/- 48.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 311      |
|    mean_reward     | -102     |
| time/              |          |
|    total_timesteps | 806760   |
---------------------------------
Eval num_timesteps=808752, episode_reward=-27.11 +/- 152.88
Episode length: 394.40 +/- 53.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 394      |
|    mean_reward     | -27.1    |
| time/              |          |
|    total_timesteps | 808752   |
---------------------------------
Eval num_timesteps=810744, episode_reward=55.99 +/- 108.99
Episode length: 372.00 +/- 62.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 372      |
|    mean_reward     | 56       |
| time/              |          |
|    total_timesteps | 810744   |
---------------------------------
New best mean reward!
Eval num_timesteps=812736, episode_reward=-99.94 +/- 107.81
Episode length: 356.60 +/- 92.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 357      |
|    mean_reward     | -99.9    |
| time/              |          |
|    total_timesteps | 812736   |
---------------------------------
Eval num_timesteps=814728, episode_reward=-75.20 +/- 147.68
Episode length: 328.20 +/- 68.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 328      |
|    mean_reward     | -75.2    |
| time/              |          |
|    total_timesteps | 814728   |
---------------------------------
Eval num_timesteps=816720, episode_reward=-218.01 +/- 26.80
Episode length: 248.20 +/- 33.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 248      |
|    mean_reward     | -218     |
| time/              |          |
|    total_timesteps | 816720   |
---------------------------------
Eval num_timesteps=818712, episode_reward=-21.69 +/- 89.64
Episode length: 355.60 +/- 80.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 356      |
|    mean_reward     | -21.7    |
| time/              |          |
|    total_timesteps | 818712   |
---------------------------------
Eval num_timesteps=820704, episode_reward=16.61 +/- 133.14
Episode length: 407.60 +/- 86.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | 16.6     |
| time/              |          |
|    total_timesteps | 820704   |
---------------------------------
Eval num_timesteps=822696, episode_reward=-69.26 +/- 117.21
Episode length: 317.00 +/- 84.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 317      |
|    mean_reward     | -69.3    |
| time/              |          |
|    total_timesteps | 822696   |
---------------------------------
Eval num_timesteps=824688, episode_reward=-94.03 +/- 57.85
Episode length: 349.60 +/- 86.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | -94      |
| time/              |          |
|    total_timesteps | 824688   |
---------------------------------
Eval num_timesteps=826680, episode_reward=-90.58 +/- 77.07
Episode length: 412.40 +/- 56.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 412      |
|    mean_reward     | -90.6    |
| time/              |          |
|    total_timesteps | 826680   |
---------------------------------
Eval num_timesteps=828672, episode_reward=-87.34 +/- 52.04
Episode length: 311.80 +/- 28.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 312      |
|    mean_reward     | -87.3    |
| time/              |          |
|    total_timesteps | 828672   |
---------------------------------
Eval num_timesteps=830664, episode_reward=130.00 +/- 192.17
Episode length: 438.60 +/- 53.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | 130      |
| time/              |          |
|    total_timesteps | 830664   |
---------------------------------
New best mean reward!
Eval num_timesteps=832656, episode_reward=-86.09 +/- 131.15
Episode length: 313.40 +/- 74.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 313      |
|    mean_reward     | -86.1    |
| time/              |          |
|    total_timesteps | 832656   |
---------------------------------
Eval num_timesteps=834648, episode_reward=-112.78 +/- 93.13
Episode length: 285.40 +/- 56.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 285      |
|    mean_reward     | -113     |
| time/              |          |
|    total_timesteps | 834648   |
---------------------------------
Eval num_timesteps=836640, episode_reward=164.99 +/- 255.57
Episode length: 445.80 +/- 74.34
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 446          |
|    mean_reward          | 165          |
| time/                   |              |
|    total_timesteps      | 836640       |
| train/                  |              |
|    approx_kl            | 0.0099605415 |
|    clip_fraction        | 0.118        |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.92        |
|    explained_variance   | 0.95         |
|    learning_rate        | 0.001        |
|    loss                 | 0.0606       |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00317     |
|    std                  | 1.07         |
|    value_loss           | 0.33         |
------------------------------------------
New best mean reward!
Eval num_timesteps=838632, episode_reward=-176.46 +/- 113.36
Episode length: 353.40 +/- 74.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 353      |
|    mean_reward     | -176     |
| time/              |          |
|    total_timesteps | 838632   |
---------------------------------
Eval num_timesteps=840624, episode_reward=11.58 +/- 214.80
Episode length: 413.20 +/- 96.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 413      |
|    mean_reward     | 11.6     |
| time/              |          |
|    total_timesteps | 840624   |
---------------------------------
Eval num_timesteps=842616, episode_reward=-17.28 +/- 141.40
Episode length: 438.60 +/- 77.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -17.3    |
| time/              |          |
|    total_timesteps | 842616   |
---------------------------------
Eval num_timesteps=844608, episode_reward=-75.81 +/- 100.15
Episode length: 390.40 +/- 39.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 390      |
|    mean_reward     | -75.8    |
| time/              |          |
|    total_timesteps | 844608   |
---------------------------------
Eval num_timesteps=846600, episode_reward=-108.66 +/- 201.79
Episode length: 348.60 +/- 62.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 349      |
|    mean_reward     | -109     |
| time/              |          |
|    total_timesteps | 846600   |
---------------------------------
Eval num_timesteps=848592, episode_reward=-142.79 +/- 97.81
Episode length: 391.20 +/- 31.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | -143     |
| time/              |          |
|    total_timesteps | 848592   |
---------------------------------
Eval num_timesteps=850584, episode_reward=-110.89 +/- 232.99
Episode length: 380.40 +/- 118.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | -111     |
| time/              |          |
|    total_timesteps | 850584   |
---------------------------------
Eval num_timesteps=852576, episode_reward=66.15 +/- 138.99
Episode length: 415.40 +/- 50.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | 66.2     |
| time/              |          |
|    total_timesteps | 852576   |
---------------------------------
Eval num_timesteps=854568, episode_reward=-153.23 +/- 88.62
Episode length: 365.40 +/- 57.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 365      |
|    mean_reward     | -153     |
| time/              |          |
|    total_timesteps | 854568   |
---------------------------------
Eval num_timesteps=856560, episode_reward=-47.53 +/- 166.03
Episode length: 454.00 +/- 76.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | -47.5    |
| time/              |          |
|    total_timesteps | 856560   |
---------------------------------
Eval num_timesteps=858552, episode_reward=17.58 +/- 256.63
Episode length: 438.80 +/- 85.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | 17.6     |
| time/              |          |
|    total_timesteps | 858552   |
---------------------------------
Eval num_timesteps=860544, episode_reward=33.43 +/- 151.96
Episode length: 394.80 +/- 42.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 395      |
|    mean_reward     | 33.4     |
| time/              |          |
|    total_timesteps | 860544   |
---------------------------------
Eval num_timesteps=862536, episode_reward=129.15 +/- 132.25
Episode length: 546.00 +/- 149.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 129      |
| time/              |          |
|    total_timesteps | 862536   |
---------------------------------
Eval num_timesteps=864528, episode_reward=-20.18 +/- 251.63
Episode length: 340.40 +/- 92.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 340      |
|    mean_reward     | -20.2    |
| time/              |          |
|    total_timesteps | 864528   |
---------------------------------
Eval num_timesteps=866520, episode_reward=181.27 +/- 317.10
Episode length: 479.20 +/- 67.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | 181      |
| time/              |          |
|    total_timesteps | 866520   |
---------------------------------
New best mean reward!
Eval num_timesteps=868512, episode_reward=-41.38 +/- 158.95
Episode length: 378.80 +/- 70.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 379      |
|    mean_reward     | -41.4    |
| time/              |          |
|    total_timesteps | 868512   |
---------------------------------
Eval num_timesteps=870504, episode_reward=-147.51 +/- 82.35
Episode length: 391.40 +/- 133.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | -148     |
| time/              |          |
|    total_timesteps | 870504   |
---------------------------------
Eval num_timesteps=872496, episode_reward=-82.12 +/- 86.08
Episode length: 375.40 +/- 31.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 375      |
|    mean_reward     | -82.1    |
| time/              |          |
|    total_timesteps | 872496   |
---------------------------------
Eval num_timesteps=874488, episode_reward=-20.02 +/- 187.68
Episode length: 409.60 +/- 48.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 410      |
|    mean_reward     | -20      |
| time/              |          |
|    total_timesteps | 874488   |
---------------------------------
Eval num_timesteps=876480, episode_reward=-75.96 +/- 189.88
Episode length: 380.40 +/- 71.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | -76      |
| time/              |          |
|    total_timesteps | 876480   |
---------------------------------
Eval num_timesteps=878472, episode_reward=105.64 +/- 339.22
Episode length: 435.20 +/- 168.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | 106      |
| time/              |          |
|    total_timesteps | 878472   |
---------------------------------
Eval num_timesteps=880464, episode_reward=-16.31 +/- 151.77
Episode length: 396.60 +/- 71.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 397      |
|    mean_reward     | -16.3    |
| time/              |          |
|    total_timesteps | 880464   |
---------------------------------
Eval num_timesteps=882456, episode_reward=-200.32 +/- 33.32
Episode length: 303.00 +/- 57.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 303      |
|    mean_reward     | -200     |
| time/              |          |
|    total_timesteps | 882456   |
---------------------------------
Eval num_timesteps=884448, episode_reward=-73.48 +/- 82.53
Episode length: 341.20 +/- 39.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 341      |
|    mean_reward     | -73.5    |
| time/              |          |
|    total_timesteps | 884448   |
---------------------------------
Eval num_timesteps=886440, episode_reward=-236.20 +/- 29.86
Episode length: 485.60 +/- 157.81
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 486         |
|    mean_reward          | -236        |
| time/                   |             |
|    total_timesteps      | 886440      |
| train/                  |             |
|    approx_kl            | 0.009795826 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.95       |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0641      |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00166    |
|    std                  | 1.07        |
|    value_loss           | 0.298       |
-----------------------------------------
Eval num_timesteps=888432, episode_reward=-117.54 +/- 281.72
Episode length: 513.60 +/- 201.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | -118     |
| time/              |          |
|    total_timesteps | 888432   |
---------------------------------
Eval num_timesteps=890424, episode_reward=76.38 +/- 389.10
Episode length: 674.00 +/- 139.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 674      |
|    mean_reward     | 76.4     |
| time/              |          |
|    total_timesteps | 890424   |
---------------------------------
Eval num_timesteps=892416, episode_reward=-91.55 +/- 211.98
Episode length: 465.40 +/- 138.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -91.6    |
| time/              |          |
|    total_timesteps | 892416   |
---------------------------------
Eval num_timesteps=894408, episode_reward=-257.56 +/- 27.67
Episode length: 355.00 +/- 59.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 355      |
|    mean_reward     | -258     |
| time/              |          |
|    total_timesteps | 894408   |
---------------------------------
Eval num_timesteps=896400, episode_reward=-194.88 +/- 134.02
Episode length: 586.40 +/- 117.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | -195     |
| time/              |          |
|    total_timesteps | 896400   |
---------------------------------
Eval num_timesteps=898392, episode_reward=-73.25 +/- 240.13
Episode length: 460.20 +/- 88.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | -73.3    |
| time/              |          |
|    total_timesteps | 898392   |
---------------------------------
Eval num_timesteps=900384, episode_reward=-76.36 +/- 272.50
Episode length: 490.80 +/- 159.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | -76.4    |
| time/              |          |
|    total_timesteps | 900384   |
---------------------------------
Eval num_timesteps=902376, episode_reward=-56.46 +/- 336.65
Episode length: 481.60 +/- 91.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | -56.5    |
| time/              |          |
|    total_timesteps | 902376   |
---------------------------------
Eval num_timesteps=904368, episode_reward=-256.52 +/- 35.98
Episode length: 383.60 +/- 101.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 384      |
|    mean_reward     | -257     |
| time/              |          |
|    total_timesteps | 904368   |
---------------------------------
Eval num_timesteps=906360, episode_reward=-35.83 +/- 286.06
Episode length: 512.80 +/- 122.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | -35.8    |
| time/              |          |
|    total_timesteps | 906360   |
---------------------------------
Eval num_timesteps=908352, episode_reward=-206.73 +/- 71.76
Episode length: 420.00 +/- 95.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 420      |
|    mean_reward     | -207     |
| time/              |          |
|    total_timesteps | 908352   |
---------------------------------
Eval num_timesteps=910344, episode_reward=-78.95 +/- 377.03
Episode length: 461.20 +/- 112.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -79      |
| time/              |          |
|    total_timesteps | 910344   |
---------------------------------
Eval num_timesteps=912336, episode_reward=-65.35 +/- 199.58
Episode length: 553.20 +/- 125.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | -65.4    |
| time/              |          |
|    total_timesteps | 912336   |
---------------------------------
Eval num_timesteps=914328, episode_reward=-102.31 +/- 177.26
Episode length: 475.00 +/- 78.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | -102     |
| time/              |          |
|    total_timesteps | 914328   |
---------------------------------
Eval num_timesteps=916320, episode_reward=-64.12 +/- 254.82
Episode length: 466.00 +/- 223.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -64.1    |
| time/              |          |
|    total_timesteps | 916320   |
---------------------------------
Eval num_timesteps=918312, episode_reward=-26.77 +/- 378.78
Episode length: 597.00 +/- 152.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | -26.8    |
| time/              |          |
|    total_timesteps | 918312   |
---------------------------------
Eval num_timesteps=920304, episode_reward=-171.76 +/- 139.51
Episode length: 448.80 +/- 86.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | -172     |
| time/              |          |
|    total_timesteps | 920304   |
---------------------------------
Eval num_timesteps=922296, episode_reward=-271.92 +/- 28.64
Episode length: 434.60 +/- 110.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 922296   |
---------------------------------
Eval num_timesteps=924288, episode_reward=-179.69 +/- 168.52
Episode length: 377.60 +/- 97.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | -180     |
| time/              |          |
|    total_timesteps | 924288   |
---------------------------------
Eval num_timesteps=926280, episode_reward=-39.50 +/- 278.49
Episode length: 508.40 +/- 125.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -39.5    |
| time/              |          |
|    total_timesteps | 926280   |
---------------------------------
Eval num_timesteps=928272, episode_reward=-209.31 +/- 95.17
Episode length: 406.40 +/- 120.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 406      |
|    mean_reward     | -209     |
| time/              |          |
|    total_timesteps | 928272   |
---------------------------------
Eval num_timesteps=930264, episode_reward=-138.56 +/- 231.14
Episode length: 480.00 +/- 114.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -139     |
| time/              |          |
|    total_timesteps | 930264   |
---------------------------------
Eval num_timesteps=932256, episode_reward=-244.35 +/- 50.57
Episode length: 424.20 +/- 55.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | -244     |
| time/              |          |
|    total_timesteps | 932256   |
---------------------------------
Eval num_timesteps=934248, episode_reward=-282.31 +/- 16.67
Episode length: 454.80 +/- 41.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 455         |
|    mean_reward          | -282        |
| time/                   |             |
|    total_timesteps      | 934248      |
| train/                  |             |
|    approx_kl            | 0.005626958 |
|    clip_fraction        | 0.0614      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.96       |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.001       |
|    loss                 | 0.126       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00268    |
|    std                  | 1.07        |
|    value_loss           | 0.456       |
-----------------------------------------
Eval num_timesteps=936240, episode_reward=-217.22 +/- 80.04
Episode length: 569.00 +/- 108.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | -217     |
| time/              |          |
|    total_timesteps | 936240   |
---------------------------------
Eval num_timesteps=938232, episode_reward=-290.46 +/- 18.81
Episode length: 373.00 +/- 80.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 373      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 938232   |
---------------------------------
Eval num_timesteps=940224, episode_reward=-301.24 +/- 12.51
Episode length: 471.80 +/- 89.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 940224   |
---------------------------------
Eval num_timesteps=942216, episode_reward=-272.54 +/- 15.76
Episode length: 470.00 +/- 81.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -273     |
| time/              |          |
|    total_timesteps | 942216   |
---------------------------------
Eval num_timesteps=944208, episode_reward=-263.70 +/- 37.33
Episode length: 420.60 +/- 105.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 421      |
|    mean_reward     | -264     |
| time/              |          |
|    total_timesteps | 944208   |
---------------------------------
Eval num_timesteps=946200, episode_reward=-235.54 +/- 35.18
Episode length: 549.20 +/- 99.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | -236     |
| time/              |          |
|    total_timesteps | 946200   |
---------------------------------
Eval num_timesteps=948192, episode_reward=-201.47 +/- 123.71
Episode length: 495.60 +/- 146.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | -201     |
| time/              |          |
|    total_timesteps | 948192   |
---------------------------------
Eval num_timesteps=950184, episode_reward=-281.43 +/- 16.84
Episode length: 532.40 +/- 62.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 950184   |
---------------------------------
Eval num_timesteps=952176, episode_reward=-270.71 +/- 22.37
Episode length: 477.20 +/- 108.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 952176   |
---------------------------------
Eval num_timesteps=954168, episode_reward=-228.13 +/- 122.04
Episode length: 487.20 +/- 97.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | -228     |
| time/              |          |
|    total_timesteps | 954168   |
---------------------------------
Eval num_timesteps=956160, episode_reward=-152.01 +/- 271.70
Episode length: 455.40 +/- 59.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -152     |
| time/              |          |
|    total_timesteps | 956160   |
---------------------------------
Eval num_timesteps=958152, episode_reward=-282.84 +/- 20.25
Episode length: 421.40 +/- 47.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 421      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 958152   |
---------------------------------
Eval num_timesteps=960144, episode_reward=-286.14 +/- 8.72
Episode length: 623.20 +/- 159.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 960144   |
---------------------------------
Eval num_timesteps=962136, episode_reward=-177.44 +/- 76.04
Episode length: 492.80 +/- 87.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -177     |
| time/              |          |
|    total_timesteps | 962136   |
---------------------------------
Eval num_timesteps=964128, episode_reward=-203.24 +/- 146.87
Episode length: 450.40 +/- 156.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | -203     |
| time/              |          |
|    total_timesteps | 964128   |
---------------------------------
Eval num_timesteps=966120, episode_reward=-266.93 +/- 38.43
Episode length: 531.40 +/- 96.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 966120   |
---------------------------------
Eval num_timesteps=968112, episode_reward=-272.48 +/- 37.98
Episode length: 551.60 +/- 145.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 968112   |
---------------------------------
Eval num_timesteps=970104, episode_reward=-290.73 +/- 12.53
Episode length: 391.20 +/- 55.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 970104   |
---------------------------------
Eval num_timesteps=972096, episode_reward=-294.37 +/- 5.53
Episode length: 416.00 +/- 34.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 972096   |
---------------------------------
Eval num_timesteps=974088, episode_reward=-261.04 +/- 35.10
Episode length: 474.80 +/- 28.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | -261     |
| time/              |          |
|    total_timesteps | 974088   |
---------------------------------
Eval num_timesteps=976080, episode_reward=-252.21 +/- 36.98
Episode length: 521.80 +/- 69.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 976080   |
---------------------------------
Eval num_timesteps=978072, episode_reward=-213.67 +/- 120.06
Episode length: 544.40 +/- 186.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | -214     |
| time/              |          |
|    total_timesteps | 978072   |
---------------------------------
Eval num_timesteps=980064, episode_reward=-283.17 +/- 9.56
Episode length: 470.20 +/- 82.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 980064   |
---------------------------------
Eval num_timesteps=982056, episode_reward=-265.36 +/- 42.72
Episode length: 489.40 +/- 5.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | -265     |
| time/              |          |
|    total_timesteps | 982056   |
---------------------------------
Eval num_timesteps=984048, episode_reward=-298.44 +/- 9.76
Episode length: 431.60 +/- 62.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 432          |
|    mean_reward          | -298         |
| time/                   |              |
|    total_timesteps      | 984048       |
| train/                  |              |
|    approx_kl            | 0.0053811213 |
|    clip_fraction        | 0.0802       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.97        |
|    explained_variance   | 0.921        |
|    learning_rate        | 0.001        |
|    loss                 | 0.121        |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.0024      |
|    std                  | 1.08         |
|    value_loss           | 0.429        |
------------------------------------------
Eval num_timesteps=986040, episode_reward=-293.42 +/- 7.94
Episode length: 407.20 +/- 61.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 407      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 986040   |
---------------------------------
Eval num_timesteps=988032, episode_reward=-306.70 +/- 6.64
Episode length: 369.40 +/- 57.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 369      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 988032   |
---------------------------------
Eval num_timesteps=990024, episode_reward=-284.44 +/- 7.51
Episode length: 414.60 +/- 35.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 990024   |
---------------------------------
Eval num_timesteps=992016, episode_reward=-300.68 +/- 10.71
Episode length: 394.80 +/- 23.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 395      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 992016   |
---------------------------------
Eval num_timesteps=994008, episode_reward=-298.75 +/- 11.47
Episode length: 401.40 +/- 51.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 994008   |
---------------------------------
Eval num_timesteps=996000, episode_reward=-285.90 +/- 10.93
Episode length: 464.80 +/- 36.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 996000   |
---------------------------------
Eval num_timesteps=997992, episode_reward=-296.68 +/- 11.17
Episode length: 415.20 +/- 43.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 997992   |
---------------------------------
Eval num_timesteps=999984, episode_reward=-294.92 +/- 16.91
Episode length: 434.60 +/- 39.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 999984   |
---------------------------------
Eval num_timesteps=1001976, episode_reward=-296.72 +/- 20.81
Episode length: 418.80 +/- 46.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 419      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1001976  |
---------------------------------
Eval num_timesteps=1003968, episode_reward=-286.78 +/- 5.62
Episode length: 468.40 +/- 30.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 468      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 1003968  |
---------------------------------
Eval num_timesteps=1005960, episode_reward=-289.82 +/- 16.87
Episode length: 442.40 +/- 33.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 1005960  |
---------------------------------
Eval num_timesteps=1007952, episode_reward=-305.30 +/- 7.16
Episode length: 419.20 +/- 30.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 419      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1007952  |
---------------------------------
Eval num_timesteps=1009944, episode_reward=-289.51 +/- 8.98
Episode length: 416.00 +/- 35.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 1009944  |
---------------------------------
Eval num_timesteps=1011936, episode_reward=-282.50 +/- 20.22
Episode length: 430.80 +/- 27.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 1011936  |
---------------------------------
Eval num_timesteps=1013928, episode_reward=-288.16 +/- 17.66
Episode length: 494.60 +/- 144.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 1013928  |
---------------------------------
Eval num_timesteps=1015920, episode_reward=-299.08 +/- 10.76
Episode length: 403.20 +/- 41.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 403      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1015920  |
---------------------------------
Eval num_timesteps=1017912, episode_reward=-302.20 +/- 13.87
Episode length: 424.00 +/- 50.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1017912  |
---------------------------------
Eval num_timesteps=1019904, episode_reward=-293.80 +/- 13.07
Episode length: 452.60 +/- 60.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 453      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 1019904  |
---------------------------------
Eval num_timesteps=1021896, episode_reward=-284.18 +/- 22.69
Episode length: 438.00 +/- 50.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 1021896  |
---------------------------------
Eval num_timesteps=1023888, episode_reward=-300.80 +/- 14.62
Episode length: 405.20 +/- 77.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 405      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1023888  |
---------------------------------
Eval num_timesteps=1025880, episode_reward=-294.15 +/- 6.37
Episode length: 422.80 +/- 68.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 423      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 1025880  |
---------------------------------
Eval num_timesteps=1027872, episode_reward=-291.63 +/- 10.64
Episode length: 355.60 +/- 82.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 356      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1027872  |
---------------------------------
Eval num_timesteps=1029864, episode_reward=-304.56 +/- 14.78
Episode length: 438.80 +/- 34.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1029864  |
---------------------------------
Eval num_timesteps=1031856, episode_reward=-295.72 +/- 12.64
Episode length: 389.40 +/- 84.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1031856  |
---------------------------------
Eval num_timesteps=1033848, episode_reward=-304.53 +/- 14.62
Episode length: 401.80 +/- 40.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 402         |
|    mean_reward          | -305        |
| time/                   |             |
|    total_timesteps      | 1033848     |
| train/                  |             |
|    approx_kl            | 0.004729745 |
|    clip_fraction        | 0.0691      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.001       |
|    loss                 | 0.147       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00142    |
|    std                  | 1.09        |
|    value_loss           | 0.513       |
-----------------------------------------
Eval num_timesteps=1035840, episode_reward=-292.45 +/- 22.03
Episode length: 438.60 +/- 71.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1035840  |
---------------------------------
Eval num_timesteps=1037832, episode_reward=-242.39 +/- 92.06
Episode length: 445.80 +/- 158.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -242     |
| time/              |          |
|    total_timesteps | 1037832  |
---------------------------------
Eval num_timesteps=1039824, episode_reward=-308.86 +/- 13.53
Episode length: 441.00 +/- 55.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 441      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1039824  |
---------------------------------
Eval num_timesteps=1041816, episode_reward=-282.15 +/- 33.34
Episode length: 432.60 +/- 54.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 1041816  |
---------------------------------
Eval num_timesteps=1043808, episode_reward=-293.29 +/- 12.23
Episode length: 465.80 +/- 60.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1043808  |
---------------------------------
Eval num_timesteps=1045800, episode_reward=-284.16 +/- 10.62
Episode length: 500.80 +/- 72.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 1045800  |
---------------------------------
Eval num_timesteps=1047792, episode_reward=-301.23 +/- 18.20
Episode length: 418.80 +/- 53.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 419      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1047792  |
---------------------------------
Eval num_timesteps=1049784, episode_reward=-274.12 +/- 23.60
Episode length: 508.00 +/- 100.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 1049784  |
---------------------------------
Eval num_timesteps=1051776, episode_reward=-285.59 +/- 16.79
Episode length: 446.40 +/- 30.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1051776  |
---------------------------------
Eval num_timesteps=1053768, episode_reward=-283.01 +/- 12.36
Episode length: 437.40 +/- 47.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 437      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 1053768  |
---------------------------------
Eval num_timesteps=1055760, episode_reward=-288.64 +/- 21.40
Episode length: 440.20 +/- 42.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 440      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 1055760  |
---------------------------------
Eval num_timesteps=1057752, episode_reward=-293.37 +/- 18.34
Episode length: 448.20 +/- 24.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1057752  |
---------------------------------
Eval num_timesteps=1059744, episode_reward=-287.42 +/- 34.86
Episode length: 417.20 +/- 33.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 1059744  |
---------------------------------
Eval num_timesteps=1061736, episode_reward=-315.11 +/- 6.95
Episode length: 444.60 +/- 63.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1061736  |
---------------------------------
Eval num_timesteps=1063728, episode_reward=-298.11 +/- 8.85
Episode length: 431.60 +/- 47.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1063728  |
---------------------------------
Eval num_timesteps=1065720, episode_reward=-293.01 +/- 9.94
Episode length: 459.20 +/- 56.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 459      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1065720  |
---------------------------------
Eval num_timesteps=1067712, episode_reward=-301.84 +/- 7.67
Episode length: 447.60 +/- 88.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1067712  |
---------------------------------
Eval num_timesteps=1069704, episode_reward=-297.30 +/- 6.15
Episode length: 421.20 +/- 18.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 421      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1069704  |
---------------------------------
Eval num_timesteps=1071696, episode_reward=-286.46 +/- 17.46
Episode length: 468.60 +/- 39.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 469      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1071696  |
---------------------------------
Eval num_timesteps=1073688, episode_reward=-278.00 +/- 37.94
Episode length: 477.80 +/- 139.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 1073688  |
---------------------------------
Eval num_timesteps=1075680, episode_reward=-298.47 +/- 7.69
Episode length: 471.40 +/- 50.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1075680  |
---------------------------------
Eval num_timesteps=1077672, episode_reward=-281.57 +/- 8.98
Episode length: 499.80 +/- 85.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 1077672  |
---------------------------------
Eval num_timesteps=1079664, episode_reward=-285.61 +/- 7.52
Episode length: 494.20 +/- 24.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1079664  |
---------------------------------
Eval num_timesteps=1081656, episode_reward=-254.30 +/- 36.09
Episode length: 493.60 +/- 45.08
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 494          |
|    mean_reward          | -254         |
| time/                   |              |
|    total_timesteps      | 1081656      |
| train/                  |              |
|    approx_kl            | 0.0070138453 |
|    clip_fraction        | 0.0651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.01        |
|    explained_variance   | 0.95         |
|    learning_rate        | 0.001        |
|    loss                 | 0.0583       |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.0017      |
|    std                  | 1.09         |
|    value_loss           | 0.337        |
------------------------------------------
Eval num_timesteps=1083648, episode_reward=-276.94 +/- 24.36
Episode length: 493.00 +/- 64.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -277     |
| time/              |          |
|    total_timesteps | 1083648  |
---------------------------------
Eval num_timesteps=1085640, episode_reward=-254.17 +/- 96.24
Episode length: 515.20 +/- 146.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 1085640  |
---------------------------------
Eval num_timesteps=1087632, episode_reward=47.53 +/- 635.51
Episode length: 567.20 +/- 122.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 47.5     |
| time/              |          |
|    total_timesteps | 1087632  |
---------------------------------
Eval num_timesteps=1089624, episode_reward=-288.67 +/- 33.41
Episode length: 521.00 +/- 191.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 1089624  |
---------------------------------
Eval num_timesteps=1091616, episode_reward=-291.79 +/- 12.02
Episode length: 443.00 +/- 57.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1091616  |
---------------------------------
Eval num_timesteps=1093608, episode_reward=-285.56 +/- 14.56
Episode length: 468.00 +/- 48.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 468      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1093608  |
---------------------------------
Eval num_timesteps=1095600, episode_reward=-285.38 +/- 10.42
Episode length: 462.60 +/- 30.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1095600  |
---------------------------------
Eval num_timesteps=1097592, episode_reward=-280.42 +/- 14.49
Episode length: 481.00 +/- 36.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 1097592  |
---------------------------------
Eval num_timesteps=1099584, episode_reward=-143.18 +/- 130.22
Episode length: 505.40 +/- 41.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -143     |
| time/              |          |
|    total_timesteps | 1099584  |
---------------------------------
Eval num_timesteps=1101576, episode_reward=-195.04 +/- 134.00
Episode length: 602.20 +/- 180.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | -195     |
| time/              |          |
|    total_timesteps | 1101576  |
---------------------------------
Eval num_timesteps=1103568, episode_reward=-254.92 +/- 19.55
Episode length: 539.40 +/- 66.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | -255     |
| time/              |          |
|    total_timesteps | 1103568  |
---------------------------------
Eval num_timesteps=1105560, episode_reward=-274.25 +/- 25.86
Episode length: 472.00 +/- 43.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 1105560  |
---------------------------------
Eval num_timesteps=1107552, episode_reward=-227.94 +/- 65.57
Episode length: 524.00 +/- 45.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | -228     |
| time/              |          |
|    total_timesteps | 1107552  |
---------------------------------
Eval num_timesteps=1109544, episode_reward=-298.62 +/- 10.87
Episode length: 462.80 +/- 31.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1109544  |
---------------------------------
Eval num_timesteps=1111536, episode_reward=-276.03 +/- 26.68
Episode length: 486.40 +/- 40.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 1111536  |
---------------------------------
Eval num_timesteps=1113528, episode_reward=-268.99 +/- 47.25
Episode length: 447.80 +/- 76.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 1113528  |
---------------------------------
Eval num_timesteps=1115520, episode_reward=-278.16 +/- 9.69
Episode length: 479.20 +/- 50.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 1115520  |
---------------------------------
Eval num_timesteps=1117512, episode_reward=-253.76 +/- 39.45
Episode length: 510.80 +/- 48.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 1117512  |
---------------------------------
Eval num_timesteps=1119504, episode_reward=-252.26 +/- 71.39
Episode length: 427.80 +/- 77.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1119504  |
---------------------------------
Eval num_timesteps=1121496, episode_reward=-295.50 +/- 11.04
Episode length: 479.40 +/- 56.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1121496  |
---------------------------------
Eval num_timesteps=1123488, episode_reward=-277.94 +/- 17.56
Episode length: 479.60 +/- 28.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 1123488  |
---------------------------------
Eval num_timesteps=1125480, episode_reward=-272.84 +/- 27.75
Episode length: 456.00 +/- 54.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | -273     |
| time/              |          |
|    total_timesteps | 1125480  |
---------------------------------
Eval num_timesteps=1127472, episode_reward=-264.75 +/- 23.05
Episode length: 490.40 +/- 23.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | -265     |
| time/              |          |
|    total_timesteps | 1127472  |
---------------------------------
Eval num_timesteps=1129464, episode_reward=-280.06 +/- 15.05
Episode length: 486.00 +/- 51.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 1129464  |
---------------------------------
Eval num_timesteps=1131456, episode_reward=-202.26 +/- 121.99
Episode length: 553.00 +/- 50.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 553          |
|    mean_reward          | -202         |
| time/                   |              |
|    total_timesteps      | 1131456      |
| train/                  |              |
|    approx_kl            | 0.0046712547 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.02        |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0507       |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00121     |
|    std                  | 1.09         |
|    value_loss           | 0.314        |
------------------------------------------
Eval num_timesteps=1133448, episode_reward=-249.46 +/- 61.40
Episode length: 522.80 +/- 79.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | -249     |
| time/              |          |
|    total_timesteps | 1133448  |
---------------------------------
Eval num_timesteps=1135440, episode_reward=-253.95 +/- 27.28
Episode length: 479.80 +/- 56.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 1135440  |
---------------------------------
Eval num_timesteps=1137432, episode_reward=-251.62 +/- 85.59
Episode length: 446.20 +/- 46.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1137432  |
---------------------------------
Eval num_timesteps=1139424, episode_reward=-261.34 +/- 33.51
Episode length: 493.20 +/- 59.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -261     |
| time/              |          |
|    total_timesteps | 1139424  |
---------------------------------
Eval num_timesteps=1141416, episode_reward=-221.68 +/- 101.08
Episode length: 472.80 +/- 54.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | -222     |
| time/              |          |
|    total_timesteps | 1141416  |
---------------------------------
Eval num_timesteps=1143408, episode_reward=-276.50 +/- 23.42
Episode length: 490.60 +/- 32.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 1143408  |
---------------------------------
Eval num_timesteps=1145400, episode_reward=-213.69 +/- 105.67
Episode length: 573.40 +/- 75.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | -214     |
| time/              |          |
|    total_timesteps | 1145400  |
---------------------------------
Eval num_timesteps=1147392, episode_reward=-36.46 +/- 402.36
Episode length: 460.80 +/- 35.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -36.5    |
| time/              |          |
|    total_timesteps | 1147392  |
---------------------------------
Eval num_timesteps=1149384, episode_reward=-36.80 +/- 329.78
Episode length: 521.00 +/- 42.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | -36.8    |
| time/              |          |
|    total_timesteps | 1149384  |
---------------------------------
Eval num_timesteps=1151376, episode_reward=-77.58 +/- 324.71
Episode length: 576.80 +/- 67.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | -77.6    |
| time/              |          |
|    total_timesteps | 1151376  |
---------------------------------
Eval num_timesteps=1153368, episode_reward=-262.23 +/- 16.50
Episode length: 508.20 +/- 44.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -262     |
| time/              |          |
|    total_timesteps | 1153368  |
---------------------------------
Eval num_timesteps=1155360, episode_reward=-218.04 +/- 67.16
Episode length: 491.60 +/- 46.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | -218     |
| time/              |          |
|    total_timesteps | 1155360  |
---------------------------------
Eval num_timesteps=1157352, episode_reward=-232.91 +/- 34.36
Episode length: 509.00 +/- 35.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | -233     |
| time/              |          |
|    total_timesteps | 1157352  |
---------------------------------
Eval num_timesteps=1159344, episode_reward=-241.80 +/- 89.08
Episode length: 507.60 +/- 60.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -242     |
| time/              |          |
|    total_timesteps | 1159344  |
---------------------------------
Eval num_timesteps=1161336, episode_reward=-251.35 +/- 60.36
Episode length: 496.20 +/- 58.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 1161336  |
---------------------------------
Eval num_timesteps=1163328, episode_reward=39.23 +/- 341.71
Episode length: 486.60 +/- 31.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | 39.2     |
| time/              |          |
|    total_timesteps | 1163328  |
---------------------------------
Eval num_timesteps=1165320, episode_reward=-195.80 +/- 82.22
Episode length: 508.20 +/- 42.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -196     |
| time/              |          |
|    total_timesteps | 1165320  |
---------------------------------
Eval num_timesteps=1167312, episode_reward=-219.52 +/- 109.34
Episode length: 462.20 +/- 57.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 462      |
|    mean_reward     | -220     |
| time/              |          |
|    total_timesteps | 1167312  |
---------------------------------
Eval num_timesteps=1169304, episode_reward=-208.64 +/- 130.02
Episode length: 502.60 +/- 29.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | -209     |
| time/              |          |
|    total_timesteps | 1169304  |
---------------------------------
Eval num_timesteps=1171296, episode_reward=-119.68 +/- 242.82
Episode length: 536.20 +/- 46.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | -120     |
| time/              |          |
|    total_timesteps | 1171296  |
---------------------------------
Eval num_timesteps=1173288, episode_reward=-155.00 +/- 158.30
Episode length: 482.20 +/- 44.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | -155     |
| time/              |          |
|    total_timesteps | 1173288  |
---------------------------------
Eval num_timesteps=1175280, episode_reward=-246.89 +/- 48.32
Episode length: 552.40 +/- 99.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -247     |
| time/              |          |
|    total_timesteps | 1175280  |
---------------------------------
Eval num_timesteps=1177272, episode_reward=-254.26 +/- 30.72
Episode length: 500.80 +/- 62.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 1177272  |
---------------------------------
Eval num_timesteps=1179264, episode_reward=-225.27 +/- 63.78
Episode length: 523.20 +/- 53.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | -225     |
| time/              |          |
|    total_timesteps | 1179264  |
---------------------------------
Eval num_timesteps=1181256, episode_reward=113.88 +/- 436.05
Episode length: 561.20 +/- 54.46
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 561          |
|    mean_reward          | 114          |
| time/                   |              |
|    total_timesteps      | 1181256      |
| train/                  |              |
|    approx_kl            | 0.0066135055 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.03        |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.001        |
|    loss                 | 0.0524       |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00253     |
|    std                  | 1.09         |
|    value_loss           | 0.285        |
------------------------------------------
Eval num_timesteps=1183248, episode_reward=-210.54 +/- 62.74
Episode length: 591.60 +/- 98.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | -211     |
| time/              |          |
|    total_timesteps | 1183248  |
---------------------------------
Eval num_timesteps=1185240, episode_reward=-21.40 +/- 293.53
Episode length: 591.60 +/- 82.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | -21.4    |
| time/              |          |
|    total_timesteps | 1185240  |
---------------------------------
Eval num_timesteps=1187232, episode_reward=-85.09 +/- 256.34
Episode length: 603.20 +/- 150.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | -85.1    |
| time/              |          |
|    total_timesteps | 1187232  |
---------------------------------
Eval num_timesteps=1189224, episode_reward=-121.95 +/- 167.88
Episode length: 544.40 +/- 15.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | -122     |
| time/              |          |
|    total_timesteps | 1189224  |
---------------------------------
Eval num_timesteps=1191216, episode_reward=92.82 +/- 346.13
Episode length: 465.80 +/- 72.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 92.8     |
| time/              |          |
|    total_timesteps | 1191216  |
---------------------------------
Eval num_timesteps=1193208, episode_reward=-89.23 +/- 89.04
Episode length: 552.60 +/- 93.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | -89.2    |
| time/              |          |
|    total_timesteps | 1193208  |
---------------------------------
Eval num_timesteps=1195200, episode_reward=-24.46 +/- 376.78
Episode length: 559.20 +/- 37.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | -24.5    |
| time/              |          |
|    total_timesteps | 1195200  |
---------------------------------
Eval num_timesteps=1197192, episode_reward=238.33 +/- 350.55
Episode length: 559.20 +/- 77.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 238      |
| time/              |          |
|    total_timesteps | 1197192  |
---------------------------------
New best mean reward!
Eval num_timesteps=1199184, episode_reward=-219.94 +/- 86.83
Episode length: 587.80 +/- 32.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | -220     |
| time/              |          |
|    total_timesteps | 1199184  |
---------------------------------
Eval num_timesteps=1201176, episode_reward=-48.07 +/- 145.73
Episode length: 542.40 +/- 76.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | -48.1    |
| time/              |          |
|    total_timesteps | 1201176  |
---------------------------------
Eval num_timesteps=1203168, episode_reward=98.98 +/- 416.35
Episode length: 597.20 +/- 49.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | 99       |
| time/              |          |
|    total_timesteps | 1203168  |
---------------------------------
Eval num_timesteps=1205160, episode_reward=-126.08 +/- 118.24
Episode length: 542.20 +/- 52.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | -126     |
| time/              |          |
|    total_timesteps | 1205160  |
---------------------------------
Eval num_timesteps=1207152, episode_reward=-273.20 +/- 23.65
Episode length: 550.00 +/- 86.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | -273     |
| time/              |          |
|    total_timesteps | 1207152  |
---------------------------------
Eval num_timesteps=1209144, episode_reward=-26.72 +/- 228.36
Episode length: 585.80 +/- 77.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | -26.7    |
| time/              |          |
|    total_timesteps | 1209144  |
---------------------------------
Eval num_timesteps=1211136, episode_reward=38.67 +/- 285.02
Episode length: 570.00 +/- 51.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 38.7     |
| time/              |          |
|    total_timesteps | 1211136  |
---------------------------------
Eval num_timesteps=1213128, episode_reward=-150.96 +/- 114.91
Episode length: 558.20 +/- 31.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | -151     |
| time/              |          |
|    total_timesteps | 1213128  |
---------------------------------
Eval num_timesteps=1215120, episode_reward=-112.47 +/- 130.74
Episode length: 566.00 +/- 70.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | -112     |
| time/              |          |
|    total_timesteps | 1215120  |
---------------------------------
Eval num_timesteps=1217112, episode_reward=-88.07 +/- 182.84
Episode length: 551.20 +/- 34.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | -88.1    |
| time/              |          |
|    total_timesteps | 1217112  |
---------------------------------
Eval num_timesteps=1219104, episode_reward=98.86 +/- 394.02
Episode length: 642.00 +/- 68.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 642      |
|    mean_reward     | 98.9     |
| time/              |          |
|    total_timesteps | 1219104  |
---------------------------------
Eval num_timesteps=1221096, episode_reward=-73.55 +/- 155.26
Episode length: 608.40 +/- 73.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | -73.5    |
| time/              |          |
|    total_timesteps | 1221096  |
---------------------------------
Eval num_timesteps=1223088, episode_reward=-65.76 +/- 143.48
Episode length: 581.40 +/- 93.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | -65.8    |
| time/              |          |
|    total_timesteps | 1223088  |
---------------------------------
Eval num_timesteps=1225080, episode_reward=101.14 +/- 375.83
Episode length: 568.20 +/- 102.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 101      |
| time/              |          |
|    total_timesteps | 1225080  |
---------------------------------
Eval num_timesteps=1227072, episode_reward=-17.06 +/- 204.94
Episode length: 589.00 +/- 72.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | -17.1    |
| time/              |          |
|    total_timesteps | 1227072  |
---------------------------------
Eval num_timesteps=1229064, episode_reward=-27.62 +/- 273.65
Episode length: 597.60 +/- 165.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 598         |
|    mean_reward          | -27.6       |
| time/                   |             |
|    total_timesteps      | 1229064     |
| train/                  |             |
|    approx_kl            | 0.006749723 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.001       |
|    loss                 | 0.172       |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00206    |
|    std                  | 1.1         |
|    value_loss           | 0.524       |
-----------------------------------------
Eval num_timesteps=1231056, episode_reward=-176.66 +/- 69.79
Episode length: 591.80 +/- 87.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | -177     |
| time/              |          |
|    total_timesteps | 1231056  |
---------------------------------
Eval num_timesteps=1233048, episode_reward=26.13 +/- 274.14
Episode length: 641.80 +/- 64.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 642      |
|    mean_reward     | 26.1     |
| time/              |          |
|    total_timesteps | 1233048  |
---------------------------------
Eval num_timesteps=1235040, episode_reward=-197.38 +/- 41.21
Episode length: 548.00 +/- 64.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | -197     |
| time/              |          |
|    total_timesteps | 1235040  |
---------------------------------
Eval num_timesteps=1237032, episode_reward=33.24 +/- 379.25
Episode length: 591.00 +/- 180.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 33.2     |
| time/              |          |
|    total_timesteps | 1237032  |
---------------------------------
Eval num_timesteps=1239024, episode_reward=-22.11 +/- 278.35
Episode length: 584.80 +/- 87.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | -22.1    |
| time/              |          |
|    total_timesteps | 1239024  |
---------------------------------
Eval num_timesteps=1241016, episode_reward=67.75 +/- 381.37
Episode length: 570.80 +/- 79.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 67.8     |
| time/              |          |
|    total_timesteps | 1241016  |
---------------------------------
Eval num_timesteps=1243008, episode_reward=-75.66 +/- 149.29
Episode length: 587.80 +/- 49.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | -75.7    |
| time/              |          |
|    total_timesteps | 1243008  |
---------------------------------
Eval num_timesteps=1245000, episode_reward=-29.66 +/- 272.99
Episode length: 650.40 +/- 136.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 650      |
|    mean_reward     | -29.7    |
| time/              |          |
|    total_timesteps | 1245000  |
---------------------------------
Eval num_timesteps=1246992, episode_reward=79.38 +/- 358.39
Episode length: 549.60 +/- 79.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 79.4     |
| time/              |          |
|    total_timesteps | 1246992  |
---------------------------------
Eval num_timesteps=1248984, episode_reward=4.52 +/- 303.04
Episode length: 566.00 +/- 92.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 4.52     |
| time/              |          |
|    total_timesteps | 1248984  |
---------------------------------
Eval num_timesteps=1250976, episode_reward=-130.99 +/- 168.36
Episode length: 605.60 +/- 98.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | -131     |
| time/              |          |
|    total_timesteps | 1250976  |
---------------------------------
Eval num_timesteps=1252968, episode_reward=151.36 +/- 194.80
Episode length: 627.20 +/- 68.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 151      |
| time/              |          |
|    total_timesteps | 1252968  |
---------------------------------
Eval num_timesteps=1254960, episode_reward=37.46 +/- 302.84
Episode length: 645.80 +/- 116.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 646      |
|    mean_reward     | 37.5     |
| time/              |          |
|    total_timesteps | 1254960  |
---------------------------------
Eval num_timesteps=1256952, episode_reward=-128.91 +/- 132.72
Episode length: 595.40 +/- 108.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | -129     |
| time/              |          |
|    total_timesteps | 1256952  |
---------------------------------
Eval num_timesteps=1258944, episode_reward=-176.95 +/- 126.63
Episode length: 694.80 +/- 144.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 695      |
|    mean_reward     | -177     |
| time/              |          |
|    total_timesteps | 1258944  |
---------------------------------
Eval num_timesteps=1260936, episode_reward=-180.56 +/- 72.41
Episode length: 549.60 +/- 103.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | -181     |
| time/              |          |
|    total_timesteps | 1260936  |
---------------------------------
Eval num_timesteps=1262928, episode_reward=-94.08 +/- 313.73
Episode length: 588.20 +/- 75.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | -94.1    |
| time/              |          |
|    total_timesteps | 1262928  |
---------------------------------
Eval num_timesteps=1264920, episode_reward=43.10 +/- 352.16
Episode length: 593.00 +/- 55.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 593      |
|    mean_reward     | 43.1     |
| time/              |          |
|    total_timesteps | 1264920  |
---------------------------------
Eval num_timesteps=1266912, episode_reward=-146.29 +/- 157.36
Episode length: 588.60 +/- 89.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | -146     |
| time/              |          |
|    total_timesteps | 1266912  |
---------------------------------
Eval num_timesteps=1268904, episode_reward=120.16 +/- 217.73
Episode length: 638.60 +/- 99.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 120      |
| time/              |          |
|    total_timesteps | 1268904  |
---------------------------------
Eval num_timesteps=1270896, episode_reward=129.79 +/- 251.82
Episode length: 651.00 +/- 113.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 651      |
|    mean_reward     | 130      |
| time/              |          |
|    total_timesteps | 1270896  |
---------------------------------
Eval num_timesteps=1272888, episode_reward=-133.71 +/- 172.58
Episode length: 659.20 +/- 89.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 659      |
|    mean_reward     | -134     |
| time/              |          |
|    total_timesteps | 1272888  |
---------------------------------
Eval num_timesteps=1274880, episode_reward=-176.34 +/- 90.72
Episode length: 682.40 +/- 106.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 682      |
|    mean_reward     | -176     |
| time/              |          |
|    total_timesteps | 1274880  |
---------------------------------
Eval num_timesteps=1276872, episode_reward=210.02 +/- 421.84
Episode length: 594.40 +/- 95.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 210      |
| time/              |          |
|    total_timesteps | 1276872  |
---------------------------------
Eval num_timesteps=1278864, episode_reward=-298.07 +/- 11.43
Episode length: 516.60 +/- 98.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 517          |
|    mean_reward          | -298         |
| time/                   |              |
|    total_timesteps      | 1278864      |
| train/                  |              |
|    approx_kl            | 0.0072461455 |
|    clip_fraction        | 0.0731       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.05        |
|    explained_variance   | 0.907        |
|    learning_rate        | 0.001        |
|    loss                 | 0.181        |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00206     |
|    std                  | 1.1          |
|    value_loss           | 0.589        |
------------------------------------------
Eval num_timesteps=1280856, episode_reward=-298.51 +/- 20.64
Episode length: 534.20 +/- 66.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1280856  |
---------------------------------
Eval num_timesteps=1282848, episode_reward=-246.77 +/- 52.10
Episode length: 497.60 +/- 64.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | -247     |
| time/              |          |
|    total_timesteps | 1282848  |
---------------------------------
Eval num_timesteps=1284840, episode_reward=-291.01 +/- 30.28
Episode length: 612.00 +/- 263.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1284840  |
---------------------------------
Eval num_timesteps=1286832, episode_reward=-299.33 +/- 19.75
Episode length: 620.20 +/- 125.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1286832  |
---------------------------------
Eval num_timesteps=1288824, episode_reward=-281.03 +/- 21.10
Episode length: 532.80 +/- 55.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 1288824  |
---------------------------------
Eval num_timesteps=1290816, episode_reward=-279.66 +/- 22.73
Episode length: 651.40 +/- 140.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 651      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 1290816  |
---------------------------------
Eval num_timesteps=1292808, episode_reward=-299.61 +/- 25.76
Episode length: 554.60 +/- 80.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 1292808  |
---------------------------------
Eval num_timesteps=1294800, episode_reward=-273.59 +/- 29.25
Episode length: 509.00 +/- 65.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 1294800  |
---------------------------------
Eval num_timesteps=1296792, episode_reward=-277.47 +/- 16.34
Episode length: 483.00 +/- 79.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | -277     |
| time/              |          |
|    total_timesteps | 1296792  |
---------------------------------
Eval num_timesteps=1298784, episode_reward=-252.06 +/- 35.83
Episode length: 476.20 +/- 73.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1298784  |
---------------------------------
Eval num_timesteps=1300776, episode_reward=-290.63 +/- 18.29
Episode length: 497.80 +/- 26.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1300776  |
---------------------------------
Eval num_timesteps=1302768, episode_reward=-292.99 +/- 22.89
Episode length: 511.00 +/- 26.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1302768  |
---------------------------------
Eval num_timesteps=1304760, episode_reward=-274.35 +/- 36.09
Episode length: 509.00 +/- 16.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 1304760  |
---------------------------------
Eval num_timesteps=1306752, episode_reward=-313.59 +/- 18.77
Episode length: 479.20 +/- 80.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1306752  |
---------------------------------
Eval num_timesteps=1308744, episode_reward=-278.64 +/- 37.42
Episode length: 528.20 +/- 88.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 1308744  |
---------------------------------
Eval num_timesteps=1310736, episode_reward=-305.80 +/- 14.44
Episode length: 517.40 +/- 58.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 517      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1310736  |
---------------------------------
Eval num_timesteps=1312728, episode_reward=-297.08 +/- 18.91
Episode length: 586.60 +/- 52.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1312728  |
---------------------------------
Eval num_timesteps=1314720, episode_reward=-268.80 +/- 41.51
Episode length: 498.40 +/- 85.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 1314720  |
---------------------------------
Eval num_timesteps=1316712, episode_reward=-288.83 +/- 18.86
Episode length: 479.40 +/- 77.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 1316712  |
---------------------------------
Eval num_timesteps=1318704, episode_reward=-293.03 +/- 25.01
Episode length: 524.20 +/- 29.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1318704  |
---------------------------------
Eval num_timesteps=1320696, episode_reward=-276.70 +/- 34.70
Episode length: 531.60 +/- 67.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | -277     |
| time/              |          |
|    total_timesteps | 1320696  |
---------------------------------
Eval num_timesteps=1322688, episode_reward=-285.47 +/- 21.80
Episode length: 539.80 +/- 46.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1322688  |
---------------------------------
Eval num_timesteps=1324680, episode_reward=-278.60 +/- 13.61
Episode length: 460.60 +/- 46.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 1324680  |
---------------------------------
Eval num_timesteps=1326672, episode_reward=-304.08 +/- 37.35
Episode length: 506.60 +/- 27.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1326672  |
---------------------------------
Eval num_timesteps=1328664, episode_reward=-287.29 +/- 9.68
Episode length: 415.60 +/- 38.39
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 416          |
|    mean_reward          | -287         |
| time/                   |              |
|    total_timesteps      | 1328664      |
| train/                  |              |
|    approx_kl            | 0.0059475703 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.07        |
|    explained_variance   | 0.852        |
|    learning_rate        | 0.001        |
|    loss                 | 0.284        |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.000531    |
|    std                  | 1.11         |
|    value_loss           | 0.669        |
------------------------------------------
Eval num_timesteps=1330656, episode_reward=-283.40 +/- 17.13
Episode length: 438.20 +/- 45.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 1330656  |
---------------------------------
Eval num_timesteps=1332648, episode_reward=-292.55 +/- 7.67
Episode length: 477.40 +/- 43.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1332648  |
---------------------------------
Eval num_timesteps=1334640, episode_reward=-285.68 +/- 29.33
Episode length: 487.20 +/- 116.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1334640  |
---------------------------------
Eval num_timesteps=1336632, episode_reward=-268.02 +/- 20.28
Episode length: 449.00 +/- 47.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | -268     |
| time/              |          |
|    total_timesteps | 1336632  |
---------------------------------
Eval num_timesteps=1338624, episode_reward=-281.08 +/- 13.41
Episode length: 429.60 +/- 34.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 430      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 1338624  |
---------------------------------
Eval num_timesteps=1340616, episode_reward=-279.13 +/- 17.01
Episode length: 444.20 +/- 56.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -279     |
| time/              |          |
|    total_timesteps | 1340616  |
---------------------------------
Eval num_timesteps=1342608, episode_reward=-284.18 +/- 18.20
Episode length: 436.40 +/- 9.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 1342608  |
---------------------------------
Eval num_timesteps=1344600, episode_reward=-266.81 +/- 21.02
Episode length: 432.80 +/- 39.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 1344600  |
---------------------------------
Eval num_timesteps=1346592, episode_reward=-291.18 +/- 31.49
Episode length: 451.40 +/- 29.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1346592  |
---------------------------------
Eval num_timesteps=1348584, episode_reward=-251.60 +/- 34.31
Episode length: 507.40 +/- 80.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1348584  |
---------------------------------
Eval num_timesteps=1350576, episode_reward=-272.17 +/- 17.32
Episode length: 446.40 +/- 39.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 1350576  |
---------------------------------
Eval num_timesteps=1352568, episode_reward=-291.17 +/- 10.35
Episode length: 444.60 +/- 49.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1352568  |
---------------------------------
Eval num_timesteps=1354560, episode_reward=-278.02 +/- 20.56
Episode length: 440.00 +/- 24.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 440      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 1354560  |
---------------------------------
Eval num_timesteps=1356552, episode_reward=-286.34 +/- 6.29
Episode length: 405.80 +/- 15.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 406      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1356552  |
---------------------------------
Eval num_timesteps=1358544, episode_reward=-265.72 +/- 22.36
Episode length: 432.60 +/- 59.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 1358544  |
---------------------------------
Eval num_timesteps=1360536, episode_reward=-292.75 +/- 12.03
Episode length: 419.20 +/- 45.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 419      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1360536  |
---------------------------------
Eval num_timesteps=1362528, episode_reward=-251.68 +/- 30.04
Episode length: 461.40 +/- 69.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1362528  |
---------------------------------
Eval num_timesteps=1364520, episode_reward=-291.21 +/- 22.12
Episode length: 436.40 +/- 33.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1364520  |
---------------------------------
Eval num_timesteps=1366512, episode_reward=-275.83 +/- 14.16
Episode length: 438.20 +/- 41.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 1366512  |
---------------------------------
Eval num_timesteps=1368504, episode_reward=-285.79 +/- 18.22
Episode length: 465.00 +/- 52.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1368504  |
---------------------------------
Eval num_timesteps=1370496, episode_reward=-312.12 +/- 4.33
Episode length: 442.20 +/- 52.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1370496  |
---------------------------------
Eval num_timesteps=1372488, episode_reward=-294.84 +/- 10.64
Episode length: 432.20 +/- 47.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1372488  |
---------------------------------
Eval num_timesteps=1374480, episode_reward=-288.09 +/- 19.25
Episode length: 477.20 +/- 46.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 1374480  |
---------------------------------
Eval num_timesteps=1376472, episode_reward=-317.78 +/- 12.11
Episode length: 396.40 +/- 18.05
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 396          |
|    mean_reward          | -318         |
| time/                   |              |
|    total_timesteps      | 1376472      |
| train/                  |              |
|    approx_kl            | 0.0061128745 |
|    clip_fraction        | 0.0694       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.09        |
|    explained_variance   | 0.875        |
|    learning_rate        | 0.001        |
|    loss                 | 0.181        |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.000917    |
|    std                  | 1.11         |
|    value_loss           | 0.514        |
------------------------------------------
Eval num_timesteps=1378464, episode_reward=-284.84 +/- 21.06
Episode length: 429.20 +/- 71.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 429      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1378464  |
---------------------------------
Eval num_timesteps=1380456, episode_reward=-291.73 +/- 5.83
Episode length: 417.40 +/- 16.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1380456  |
---------------------------------
Eval num_timesteps=1382448, episode_reward=-305.02 +/- 19.87
Episode length: 416.80 +/- 60.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1382448  |
---------------------------------
Eval num_timesteps=1384440, episode_reward=-302.38 +/- 17.37
Episode length: 380.60 +/- 58.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 381      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1384440  |
---------------------------------
Eval num_timesteps=1386432, episode_reward=-301.38 +/- 11.32
Episode length: 428.20 +/- 22.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1386432  |
---------------------------------
Eval num_timesteps=1388424, episode_reward=-304.99 +/- 9.56
Episode length: 437.40 +/- 37.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 437      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1388424  |
---------------------------------
Eval num_timesteps=1390416, episode_reward=-294.68 +/- 5.72
Episode length: 381.40 +/- 61.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 381      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1390416  |
---------------------------------
Eval num_timesteps=1392408, episode_reward=-299.23 +/- 21.29
Episode length: 440.20 +/- 37.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 440      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1392408  |
---------------------------------
Eval num_timesteps=1394400, episode_reward=-308.43 +/- 16.07
Episode length: 400.00 +/- 17.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1394400  |
---------------------------------
Eval num_timesteps=1396392, episode_reward=-302.13 +/- 17.50
Episode length: 456.60 +/- 45.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 457      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1396392  |
---------------------------------
Eval num_timesteps=1398384, episode_reward=-310.67 +/- 9.09
Episode length: 404.00 +/- 18.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 404      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1398384  |
---------------------------------
Eval num_timesteps=1400376, episode_reward=-303.97 +/- 12.09
Episode length: 398.40 +/- 22.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 398      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1400376  |
---------------------------------
Eval num_timesteps=1402368, episode_reward=-295.27 +/- 11.08
Episode length: 404.40 +/- 48.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 404      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1402368  |
---------------------------------
Eval num_timesteps=1404360, episode_reward=-301.33 +/- 17.11
Episode length: 421.00 +/- 47.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 421      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1404360  |
---------------------------------
Eval num_timesteps=1406352, episode_reward=-307.24 +/- 7.48
Episode length: 418.40 +/- 24.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 418      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1406352  |
---------------------------------
Eval num_timesteps=1408344, episode_reward=-309.09 +/- 13.11
Episode length: 425.60 +/- 27.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 426      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1408344  |
---------------------------------
Eval num_timesteps=1410336, episode_reward=-296.92 +/- 8.02
Episode length: 430.20 +/- 27.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 430      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1410336  |
---------------------------------
Eval num_timesteps=1412328, episode_reward=-310.19 +/- 19.43
Episode length: 450.60 +/- 56.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1412328  |
---------------------------------
Eval num_timesteps=1414320, episode_reward=-304.57 +/- 17.80
Episode length: 420.00 +/- 30.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 420      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1414320  |
---------------------------------
Eval num_timesteps=1416312, episode_reward=-308.42 +/- 7.21
Episode length: 413.40 +/- 12.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 413      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1416312  |
---------------------------------
Eval num_timesteps=1418304, episode_reward=-300.69 +/- 15.54
Episode length: 426.60 +/- 44.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 427      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1418304  |
---------------------------------
Eval num_timesteps=1420296, episode_reward=-280.55 +/- 30.89
Episode length: 446.20 +/- 40.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 1420296  |
---------------------------------
Eval num_timesteps=1422288, episode_reward=-291.03 +/- 13.88
Episode length: 430.60 +/- 51.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1422288  |
---------------------------------
Eval num_timesteps=1424280, episode_reward=-295.99 +/- 7.17
Episode length: 428.00 +/- 20.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1424280  |
---------------------------------
Eval num_timesteps=1426272, episode_reward=-298.70 +/- 14.34
Episode length: 417.20 +/- 38.39
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 417          |
|    mean_reward          | -299         |
| time/                   |              |
|    total_timesteps      | 1426272      |
| train/                  |              |
|    approx_kl            | 0.0043913033 |
|    clip_fraction        | 0.0383       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.1         |
|    explained_variance   | 0.85         |
|    learning_rate        | 0.001        |
|    loss                 | 0.255        |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000863    |
|    std                  | 1.11         |
|    value_loss           | 0.564        |
------------------------------------------
Eval num_timesteps=1428264, episode_reward=-309.15 +/- 15.36
Episode length: 389.20 +/- 28.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1428264  |
---------------------------------
Eval num_timesteps=1430256, episode_reward=-308.68 +/- 14.28
Episode length: 394.40 +/- 48.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 394      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1430256  |
---------------------------------
Eval num_timesteps=1432248, episode_reward=-309.65 +/- 9.30
Episode length: 399.40 +/- 17.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 399      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1432248  |
---------------------------------
Eval num_timesteps=1434240, episode_reward=-317.17 +/- 11.64
Episode length: 413.80 +/- 21.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 414      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1434240  |
---------------------------------
Eval num_timesteps=1436232, episode_reward=-315.65 +/- 21.62
Episode length: 452.20 +/- 51.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 452      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1436232  |
---------------------------------
Eval num_timesteps=1438224, episode_reward=-320.24 +/- 5.65
Episode length: 405.40 +/- 22.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 405      |
|    mean_reward     | -320     |
| time/              |          |
|    total_timesteps | 1438224  |
---------------------------------
Eval num_timesteps=1440216, episode_reward=-307.40 +/- 17.19
Episode length: 359.80 +/- 76.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 360      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1440216  |
---------------------------------
Eval num_timesteps=1442208, episode_reward=-308.25 +/- 4.43
Episode length: 404.40 +/- 13.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 404      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1442208  |
---------------------------------
Eval num_timesteps=1444200, episode_reward=-305.54 +/- 12.63
Episode length: 383.20 +/- 30.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1444200  |
---------------------------------
Eval num_timesteps=1446192, episode_reward=-311.70 +/- 13.22
Episode length: 424.80 +/- 27.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1446192  |
---------------------------------
Eval num_timesteps=1448184, episode_reward=-309.11 +/- 5.57
Episode length: 402.00 +/- 43.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 402      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1448184  |
---------------------------------
Eval num_timesteps=1450176, episode_reward=-314.55 +/- 10.32
Episode length: 408.20 +/- 13.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1450176  |
---------------------------------
Eval num_timesteps=1452168, episode_reward=-309.66 +/- 17.77
Episode length: 420.40 +/- 50.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 420      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1452168  |
---------------------------------
Eval num_timesteps=1454160, episode_reward=-317.08 +/- 12.44
Episode length: 415.00 +/- 68.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1454160  |
---------------------------------
Eval num_timesteps=1456152, episode_reward=-285.45 +/- 27.85
Episode length: 416.60 +/- 36.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1456152  |
---------------------------------
Eval num_timesteps=1458144, episode_reward=-299.75 +/- 10.48
Episode length: 415.60 +/- 62.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 1458144  |
---------------------------------
Eval num_timesteps=1460136, episode_reward=-318.33 +/- 15.23
Episode length: 414.00 +/- 25.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 414      |
|    mean_reward     | -318     |
| time/              |          |
|    total_timesteps | 1460136  |
---------------------------------
Eval num_timesteps=1462128, episode_reward=-313.73 +/- 7.23
Episode length: 410.40 +/- 31.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 410      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1462128  |
---------------------------------
Eval num_timesteps=1464120, episode_reward=-307.37 +/- 15.86
Episode length: 380.80 +/- 30.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 381      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1464120  |
---------------------------------
Eval num_timesteps=1466112, episode_reward=-310.65 +/- 14.84
Episode length: 374.00 +/- 15.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 374      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1466112  |
---------------------------------
Eval num_timesteps=1468104, episode_reward=-308.60 +/- 21.10
Episode length: 396.80 +/- 33.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 397      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1468104  |
---------------------------------
Eval num_timesteps=1470096, episode_reward=-312.32 +/- 5.19
Episode length: 402.20 +/- 18.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 402      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1470096  |
---------------------------------
Eval num_timesteps=1472088, episode_reward=-302.52 +/- 20.54
Episode length: 427.00 +/- 36.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 427      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 1472088  |
---------------------------------
Eval num_timesteps=1474080, episode_reward=-308.38 +/- 14.06
Episode length: 421.60 +/- 67.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 422      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1474080  |
---------------------------------
Eval num_timesteps=1476072, episode_reward=-303.47 +/- 13.70
Episode length: 421.20 +/- 16.77
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 421          |
|    mean_reward          | -303         |
| time/                   |              |
|    total_timesteps      | 1476072      |
| train/                  |              |
|    approx_kl            | 0.0066390783 |
|    clip_fraction        | 0.0479       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.11        |
|    explained_variance   | 0.891        |
|    learning_rate        | 0.001        |
|    loss                 | 0.156        |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00082     |
|    std                  | 1.12         |
|    value_loss           | 0.449        |
------------------------------------------
Eval num_timesteps=1478064, episode_reward=-316.04 +/- 9.31
Episode length: 443.80 +/- 16.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1478064  |
---------------------------------
Eval num_timesteps=1480056, episode_reward=-321.44 +/- 11.44
Episode length: 435.60 +/- 49.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -321     |
| time/              |          |
|    total_timesteps | 1480056  |
---------------------------------
Eval num_timesteps=1482048, episode_reward=-303.76 +/- 9.81
Episode length: 416.20 +/- 53.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1482048  |
---------------------------------
Eval num_timesteps=1484040, episode_reward=-303.87 +/- 19.48
Episode length: 415.40 +/- 19.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1484040  |
---------------------------------
Eval num_timesteps=1486032, episode_reward=-301.64 +/- 14.43
Episode length: 474.60 +/- 78.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1486032  |
---------------------------------
Eval num_timesteps=1488024, episode_reward=-316.88 +/- 17.95
Episode length: 437.60 +/- 30.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1488024  |
---------------------------------
Eval num_timesteps=1490016, episode_reward=-314.14 +/- 15.76
Episode length: 465.00 +/- 28.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1490016  |
---------------------------------
Eval num_timesteps=1492008, episode_reward=-314.25 +/- 15.81
Episode length: 535.60 +/- 37.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1492008  |
---------------------------------
Eval num_timesteps=1494000, episode_reward=-300.77 +/- 35.13
Episode length: 460.40 +/- 75.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1494000  |
---------------------------------
Eval num_timesteps=1495992, episode_reward=-304.33 +/- 9.86
Episode length: 452.20 +/- 73.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 452      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1495992  |
---------------------------------
Eval num_timesteps=1497984, episode_reward=-323.67 +/- 13.91
Episode length: 439.40 +/- 32.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -324     |
| time/              |          |
|    total_timesteps | 1497984  |
---------------------------------
Eval num_timesteps=1499976, episode_reward=-304.24 +/- 17.24
Episode length: 373.20 +/- 34.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 373      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1499976  |
---------------------------------
Eval num_timesteps=1501968, episode_reward=-312.37 +/- 6.76
Episode length: 422.40 +/- 66.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 422      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1501968  |
---------------------------------
Eval num_timesteps=1503960, episode_reward=-301.45 +/- 21.87
Episode length: 481.80 +/- 44.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1503960  |
---------------------------------
Eval num_timesteps=1505952, episode_reward=-315.88 +/- 14.27
Episode length: 407.40 +/- 19.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 407      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1505952  |
---------------------------------
Eval num_timesteps=1507944, episode_reward=-305.99 +/- 10.09
Episode length: 407.80 +/- 40.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1507944  |
---------------------------------
Eval num_timesteps=1509936, episode_reward=-305.32 +/- 10.17
Episode length: 459.60 +/- 34.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1509936  |
---------------------------------
Eval num_timesteps=1511928, episode_reward=-306.85 +/- 9.38
Episode length: 433.00 +/- 29.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1511928  |
---------------------------------
Eval num_timesteps=1513920, episode_reward=-304.57 +/- 17.94
Episode length: 431.60 +/- 36.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1513920  |
---------------------------------
Eval num_timesteps=1515912, episode_reward=-296.08 +/- 27.37
Episode length: 413.20 +/- 20.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 413      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1515912  |
---------------------------------
Eval num_timesteps=1517904, episode_reward=-302.58 +/- 17.49
Episode length: 425.40 +/- 46.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 1517904  |
---------------------------------
Eval num_timesteps=1519896, episode_reward=-295.58 +/- 23.14
Episode length: 439.00 +/- 30.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1519896  |
---------------------------------
Eval num_timesteps=1521888, episode_reward=-288.14 +/- 47.83
Episode length: 409.00 +/- 62.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 409      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 1521888  |
---------------------------------
Eval num_timesteps=1523880, episode_reward=-290.33 +/- 29.84
Episode length: 483.20 +/- 52.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 483        |
|    mean_reward          | -290       |
| time/                   |            |
|    total_timesteps      | 1523880    |
| train/                  |            |
|    approx_kl            | 0.00399011 |
|    clip_fraction        | 0.0313     |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.12      |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.001      |
|    loss                 | 0.072      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.00135   |
|    std                  | 1.12       |
|    value_loss           | 0.33       |
----------------------------------------
Eval num_timesteps=1525872, episode_reward=-308.62 +/- 15.07
Episode length: 464.40 +/- 34.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1525872  |
---------------------------------
Eval num_timesteps=1527864, episode_reward=-293.13 +/- 12.76
Episode length: 412.80 +/- 55.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 413      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1527864  |
---------------------------------
Eval num_timesteps=1529856, episode_reward=-299.10 +/- 17.57
Episode length: 421.00 +/- 36.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 421      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1529856  |
---------------------------------
Eval num_timesteps=1531848, episode_reward=-309.69 +/- 13.06
Episode length: 471.40 +/- 46.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1531848  |
---------------------------------
Eval num_timesteps=1533840, episode_reward=-294.61 +/- 12.46
Episode length: 472.80 +/- 55.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1533840  |
---------------------------------
Eval num_timesteps=1535832, episode_reward=-314.21 +/- 17.10
Episode length: 470.60 +/- 36.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1535832  |
---------------------------------
Eval num_timesteps=1537824, episode_reward=-292.63 +/- 24.32
Episode length: 500.60 +/- 32.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1537824  |
---------------------------------
Eval num_timesteps=1539816, episode_reward=-303.69 +/- 20.28
Episode length: 492.60 +/- 35.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1539816  |
---------------------------------
Eval num_timesteps=1541808, episode_reward=-301.14 +/- 27.21
Episode length: 479.80 +/- 50.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1541808  |
---------------------------------
Eval num_timesteps=1543800, episode_reward=-319.61 +/- 14.19
Episode length: 435.60 +/- 62.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -320     |
| time/              |          |
|    total_timesteps | 1543800  |
---------------------------------
Eval num_timesteps=1545792, episode_reward=-297.70 +/- 16.71
Episode length: 505.40 +/- 61.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1545792  |
---------------------------------
Eval num_timesteps=1547784, episode_reward=-308.97 +/- 12.65
Episode length: 407.20 +/- 10.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 407      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1547784  |
---------------------------------
Eval num_timesteps=1549776, episode_reward=-296.69 +/- 35.29
Episode length: 468.60 +/- 67.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 469      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1549776  |
---------------------------------
Eval num_timesteps=1551768, episode_reward=-297.62 +/- 19.35
Episode length: 471.60 +/- 49.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1551768  |
---------------------------------
Eval num_timesteps=1553760, episode_reward=-300.92 +/- 16.45
Episode length: 472.40 +/- 58.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1553760  |
---------------------------------
Eval num_timesteps=1555752, episode_reward=-292.69 +/- 17.31
Episode length: 458.60 +/- 69.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 459      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1555752  |
---------------------------------
Eval num_timesteps=1557744, episode_reward=-304.73 +/- 10.58
Episode length: 478.20 +/- 46.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1557744  |
---------------------------------
Eval num_timesteps=1559736, episode_reward=-302.00 +/- 14.46
Episode length: 464.40 +/- 65.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1559736  |
---------------------------------
Eval num_timesteps=1561728, episode_reward=-301.44 +/- 23.88
Episode length: 489.80 +/- 45.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1561728  |
---------------------------------
Eval num_timesteps=1563720, episode_reward=-307.42 +/- 18.07
Episode length: 461.00 +/- 34.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1563720  |
---------------------------------
Eval num_timesteps=1565712, episode_reward=-310.14 +/- 18.04
Episode length: 435.20 +/- 33.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1565712  |
---------------------------------
Eval num_timesteps=1567704, episode_reward=-306.69 +/- 11.86
Episode length: 410.60 +/- 13.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 411      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1567704  |
---------------------------------
Eval num_timesteps=1569696, episode_reward=-282.23 +/- 26.57
Episode length: 449.20 +/- 68.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | -282     |
| time/              |          |
|    total_timesteps | 1569696  |
---------------------------------
Eval num_timesteps=1571688, episode_reward=-310.66 +/- 15.04
Episode length: 447.80 +/- 55.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1571688  |
---------------------------------
Eval num_timesteps=1573680, episode_reward=-308.19 +/- 19.27
Episode length: 527.60 +/- 132.46
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 528          |
|    mean_reward          | -308         |
| time/                   |              |
|    total_timesteps      | 1573680      |
| train/                  |              |
|    approx_kl            | 0.0052579064 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.14        |
|    explained_variance   | 0.962        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0309       |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00081     |
|    std                  | 1.13         |
|    value_loss           | 0.213        |
------------------------------------------
Eval num_timesteps=1575672, episode_reward=-300.08 +/- 22.57
Episode length: 531.80 +/- 44.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 1575672  |
---------------------------------
Eval num_timesteps=1577664, episode_reward=-295.99 +/- 8.77
Episode length: 454.00 +/- 36.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1577664  |
---------------------------------
Eval num_timesteps=1579656, episode_reward=-310.72 +/- 6.94
Episode length: 539.60 +/- 10.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1579656  |
---------------------------------
Eval num_timesteps=1581648, episode_reward=-318.62 +/- 12.39
Episode length: 442.40 +/- 60.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -319     |
| time/              |          |
|    total_timesteps | 1581648  |
---------------------------------
Eval num_timesteps=1583640, episode_reward=-296.49 +/- 15.83
Episode length: 484.60 +/- 79.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 485      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1583640  |
---------------------------------
Eval num_timesteps=1585632, episode_reward=-314.79 +/- 13.29
Episode length: 479.40 +/- 35.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1585632  |
---------------------------------
Eval num_timesteps=1587624, episode_reward=-296.26 +/- 32.71
Episode length: 493.40 +/- 44.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1587624  |
---------------------------------
Eval num_timesteps=1589616, episode_reward=-298.60 +/- 9.73
Episode length: 531.20 +/- 42.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1589616  |
---------------------------------
Eval num_timesteps=1591608, episode_reward=-285.75 +/- 47.93
Episode length: 492.00 +/- 46.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 1591608  |
---------------------------------
Eval num_timesteps=1593600, episode_reward=-283.84 +/- 24.96
Episode length: 499.80 +/- 26.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 1593600  |
---------------------------------
Eval num_timesteps=1595592, episode_reward=-302.76 +/- 19.64
Episode length: 520.20 +/- 14.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 1595592  |
---------------------------------
Eval num_timesteps=1597584, episode_reward=-310.11 +/- 18.84
Episode length: 480.60 +/- 78.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1597584  |
---------------------------------
Eval num_timesteps=1599576, episode_reward=-300.38 +/- 16.43
Episode length: 463.80 +/- 53.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 1599576  |
---------------------------------
Eval num_timesteps=1601568, episode_reward=-315.36 +/- 2.01
Episode length: 448.40 +/- 40.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1601568  |
---------------------------------
Eval num_timesteps=1603560, episode_reward=-307.99 +/- 29.73
Episode length: 480.40 +/- 45.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1603560  |
---------------------------------
Eval num_timesteps=1605552, episode_reward=-304.79 +/- 10.91
Episode length: 496.60 +/- 15.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1605552  |
---------------------------------
Eval num_timesteps=1607544, episode_reward=-311.54 +/- 4.19
Episode length: 481.40 +/- 57.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1607544  |
---------------------------------
Eval num_timesteps=1609536, episode_reward=-310.58 +/- 13.67
Episode length: 499.80 +/- 26.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1609536  |
---------------------------------
Eval num_timesteps=1611528, episode_reward=-301.58 +/- 12.59
Episode length: 455.20 +/- 103.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1611528  |
---------------------------------
Eval num_timesteps=1613520, episode_reward=-305.51 +/- 20.37
Episode length: 415.60 +/- 47.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1613520  |
---------------------------------
Eval num_timesteps=1615512, episode_reward=-310.93 +/- 9.19
Episode length: 525.00 +/- 76.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1615512  |
---------------------------------
Eval num_timesteps=1617504, episode_reward=-314.54 +/- 6.77
Episode length: 519.00 +/- 47.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1617504  |
---------------------------------
Eval num_timesteps=1619496, episode_reward=-306.33 +/- 20.76
Episode length: 476.20 +/- 43.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1619496  |
---------------------------------
Eval num_timesteps=1621488, episode_reward=-312.74 +/- 10.35
Episode length: 489.40 +/- 32.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1621488  |
---------------------------------
Eval num_timesteps=1623480, episode_reward=-295.11 +/- 12.29
Episode length: 500.60 +/- 59.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 501         |
|    mean_reward          | -295        |
| time/                   |             |
|    total_timesteps      | 1623480     |
| train/                  |             |
|    approx_kl            | 0.004106329 |
|    clip_fraction        | 0.0516      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.16       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0253      |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00129    |
|    std                  | 1.13        |
|    value_loss           | 0.197       |
-----------------------------------------
Eval num_timesteps=1625472, episode_reward=-312.90 +/- 15.51
Episode length: 476.20 +/- 84.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1625472  |
---------------------------------
Eval num_timesteps=1627464, episode_reward=-316.42 +/- 10.76
Episode length: 383.40 +/- 32.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1627464  |
---------------------------------
Eval num_timesteps=1629456, episode_reward=-315.20 +/- 10.57
Episode length: 436.40 +/- 95.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1629456  |
---------------------------------
Eval num_timesteps=1631448, episode_reward=-310.59 +/- 9.87
Episode length: 480.80 +/- 66.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1631448  |
---------------------------------
Eval num_timesteps=1633440, episode_reward=-317.19 +/- 11.51
Episode length: 461.20 +/- 93.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1633440  |
---------------------------------
Eval num_timesteps=1635432, episode_reward=-308.85 +/- 20.54
Episode length: 477.80 +/- 65.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1635432  |
---------------------------------
Eval num_timesteps=1637424, episode_reward=-317.01 +/- 8.67
Episode length: 447.00 +/- 51.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 447      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1637424  |
---------------------------------
Eval num_timesteps=1639416, episode_reward=-291.64 +/- 24.45
Episode length: 492.40 +/- 69.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1639416  |
---------------------------------
Eval num_timesteps=1641408, episode_reward=-319.94 +/- 6.89
Episode length: 485.00 +/- 67.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 485      |
|    mean_reward     | -320     |
| time/              |          |
|    total_timesteps | 1641408  |
---------------------------------
Eval num_timesteps=1643400, episode_reward=-314.63 +/- 16.96
Episode length: 478.40 +/- 38.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1643400  |
---------------------------------
Eval num_timesteps=1645392, episode_reward=-304.08 +/- 15.46
Episode length: 466.20 +/- 74.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1645392  |
---------------------------------
Eval num_timesteps=1647384, episode_reward=-295.48 +/- 24.04
Episode length: 423.20 +/- 105.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 423      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1647384  |
---------------------------------
Eval num_timesteps=1649376, episode_reward=-316.22 +/- 7.22
Episode length: 500.80 +/- 98.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1649376  |
---------------------------------
Eval num_timesteps=1651368, episode_reward=-296.14 +/- 23.26
Episode length: 496.80 +/- 50.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1651368  |
---------------------------------
Eval num_timesteps=1653360, episode_reward=-288.74 +/- 30.25
Episode length: 505.00 +/- 37.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 1653360  |
---------------------------------
Eval num_timesteps=1655352, episode_reward=-298.40 +/- 27.90
Episode length: 468.60 +/- 81.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 469      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1655352  |
---------------------------------
Eval num_timesteps=1657344, episode_reward=-298.03 +/- 16.47
Episode length: 502.00 +/- 56.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1657344  |
---------------------------------
Eval num_timesteps=1659336, episode_reward=-309.68 +/- 12.42
Episode length: 475.60 +/- 55.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1659336  |
---------------------------------
Eval num_timesteps=1661328, episode_reward=-306.71 +/- 21.65
Episode length: 491.80 +/- 69.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1661328  |
---------------------------------
Eval num_timesteps=1663320, episode_reward=-305.00 +/- 18.49
Episode length: 515.40 +/- 44.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1663320  |
---------------------------------
Eval num_timesteps=1665312, episode_reward=-315.69 +/- 15.10
Episode length: 437.80 +/- 50.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1665312  |
---------------------------------
Eval num_timesteps=1667304, episode_reward=-291.10 +/- 8.53
Episode length: 463.40 +/- 44.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | -291     |
| time/              |          |
|    total_timesteps | 1667304  |
---------------------------------
Eval num_timesteps=1669296, episode_reward=-302.26 +/- 12.15
Episode length: 514.60 +/- 21.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 1669296  |
---------------------------------
Eval num_timesteps=1671288, episode_reward=-318.58 +/- 14.01
Episode length: 433.80 +/- 50.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 434          |
|    mean_reward          | -319         |
| time/                   |              |
|    total_timesteps      | 1671288      |
| train/                  |              |
|    approx_kl            | 0.0040764855 |
|    clip_fraction        | 0.0467       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.17        |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.001        |
|    loss                 | 0.00828      |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00161     |
|    std                  | 1.13         |
|    value_loss           | 0.151        |
------------------------------------------
Eval num_timesteps=1673280, episode_reward=-317.51 +/- 14.84
Episode length: 431.20 +/- 35.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -318     |
| time/              |          |
|    total_timesteps | 1673280  |
---------------------------------
Eval num_timesteps=1675272, episode_reward=-313.48 +/- 13.10
Episode length: 444.00 +/- 67.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1675272  |
---------------------------------
Eval num_timesteps=1677264, episode_reward=-309.10 +/- 18.64
Episode length: 460.00 +/- 53.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1677264  |
---------------------------------
Eval num_timesteps=1679256, episode_reward=-303.99 +/- 18.14
Episode length: 428.40 +/- 61.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1679256  |
---------------------------------
Eval num_timesteps=1681248, episode_reward=-309.83 +/- 9.68
Episode length: 463.80 +/- 70.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1681248  |
---------------------------------
Eval num_timesteps=1683240, episode_reward=-305.79 +/- 23.24
Episode length: 425.20 +/- 49.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1683240  |
---------------------------------
Eval num_timesteps=1685232, episode_reward=-321.36 +/- 9.04
Episode length: 434.60 +/- 77.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | -321     |
| time/              |          |
|    total_timesteps | 1685232  |
---------------------------------
Eval num_timesteps=1687224, episode_reward=-203.76 +/- 222.82
Episode length: 530.00 +/- 167.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | -204     |
| time/              |          |
|    total_timesteps | 1687224  |
---------------------------------
Eval num_timesteps=1689216, episode_reward=-306.54 +/- 19.19
Episode length: 417.00 +/- 92.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1689216  |
---------------------------------
Eval num_timesteps=1691208, episode_reward=-325.37 +/- 12.18
Episode length: 427.60 +/- 64.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -325     |
| time/              |          |
|    total_timesteps | 1691208  |
---------------------------------
Eval num_timesteps=1693200, episode_reward=-309.57 +/- 3.83
Episode length: 464.00 +/- 26.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1693200  |
---------------------------------
Eval num_timesteps=1695192, episode_reward=-326.37 +/- 8.20
Episode length: 444.40 +/- 53.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -326     |
| time/              |          |
|    total_timesteps | 1695192  |
---------------------------------
Eval num_timesteps=1697184, episode_reward=-312.22 +/- 13.54
Episode length: 479.40 +/- 65.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1697184  |
---------------------------------
Eval num_timesteps=1699176, episode_reward=-314.05 +/- 8.52
Episode length: 418.00 +/- 57.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 418      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1699176  |
---------------------------------
Eval num_timesteps=1701168, episode_reward=-322.38 +/- 11.14
Episode length: 443.40 +/- 51.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | -322     |
| time/              |          |
|    total_timesteps | 1701168  |
---------------------------------
Eval num_timesteps=1703160, episode_reward=-296.84 +/- 14.62
Episode length: 507.40 +/- 39.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1703160  |
---------------------------------
Eval num_timesteps=1705152, episode_reward=-299.38 +/- 38.00
Episode length: 455.00 +/- 42.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1705152  |
---------------------------------
Eval num_timesteps=1707144, episode_reward=-307.75 +/- 18.29
Episode length: 442.60 +/- 68.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | -308     |
| time/              |          |
|    total_timesteps | 1707144  |
---------------------------------
Eval num_timesteps=1709136, episode_reward=-326.06 +/- 10.18
Episode length: 446.40 +/- 38.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -326     |
| time/              |          |
|    total_timesteps | 1709136  |
---------------------------------
Eval num_timesteps=1711128, episode_reward=-320.82 +/- 17.57
Episode length: 444.80 +/- 38.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | -321     |
| time/              |          |
|    total_timesteps | 1711128  |
---------------------------------
Eval num_timesteps=1713120, episode_reward=-314.41 +/- 11.66
Episode length: 411.20 +/- 76.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 411      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1713120  |
---------------------------------
Eval num_timesteps=1715112, episode_reward=-311.23 +/- 11.95
Episode length: 455.00 +/- 66.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1715112  |
---------------------------------
Eval num_timesteps=1717104, episode_reward=-268.03 +/- 39.44
Episode length: 534.60 +/- 89.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | -268     |
| time/              |          |
|    total_timesteps | 1717104  |
---------------------------------
Eval num_timesteps=1719096, episode_reward=-295.67 +/- 22.16
Episode length: 484.00 +/- 40.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 484      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1719096  |
---------------------------------
Eval num_timesteps=1721088, episode_reward=-320.33 +/- 10.75
Episode length: 396.40 +/- 35.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 396         |
|    mean_reward          | -320        |
| time/                   |             |
|    total_timesteps      | 1721088     |
| train/                  |             |
|    approx_kl            | 0.004839044 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.18       |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0099      |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.000837   |
|    std                  | 1.14        |
|    value_loss           | 0.167       |
-----------------------------------------
Eval num_timesteps=1723080, episode_reward=-319.40 +/- 10.14
Episode length: 432.00 +/- 34.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -319     |
| time/              |          |
|    total_timesteps | 1723080  |
---------------------------------
Eval num_timesteps=1725072, episode_reward=-305.82 +/- 17.84
Episode length: 477.20 +/- 45.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1725072  |
---------------------------------
Eval num_timesteps=1727064, episode_reward=-313.23 +/- 19.48
Episode length: 430.60 +/- 69.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1727064  |
---------------------------------
Eval num_timesteps=1729056, episode_reward=-327.87 +/- 6.92
Episode length: 439.40 +/- 40.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -328     |
| time/              |          |
|    total_timesteps | 1729056  |
---------------------------------
Eval num_timesteps=1731048, episode_reward=-321.45 +/- 23.67
Episode length: 400.20 +/- 48.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 400      |
|    mean_reward     | -321     |
| time/              |          |
|    total_timesteps | 1731048  |
---------------------------------
Eval num_timesteps=1733040, episode_reward=-307.32 +/- 20.53
Episode length: 462.80 +/- 34.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1733040  |
---------------------------------
Eval num_timesteps=1735032, episode_reward=-325.10 +/- 13.52
Episode length: 405.20 +/- 69.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 405      |
|    mean_reward     | -325     |
| time/              |          |
|    total_timesteps | 1735032  |
---------------------------------
Eval num_timesteps=1737024, episode_reward=-327.01 +/- 6.13
Episode length: 417.40 +/- 25.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -327     |
| time/              |          |
|    total_timesteps | 1737024  |
---------------------------------
Eval num_timesteps=1739016, episode_reward=-326.42 +/- 9.47
Episode length: 393.60 +/- 41.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 394      |
|    mean_reward     | -326     |
| time/              |          |
|    total_timesteps | 1739016  |
---------------------------------
Eval num_timesteps=1741008, episode_reward=-333.79 +/- 4.05
Episode length: 445.00 +/- 92.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | -334     |
| time/              |          |
|    total_timesteps | 1741008  |
---------------------------------
Eval num_timesteps=1743000, episode_reward=-314.98 +/- 6.42
Episode length: 469.60 +/- 7.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1743000  |
---------------------------------
Eval num_timesteps=1744992, episode_reward=-310.67 +/- 11.18
Episode length: 402.20 +/- 55.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 402      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1744992  |
---------------------------------
Eval num_timesteps=1746984, episode_reward=-317.37 +/- 26.09
Episode length: 404.00 +/- 52.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 404      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1746984  |
---------------------------------
Eval num_timesteps=1748976, episode_reward=-314.79 +/- 12.02
Episode length: 404.80 +/- 69.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 405      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1748976  |
---------------------------------
Eval num_timesteps=1750968, episode_reward=-316.32 +/- 21.48
Episode length: 421.80 +/- 39.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 422      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1750968  |
---------------------------------
Eval num_timesteps=1752960, episode_reward=-311.47 +/- 23.48
Episode length: 443.80 +/- 39.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1752960  |
---------------------------------
Eval num_timesteps=1754952, episode_reward=-305.57 +/- 29.57
Episode length: 448.60 +/- 82.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1754952  |
---------------------------------
Eval num_timesteps=1756944, episode_reward=-330.48 +/- 7.31
Episode length: 389.40 +/- 18.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | -330     |
| time/              |          |
|    total_timesteps | 1756944  |
---------------------------------
Eval num_timesteps=1758936, episode_reward=-298.24 +/- 24.55
Episode length: 449.60 +/- 43.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | -298     |
| time/              |          |
|    total_timesteps | 1758936  |
---------------------------------
Eval num_timesteps=1760928, episode_reward=-296.87 +/- 28.66
Episode length: 418.40 +/- 72.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 418      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 1760928  |
---------------------------------
Eval num_timesteps=1762920, episode_reward=-321.79 +/- 11.11
Episode length: 415.60 +/- 40.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | -322     |
| time/              |          |
|    total_timesteps | 1762920  |
---------------------------------
Eval num_timesteps=1764912, episode_reward=-316.92 +/- 11.70
Episode length: 430.60 +/- 65.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1764912  |
---------------------------------
Eval num_timesteps=1766904, episode_reward=-311.24 +/- 15.15
Episode length: 433.40 +/- 95.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1766904  |
---------------------------------
Eval num_timesteps=1768896, episode_reward=-320.28 +/- 12.19
Episode length: 417.40 +/- 50.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 417      |
|    mean_reward     | -320     |
| time/              |          |
|    total_timesteps | 1768896  |
---------------------------------
Eval num_timesteps=1770888, episode_reward=-318.46 +/- 9.13
Episode length: 428.00 +/- 55.43
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 428          |
|    mean_reward          | -318         |
| time/                   |              |
|    total_timesteps      | 1770888      |
| train/                  |              |
|    approx_kl            | 0.0036173942 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.19        |
|    explained_variance   | 0.975        |
|    learning_rate        | 0.001        |
|    loss                 | 0.00823      |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00135     |
|    std                  | 1.14         |
|    value_loss           | 0.163        |
------------------------------------------
Eval num_timesteps=1772880, episode_reward=-315.85 +/- 7.52
Episode length: 463.20 +/- 62.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1772880  |
---------------------------------
Eval num_timesteps=1774872, episode_reward=-319.59 +/- 15.47
Episode length: 428.60 +/- 28.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 429      |
|    mean_reward     | -320     |
| time/              |          |
|    total_timesteps | 1774872  |
---------------------------------
Eval num_timesteps=1776864, episode_reward=-308.83 +/- 14.39
Episode length: 464.60 +/- 39.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1776864  |
---------------------------------
Eval num_timesteps=1778856, episode_reward=-317.70 +/- 3.16
Episode length: 466.40 +/- 37.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -318     |
| time/              |          |
|    total_timesteps | 1778856  |
---------------------------------
Eval num_timesteps=1780848, episode_reward=-326.58 +/- 11.77
Episode length: 420.20 +/- 42.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 420      |
|    mean_reward     | -327     |
| time/              |          |
|    total_timesteps | 1780848  |
---------------------------------
Eval num_timesteps=1782840, episode_reward=-309.26 +/- 22.01
Episode length: 471.40 +/- 31.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1782840  |
---------------------------------
Eval num_timesteps=1784832, episode_reward=-315.56 +/- 18.27
Episode length: 409.20 +/- 63.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 409      |
|    mean_reward     | -316     |
| time/              |          |
|    total_timesteps | 1784832  |
---------------------------------
Eval num_timesteps=1786824, episode_reward=-316.73 +/- 23.81
Episode length: 478.80 +/- 70.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1786824  |
---------------------------------
Eval num_timesteps=1788816, episode_reward=-323.17 +/- 10.11
Episode length: 451.40 +/- 71.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | -323     |
| time/              |          |
|    total_timesteps | 1788816  |
---------------------------------
Eval num_timesteps=1790808, episode_reward=-311.80 +/- 4.62
Episode length: 424.20 +/- 43.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1790808  |
---------------------------------
Eval num_timesteps=1792800, episode_reward=-322.65 +/- 10.71
Episode length: 455.40 +/- 42.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -323     |
| time/              |          |
|    total_timesteps | 1792800  |
---------------------------------
Eval num_timesteps=1794792, episode_reward=-309.60 +/- 25.97
Episode length: 480.20 +/- 30.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1794792  |
---------------------------------
Eval num_timesteps=1796784, episode_reward=-310.82 +/- 21.05
Episode length: 444.20 +/- 39.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1796784  |
---------------------------------
Eval num_timesteps=1798776, episode_reward=-319.16 +/- 14.05
Episode length: 457.20 +/- 23.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 457      |
|    mean_reward     | -319     |
| time/              |          |
|    total_timesteps | 1798776  |
---------------------------------
Eval num_timesteps=1800768, episode_reward=-328.51 +/- 5.81
Episode length: 427.40 +/- 47.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 427      |
|    mean_reward     | -329     |
| time/              |          |
|    total_timesteps | 1800768  |
---------------------------------
Eval num_timesteps=1802760, episode_reward=-303.90 +/- 23.78
Episode length: 438.60 +/- 82.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1802760  |
---------------------------------
Eval num_timesteps=1804752, episode_reward=-322.11 +/- 13.87
Episode length: 465.60 +/- 28.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -322     |
| time/              |          |
|    total_timesteps | 1804752  |
---------------------------------
Eval num_timesteps=1806744, episode_reward=-317.36 +/- 7.49
Episode length: 452.60 +/- 33.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 453      |
|    mean_reward     | -317     |
| time/              |          |
|    total_timesteps | 1806744  |
---------------------------------
Eval num_timesteps=1808736, episode_reward=-306.89 +/- 17.57
Episode length: 451.00 +/- 28.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1808736  |
---------------------------------
Eval num_timesteps=1810728, episode_reward=-321.65 +/- 7.60
Episode length: 461.60 +/- 48.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 462      |
|    mean_reward     | -322     |
| time/              |          |
|    total_timesteps | 1810728  |
---------------------------------
Eval num_timesteps=1812720, episode_reward=-314.26 +/- 19.99
Episode length: 446.60 +/- 31.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 447      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1812720  |
---------------------------------
Eval num_timesteps=1814712, episode_reward=-310.93 +/- 14.21
Episode length: 442.00 +/- 28.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1814712  |
---------------------------------
Eval num_timesteps=1816704, episode_reward=-312.45 +/- 5.06
Episode length: 442.20 +/- 27.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -312     |
| time/              |          |
|    total_timesteps | 1816704  |
---------------------------------
Eval num_timesteps=1818696, episode_reward=-305.74 +/- 11.81
Episode length: 465.60 +/- 50.30
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 466          |
|    mean_reward          | -306         |
| time/                   |              |
|    total_timesteps      | 1818696      |
| train/                  |              |
|    approx_kl            | 0.0043903664 |
|    clip_fraction        | 0.0437       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.2         |
|    explained_variance   | 0.983        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0249      |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00181     |
|    std                  | 1.14         |
|    value_loss           | 0.101        |
------------------------------------------
Eval num_timesteps=1820688, episode_reward=-294.72 +/- 18.37
Episode length: 476.20 +/- 69.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1820688  |
---------------------------------
Eval num_timesteps=1822680, episode_reward=-305.30 +/- 7.79
Episode length: 505.20 +/- 34.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1822680  |
---------------------------------
Eval num_timesteps=1824672, episode_reward=-311.34 +/- 15.21
Episode length: 466.60 +/- 48.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 467      |
|    mean_reward     | -311     |
| time/              |          |
|    total_timesteps | 1824672  |
---------------------------------
Eval num_timesteps=1826664, episode_reward=-302.55 +/- 12.80
Episode length: 500.80 +/- 39.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 1826664  |
---------------------------------
Eval num_timesteps=1828656, episode_reward=-322.66 +/- 12.06
Episode length: 431.20 +/- 42.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | -323     |
| time/              |          |
|    total_timesteps | 1828656  |
---------------------------------
Eval num_timesteps=1830648, episode_reward=-309.74 +/- 21.61
Episode length: 487.00 +/- 33.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | -310     |
| time/              |          |
|    total_timesteps | 1830648  |
---------------------------------
Eval num_timesteps=1832640, episode_reward=-305.55 +/- 9.02
Episode length: 502.80 +/- 31.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1832640  |
---------------------------------
Eval num_timesteps=1834632, episode_reward=-309.28 +/- 15.52
Episode length: 487.00 +/- 29.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1834632  |
---------------------------------
Eval num_timesteps=1836624, episode_reward=-292.90 +/- 11.56
Episode length: 470.60 +/- 57.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1836624  |
---------------------------------
Eval num_timesteps=1838616, episode_reward=-300.55 +/- 14.97
Episode length: 464.00 +/- 49.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1838616  |
---------------------------------
Eval num_timesteps=1840608, episode_reward=-318.88 +/- 16.38
Episode length: 505.60 +/- 43.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | -319     |
| time/              |          |
|    total_timesteps | 1840608  |
---------------------------------
Eval num_timesteps=1842600, episode_reward=-314.63 +/- 16.57
Episode length: 491.80 +/- 50.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | -315     |
| time/              |          |
|    total_timesteps | 1842600  |
---------------------------------
Eval num_timesteps=1844592, episode_reward=-291.98 +/- 15.85
Episode length: 491.20 +/- 28.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 1844592  |
---------------------------------
Eval num_timesteps=1846584, episode_reward=-305.74 +/- 17.45
Episode length: 480.80 +/- 20.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 1846584  |
---------------------------------
Eval num_timesteps=1848576, episode_reward=-313.33 +/- 10.58
Episode length: 437.20 +/- 18.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 437      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1848576  |
---------------------------------
Eval num_timesteps=1850568, episode_reward=-308.55 +/- 12.09
Episode length: 458.80 +/- 39.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 459      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1850568  |
---------------------------------
Eval num_timesteps=1852560, episode_reward=-303.76 +/- 12.25
Episode length: 454.60 +/- 39.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1852560  |
---------------------------------
Eval num_timesteps=1854552, episode_reward=-301.03 +/- 12.79
Episode length: 432.40 +/- 84.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -301     |
| time/              |          |
|    total_timesteps | 1854552  |
---------------------------------
Eval num_timesteps=1856544, episode_reward=-304.89 +/- 14.76
Episode length: 478.00 +/- 33.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -305     |
| time/              |          |
|    total_timesteps | 1856544  |
---------------------------------
Eval num_timesteps=1858536, episode_reward=-308.73 +/- 18.26
Episode length: 468.00 +/- 54.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 468      |
|    mean_reward     | -309     |
| time/              |          |
|    total_timesteps | 1858536  |
---------------------------------
Eval num_timesteps=1860528, episode_reward=-313.03 +/- 15.79
Episode length: 475.40 +/- 37.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | -313     |
| time/              |          |
|    total_timesteps | 1860528  |
---------------------------------
Eval num_timesteps=1862520, episode_reward=-313.55 +/- 18.08
Episode length: 475.60 +/- 43.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | -314     |
| time/              |          |
|    total_timesteps | 1862520  |
---------------------------------
Eval num_timesteps=1864512, episode_reward=-303.21 +/- 14.38
Episode length: 473.00 +/- 46.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | -303     |
| time/              |          |
|    total_timesteps | 1864512  |
---------------------------------
Eval num_timesteps=1866504, episode_reward=-304.22 +/- 17.27
Episode length: 472.40 +/- 29.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -304     |
| time/              |          |
|    total_timesteps | 1866504  |
---------------------------------
Eval num_timesteps=1868496, episode_reward=-273.06 +/- 20.19
Episode length: 494.00 +/- 28.83
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 494          |
|    mean_reward          | -273         |
| time/                   |              |
|    total_timesteps      | 1868496      |
| train/                  |              |
|    approx_kl            | 0.0056329276 |
|    clip_fraction        | 0.0823       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.21        |
|    explained_variance   | 0.985        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0255      |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00197     |
|    std                  | 1.15         |
|    value_loss           | 0.0962       |
------------------------------------------
Eval num_timesteps=1870488, episode_reward=-280.52 +/- 30.60
Episode length: 578.40 +/- 57.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 1870488  |
---------------------------------
Eval num_timesteps=1872480, episode_reward=-306.58 +/- 12.63
Episode length: 526.00 +/- 58.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | -307     |
| time/              |          |
|    total_timesteps | 1872480  |
---------------------------------
Eval num_timesteps=1874472, episode_reward=-283.55 +/- 24.06
Episode length: 523.80 +/- 43.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | -284     |
| time/              |          |
|    total_timesteps | 1874472  |
---------------------------------
Eval num_timesteps=1876464, episode_reward=-250.64 +/- 31.11
Episode length: 573.80 +/- 73.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 1876464  |
---------------------------------
Eval num_timesteps=1878456, episode_reward=-292.78 +/- 13.42
Episode length: 488.40 +/- 16.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | -293     |
| time/              |          |
|    total_timesteps | 1878456  |
---------------------------------
Eval num_timesteps=1880448, episode_reward=-298.77 +/- 29.24
Episode length: 488.00 +/- 57.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1880448  |
---------------------------------
Eval num_timesteps=1882440, episode_reward=-270.61 +/- 38.50
Episode length: 527.80 +/- 45.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 1882440  |
---------------------------------
Eval num_timesteps=1884432, episode_reward=-299.20 +/- 7.78
Episode length: 505.80 +/- 47.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | -299     |
| time/              |          |
|    total_timesteps | 1884432  |
---------------------------------
Eval num_timesteps=1886424, episode_reward=-252.38 +/- 39.19
Episode length: 557.60 +/- 57.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | -252     |
| time/              |          |
|    total_timesteps | 1886424  |
---------------------------------
Eval num_timesteps=1888416, episode_reward=-264.56 +/- 40.82
Episode length: 520.80 +/- 46.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | -265     |
| time/              |          |
|    total_timesteps | 1888416  |
---------------------------------
Eval num_timesteps=1890408, episode_reward=-272.75 +/- 41.62
Episode length: 551.00 +/- 45.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | -273     |
| time/              |          |
|    total_timesteps | 1890408  |
---------------------------------
Eval num_timesteps=1892400, episode_reward=-294.73 +/- 19.79
Episode length: 536.80 +/- 61.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | -295     |
| time/              |          |
|    total_timesteps | 1892400  |
---------------------------------
Eval num_timesteps=1894392, episode_reward=-288.13 +/- 30.49
Episode length: 507.20 +/- 34.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 1894392  |
---------------------------------
Eval num_timesteps=1896384, episode_reward=-288.66 +/- 29.86
Episode length: 511.40 +/- 75.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 1896384  |
---------------------------------
Eval num_timesteps=1898376, episode_reward=-271.30 +/- 22.44
Episode length: 534.60 +/- 68.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 1898376  |
---------------------------------
Eval num_timesteps=1900368, episode_reward=-274.18 +/- 30.79
Episode length: 502.80 +/- 35.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | -274     |
| time/              |          |
|    total_timesteps | 1900368  |
---------------------------------
Eval num_timesteps=1902360, episode_reward=-296.41 +/- 34.69
Episode length: 568.00 +/- 43.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 1902360  |
---------------------------------
Eval num_timesteps=1904352, episode_reward=-221.96 +/- 141.96
Episode length: 520.20 +/- 96.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | -222     |
| time/              |          |
|    total_timesteps | 1904352  |
---------------------------------
Eval num_timesteps=1906344, episode_reward=-271.60 +/- 32.70
Episode length: 503.60 +/- 31.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 1906344  |
---------------------------------
Eval num_timesteps=1908336, episode_reward=-278.27 +/- 11.83
Episode length: 537.40 +/- 39.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | -278     |
| time/              |          |
|    total_timesteps | 1908336  |
---------------------------------
Eval num_timesteps=1910328, episode_reward=-294.31 +/- 9.62
Episode length: 543.40 +/- 97.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | -294     |
| time/              |          |
|    total_timesteps | 1910328  |
---------------------------------
Eval num_timesteps=1912320, episode_reward=-275.97 +/- 29.76
Episode length: 527.80 +/- 79.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 1912320  |
---------------------------------
Eval num_timesteps=1914312, episode_reward=-285.47 +/- 44.91
Episode length: 530.60 +/- 34.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1914312  |
---------------------------------
Eval num_timesteps=1916304, episode_reward=-299.88 +/- 8.40
Episode length: 568.60 +/- 152.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 1916304  |
---------------------------------
Eval num_timesteps=1918296, episode_reward=-254.84 +/- 42.18
Episode length: 558.20 +/- 41.58
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 558          |
|    mean_reward          | -255         |
| time/                   |              |
|    total_timesteps      | 1918296      |
| train/                  |              |
|    approx_kl            | 0.0058272295 |
|    clip_fraction        | 0.0697       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.23        |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.001        |
|    loss                 | -0.0343      |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00254     |
|    std                  | 1.15         |
|    value_loss           | 0.0876       |
------------------------------------------
Eval num_timesteps=1920288, episode_reward=-266.29 +/- 19.39
Episode length: 579.60 +/- 82.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 580      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 1920288  |
---------------------------------
Eval num_timesteps=1922280, episode_reward=-269.91 +/- 29.51
Episode length: 591.60 +/- 34.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 1922280  |
---------------------------------
Eval num_timesteps=1924272, episode_reward=-209.29 +/- 54.20
Episode length: 607.00 +/- 93.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 607      |
|    mean_reward     | -209     |
| time/              |          |
|    total_timesteps | 1924272  |
---------------------------------
Eval num_timesteps=1926264, episode_reward=-72.17 +/- 392.25
Episode length: 560.40 +/- 71.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | -72.2    |
| time/              |          |
|    total_timesteps | 1926264  |
---------------------------------
Eval num_timesteps=1928256, episode_reward=-200.91 +/- 95.87
Episode length: 632.60 +/- 69.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | -201     |
| time/              |          |
|    total_timesteps | 1928256  |
---------------------------------
Eval num_timesteps=1930248, episode_reward=-193.72 +/- 130.36
Episode length: 586.40 +/- 58.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | -194     |
| time/              |          |
|    total_timesteps | 1930248  |
---------------------------------
Eval num_timesteps=1932240, episode_reward=-191.77 +/- 149.25
Episode length: 590.20 +/- 61.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 590      |
|    mean_reward     | -192     |
| time/              |          |
|    total_timesteps | 1932240  |
---------------------------------
Eval num_timesteps=1934232, episode_reward=-280.55 +/- 17.63
Episode length: 516.00 +/- 33.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 1934232  |
---------------------------------
Eval num_timesteps=1936224, episode_reward=-234.20 +/- 55.84
Episode length: 532.20 +/- 45.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | -234     |
| time/              |          |
|    total_timesteps | 1936224  |
---------------------------------
Eval num_timesteps=1938216, episode_reward=-243.13 +/- 22.02
Episode length: 614.00 +/- 89.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | -243     |
| time/              |          |
|    total_timesteps | 1938216  |
---------------------------------
Eval num_timesteps=1940208, episode_reward=-273.35 +/- 15.34
Episode length: 552.40 +/- 43.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -273     |
| time/              |          |
|    total_timesteps | 1940208  |
---------------------------------
Eval num_timesteps=1942200, episode_reward=-257.11 +/- 43.26
Episode length: 565.40 +/- 36.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | -257     |
| time/              |          |
|    total_timesteps | 1942200  |
---------------------------------
Eval num_timesteps=1944192, episode_reward=-274.59 +/- 9.23
Episode length: 519.20 +/- 58.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 1944192  |
---------------------------------
Eval num_timesteps=1946184, episode_reward=-194.81 +/- 103.21
Episode length: 556.80 +/- 63.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | -195     |
| time/              |          |
|    total_timesteps | 1946184  |
---------------------------------
Eval num_timesteps=1948176, episode_reward=-285.20 +/- 29.05
Episode length: 562.40 +/- 29.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 1948176  |
---------------------------------
Eval num_timesteps=1950168, episode_reward=-255.07 +/- 30.63
Episode length: 629.20 +/- 28.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | -255     |
| time/              |          |
|    total_timesteps | 1950168  |
---------------------------------
Eval num_timesteps=1952160, episode_reward=-174.02 +/- 126.29
Episode length: 548.00 +/- 64.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | -174     |
| time/              |          |
|    total_timesteps | 1952160  |
---------------------------------
Eval num_timesteps=1954152, episode_reward=-183.46 +/- 147.47
Episode length: 567.00 +/- 45.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | -183     |
| time/              |          |
|    total_timesteps | 1954152  |
---------------------------------
Eval num_timesteps=1956144, episode_reward=-130.56 +/- 185.77
Episode length: 633.80 +/- 79.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 634      |
|    mean_reward     | -131     |
| time/              |          |
|    total_timesteps | 1956144  |
---------------------------------
Eval num_timesteps=1958136, episode_reward=-261.84 +/- 5.56
Episode length: 561.00 +/- 64.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | -262     |
| time/              |          |
|    total_timesteps | 1958136  |
---------------------------------
Eval num_timesteps=1960128, episode_reward=-230.59 +/- 44.80
Episode length: 619.60 +/- 70.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | -231     |
| time/              |          |
|    total_timesteps | 1960128  |
---------------------------------
Eval num_timesteps=1962120, episode_reward=-246.65 +/- 56.13
Episode length: 584.80 +/- 80.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | -247     |
| time/              |          |
|    total_timesteps | 1962120  |
---------------------------------
Eval num_timesteps=1964112, episode_reward=-204.68 +/- 138.81
Episode length: 598.80 +/- 76.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 599      |
|    mean_reward     | -205     |
| time/              |          |
|    total_timesteps | 1964112  |
---------------------------------
Eval num_timesteps=1966104, episode_reward=-215.45 +/- 48.17
Episode length: 546.40 +/- 71.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 546         |
|    mean_reward          | -215        |
| time/                   |             |
|    total_timesteps      | 1966104     |
| train/                  |             |
|    approx_kl            | 0.009351012 |
|    clip_fraction        | 0.0926      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0125     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00218    |
|    std                  | 1.16        |
|    value_loss           | 0.136       |
-----------------------------------------
Eval num_timesteps=1968096, episode_reward=-259.28 +/- 20.79
Episode length: 542.40 +/- 67.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | -259     |
| time/              |          |
|    total_timesteps | 1968096  |
---------------------------------
Eval num_timesteps=1970088, episode_reward=-179.83 +/- 126.84
Episode length: 551.60 +/- 47.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -180     |
| time/              |          |
|    total_timesteps | 1970088  |
---------------------------------
Eval num_timesteps=1972080, episode_reward=-19.13 +/- 423.48
Episode length: 527.80 +/- 46.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | -19.1    |
| time/              |          |
|    total_timesteps | 1972080  |
---------------------------------
Eval num_timesteps=1974072, episode_reward=-163.11 +/- 107.58
Episode length: 551.80 +/- 52.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -163     |
| time/              |          |
|    total_timesteps | 1974072  |
---------------------------------
Eval num_timesteps=1976064, episode_reward=-266.26 +/- 24.29
Episode length: 534.40 +/- 65.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 1976064  |
---------------------------------
Eval num_timesteps=1978056, episode_reward=67.91 +/- 387.61
Episode length: 605.80 +/- 92.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | 67.9     |
| time/              |          |
|    total_timesteps | 1978056  |
---------------------------------
Eval num_timesteps=1980048, episode_reward=-152.51 +/- 107.57
Episode length: 529.60 +/- 40.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | -153     |
| time/              |          |
|    total_timesteps | 1980048  |
---------------------------------
Eval num_timesteps=1982040, episode_reward=105.09 +/- 324.54
Episode length: 602.60 +/- 54.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | 105      |
| time/              |          |
|    total_timesteps | 1982040  |
---------------------------------
Eval num_timesteps=1984032, episode_reward=-197.83 +/- 92.94
Episode length: 514.20 +/- 88.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | -198     |
| time/              |          |
|    total_timesteps | 1984032  |
---------------------------------
Eval num_timesteps=1986024, episode_reward=-166.57 +/- 56.77
Episode length: 561.80 +/- 79.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | -167     |
| time/              |          |
|    total_timesteps | 1986024  |
---------------------------------
Eval num_timesteps=1988016, episode_reward=-238.51 +/- 18.91
Episode length: 588.60 +/- 29.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | -239     |
| time/              |          |
|    total_timesteps | 1988016  |
---------------------------------
Eval num_timesteps=1990008, episode_reward=-19.64 +/- 306.90
Episode length: 688.00 +/- 112.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 688      |
|    mean_reward     | -19.6    |
| time/              |          |
|    total_timesteps | 1990008  |
---------------------------------
Eval num_timesteps=1992000, episode_reward=-243.14 +/- 36.44
Episode length: 556.00 +/- 45.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | -243     |
| time/              |          |
|    total_timesteps | 1992000  |
---------------------------------
Eval num_timesteps=1993992, episode_reward=-169.54 +/- 89.77
Episode length: 585.60 +/- 87.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | -170     |
| time/              |          |
|    total_timesteps | 1993992  |
---------------------------------
Eval num_timesteps=1995984, episode_reward=-47.50 +/- 409.98
Episode length: 548.20 +/- 88.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | -47.5    |
| time/              |          |
|    total_timesteps | 1995984  |
---------------------------------
Eval num_timesteps=1997976, episode_reward=6.15 +/- 483.04
Episode length: 600.80 +/- 106.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 601      |
|    mean_reward     | 6.15     |
| time/              |          |
|    total_timesteps | 1997976  |
---------------------------------
Eval num_timesteps=1999968, episode_reward=-120.22 +/- 182.40
Episode length: 588.80 +/- 78.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | -120     |
| time/              |          |
|    total_timesteps | 1999968  |
---------------------------------
Eval num_timesteps=2001960, episode_reward=18.37 +/- 339.84
Episode length: 599.20 +/- 67.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 599      |
|    mean_reward     | 18.4     |
| time/              |          |
|    total_timesteps | 2001960  |
---------------------------------
Eval num_timesteps=2003952, episode_reward=-166.63 +/- 159.15
Episode length: 524.20 +/- 88.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | -167     |
| time/              |          |
|    total_timesteps | 2003952  |
---------------------------------
Eval num_timesteps=2005944, episode_reward=-60.00 +/- 168.82
Episode length: 557.20 +/- 41.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | -60      |
| time/              |          |
|    total_timesteps | 2005944  |
---------------------------------
Eval num_timesteps=2007936, episode_reward=-213.84 +/- 94.74
Episode length: 589.80 +/- 103.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 590      |
|    mean_reward     | -214     |
| time/              |          |
|    total_timesteps | 2007936  |
---------------------------------
Eval num_timesteps=2009928, episode_reward=-34.89 +/- 236.94
Episode length: 635.00 +/- 83.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | -34.9    |
| time/              |          |
|    total_timesteps | 2009928  |
---------------------------------
Eval num_timesteps=2011920, episode_reward=69.77 +/- 278.87
Episode length: 611.40 +/- 55.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 69.8     |
| time/              |          |
|    total_timesteps | 2011920  |
---------------------------------
Eval num_timesteps=2013912, episode_reward=-79.05 +/- 209.97
Episode length: 569.80 +/- 58.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | -79.1    |
| time/              |          |
|    total_timesteps | 2013912  |
---------------------------------
Eval num_timesteps=2015904, episode_reward=235.93 +/- 423.05
Episode length: 582.80 +/- 60.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 583        |
|    mean_reward          | 236        |
| time/                   |            |
|    total_timesteps      | 2015904    |
| train/                  |            |
|    approx_kl            | 0.00553902 |
|    clip_fraction        | 0.1        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0129     |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.00227   |
|    std                  | 1.17       |
|    value_loss           | 0.194      |
----------------------------------------
Eval num_timesteps=2017896, episode_reward=5.48 +/- 304.21
Episode length: 649.60 +/- 72.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 650      |
|    mean_reward     | 5.48     |
| time/              |          |
|    total_timesteps | 2017896  |
---------------------------------
Eval num_timesteps=2019888, episode_reward=-89.87 +/- 193.60
Episode length: 662.40 +/- 164.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | -89.9    |
| time/              |          |
|    total_timesteps | 2019888  |
---------------------------------
Eval num_timesteps=2021880, episode_reward=215.14 +/- 265.64
Episode length: 531.60 +/- 60.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 215      |
| time/              |          |
|    total_timesteps | 2021880  |
---------------------------------
Eval num_timesteps=2023872, episode_reward=-90.39 +/- 100.40
Episode length: 579.40 +/- 113.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 579      |
|    mean_reward     | -90.4    |
| time/              |          |
|    total_timesteps | 2023872  |
---------------------------------
Eval num_timesteps=2025864, episode_reward=159.40 +/- 410.91
Episode length: 594.00 +/- 57.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 159      |
| time/              |          |
|    total_timesteps | 2025864  |
---------------------------------
Eval num_timesteps=2027856, episode_reward=248.51 +/- 483.57
Episode length: 578.20 +/- 57.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 249      |
| time/              |          |
|    total_timesteps | 2027856  |
---------------------------------
New best mean reward!
Eval num_timesteps=2029848, episode_reward=282.09 +/- 353.68
Episode length: 594.20 +/- 48.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 282      |
| time/              |          |
|    total_timesteps | 2029848  |
---------------------------------
New best mean reward!
Eval num_timesteps=2031840, episode_reward=-133.33 +/- 136.09
Episode length: 573.40 +/- 120.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | -133     |
| time/              |          |
|    total_timesteps | 2031840  |
---------------------------------
Eval num_timesteps=2033832, episode_reward=359.88 +/- 347.56
Episode length: 613.40 +/- 92.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 360      |
| time/              |          |
|    total_timesteps | 2033832  |
---------------------------------
New best mean reward!
Eval num_timesteps=2035824, episode_reward=146.03 +/- 286.17
Episode length: 606.00 +/- 91.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | 146      |
| time/              |          |
|    total_timesteps | 2035824  |
---------------------------------
Eval num_timesteps=2037816, episode_reward=-189.65 +/- 75.11
Episode length: 553.00 +/- 131.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | -190     |
| time/              |          |
|    total_timesteps | 2037816  |
---------------------------------
Eval num_timesteps=2039808, episode_reward=543.47 +/- 209.55
Episode length: 591.60 +/- 40.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 543      |
| time/              |          |
|    total_timesteps | 2039808  |
---------------------------------
New best mean reward!
Eval num_timesteps=2041800, episode_reward=-85.00 +/- 125.50
Episode length: 597.60 +/- 167.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 598      |
|    mean_reward     | -85      |
| time/              |          |
|    total_timesteps | 2041800  |
---------------------------------
Eval num_timesteps=2043792, episode_reward=63.06 +/- 284.40
Episode length: 548.00 +/- 56.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | 63.1     |
| time/              |          |
|    total_timesteps | 2043792  |
---------------------------------
Eval num_timesteps=2045784, episode_reward=-196.01 +/- 53.58
Episode length: 618.80 +/- 56.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | -196     |
| time/              |          |
|    total_timesteps | 2045784  |
---------------------------------
Eval num_timesteps=2047776, episode_reward=77.50 +/- 320.82
Episode length: 583.80 +/- 33.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 77.5     |
| time/              |          |
|    total_timesteps | 2047776  |
---------------------------------
Eval num_timesteps=2049768, episode_reward=-60.43 +/- 126.08
Episode length: 631.20 +/- 50.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | -60.4    |
| time/              |          |
|    total_timesteps | 2049768  |
---------------------------------
Eval num_timesteps=2051760, episode_reward=142.44 +/- 325.88
Episode length: 629.00 +/- 98.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | 142      |
| time/              |          |
|    total_timesteps | 2051760  |
---------------------------------
Eval num_timesteps=2053752, episode_reward=50.70 +/- 234.69
Episode length: 580.60 +/- 65.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | 50.7     |
| time/              |          |
|    total_timesteps | 2053752  |
---------------------------------
Eval num_timesteps=2055744, episode_reward=-146.13 +/- 100.77
Episode length: 536.40 +/- 37.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | -146     |
| time/              |          |
|    total_timesteps | 2055744  |
---------------------------------
Eval num_timesteps=2057736, episode_reward=56.21 +/- 249.74
Episode length: 541.00 +/- 57.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 56.2     |
| time/              |          |
|    total_timesteps | 2057736  |
---------------------------------
Eval num_timesteps=2059728, episode_reward=185.25 +/- 514.68
Episode length: 640.00 +/- 74.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 640      |
|    mean_reward     | 185      |
| time/              |          |
|    total_timesteps | 2059728  |
---------------------------------
Eval num_timesteps=2061720, episode_reward=-58.25 +/- 216.69
Episode length: 597.00 +/- 93.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | -58.2    |
| time/              |          |
|    total_timesteps | 2061720  |
---------------------------------
Eval num_timesteps=2063712, episode_reward=-109.18 +/- 147.02
Episode length: 541.20 +/- 70.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | -109     |
| time/              |          |
|    total_timesteps | 2063712  |
---------------------------------
Eval num_timesteps=2065704, episode_reward=80.96 +/- 125.46
Episode length: 548.60 +/- 73.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 549         |
|    mean_reward          | 81          |
| time/                   |             |
|    total_timesteps      | 2065704     |
| train/                  |             |
|    approx_kl            | 0.008756591 |
|    clip_fraction        | 0.0946      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.31       |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.001       |
|    loss                 | 0.0835      |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00153    |
|    std                  | 1.18        |
|    value_loss           | 0.34        |
-----------------------------------------
Eval num_timesteps=2067696, episode_reward=184.58 +/- 297.36
Episode length: 537.20 +/- 48.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 185      |
| time/              |          |
|    total_timesteps | 2067696  |
---------------------------------
Eval num_timesteps=2069688, episode_reward=352.64 +/- 308.20
Episode length: 523.20 +/- 32.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 353      |
| time/              |          |
|    total_timesteps | 2069688  |
---------------------------------
Eval num_timesteps=2071680, episode_reward=253.64 +/- 353.80
Episode length: 595.40 +/- 91.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 254      |
| time/              |          |
|    total_timesteps | 2071680  |
---------------------------------
Eval num_timesteps=2073672, episode_reward=143.46 +/- 265.02
Episode length: 513.40 +/- 32.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 143      |
| time/              |          |
|    total_timesteps | 2073672  |
---------------------------------
Eval num_timesteps=2075664, episode_reward=211.57 +/- 431.33
Episode length: 512.80 +/- 82.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 212      |
| time/              |          |
|    total_timesteps | 2075664  |
---------------------------------
Eval num_timesteps=2077656, episode_reward=294.39 +/- 316.41
Episode length: 549.40 +/- 75.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 294      |
| time/              |          |
|    total_timesteps | 2077656  |
---------------------------------
Eval num_timesteps=2079648, episode_reward=73.54 +/- 217.46
Episode length: 573.00 +/- 73.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 73.5     |
| time/              |          |
|    total_timesteps | 2079648  |
---------------------------------
Eval num_timesteps=2081640, episode_reward=250.65 +/- 334.32
Episode length: 531.60 +/- 94.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 251      |
| time/              |          |
|    total_timesteps | 2081640  |
---------------------------------
Eval num_timesteps=2083632, episode_reward=250.00 +/- 330.98
Episode length: 609.60 +/- 51.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 250      |
| time/              |          |
|    total_timesteps | 2083632  |
---------------------------------
Eval num_timesteps=2085624, episode_reward=88.33 +/- 139.26
Episode length: 594.60 +/- 116.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 88.3     |
| time/              |          |
|    total_timesteps | 2085624  |
---------------------------------
Eval num_timesteps=2087616, episode_reward=473.41 +/- 443.46
Episode length: 625.00 +/- 146.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 473      |
| time/              |          |
|    total_timesteps | 2087616  |
---------------------------------
Eval num_timesteps=2089608, episode_reward=80.88 +/- 176.36
Episode length: 595.00 +/- 113.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 80.9     |
| time/              |          |
|    total_timesteps | 2089608  |
---------------------------------
Eval num_timesteps=2091600, episode_reward=264.27 +/- 140.75
Episode length: 588.00 +/- 35.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 264      |
| time/              |          |
|    total_timesteps | 2091600  |
---------------------------------
Eval num_timesteps=2093592, episode_reward=77.82 +/- 203.16
Episode length: 548.80 +/- 31.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 77.8     |
| time/              |          |
|    total_timesteps | 2093592  |
---------------------------------
Eval num_timesteps=2095584, episode_reward=150.67 +/- 430.46
Episode length: 557.00 +/- 30.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 151      |
| time/              |          |
|    total_timesteps | 2095584  |
---------------------------------
Eval num_timesteps=2097576, episode_reward=166.84 +/- 243.17
Episode length: 546.60 +/- 71.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 167      |
| time/              |          |
|    total_timesteps | 2097576  |
---------------------------------
Eval num_timesteps=2099568, episode_reward=173.70 +/- 383.24
Episode length: 539.00 +/- 60.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | 174      |
| time/              |          |
|    total_timesteps | 2099568  |
---------------------------------
Eval num_timesteps=2101560, episode_reward=727.66 +/- 674.36
Episode length: 614.00 +/- 59.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 728      |
| time/              |          |
|    total_timesteps | 2101560  |
---------------------------------
New best mean reward!
Eval num_timesteps=2103552, episode_reward=-31.01 +/- 40.44
Episode length: 529.00 +/- 26.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | -31      |
| time/              |          |
|    total_timesteps | 2103552  |
---------------------------------
Eval num_timesteps=2105544, episode_reward=209.43 +/- 295.66
Episode length: 483.40 +/- 35.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | 209      |
| time/              |          |
|    total_timesteps | 2105544  |
---------------------------------
Eval num_timesteps=2107536, episode_reward=212.42 +/- 304.54
Episode length: 558.60 +/- 29.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 212      |
| time/              |          |
|    total_timesteps | 2107536  |
---------------------------------
Eval num_timesteps=2109528, episode_reward=32.79 +/- 148.48
Episode length: 482.00 +/- 22.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 32.8     |
| time/              |          |
|    total_timesteps | 2109528  |
---------------------------------
Eval num_timesteps=2111520, episode_reward=-8.28 +/- 111.32
Episode length: 527.80 +/- 52.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | -8.28    |
| time/              |          |
|    total_timesteps | 2111520  |
---------------------------------
Eval num_timesteps=2113512, episode_reward=133.47 +/- 203.12
Episode length: 531.40 +/- 53.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 133      |
| time/              |          |
|    total_timesteps | 2113512  |
---------------------------------
Eval num_timesteps=2115504, episode_reward=194.85 +/- 29.87
Episode length: 454.40 +/- 25.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 454         |
|    mean_reward          | 195         |
| time/                   |             |
|    total_timesteps      | 2115504     |
| train/                  |             |
|    approx_kl            | 0.008691849 |
|    clip_fraction        | 0.0968      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.001       |
|    loss                 | 0.127       |
|    n_updates            | 430         |
|    policy_gradient_loss | 0.000114    |
|    std                  | 1.18        |
|    value_loss           | 0.465       |
-----------------------------------------
Eval num_timesteps=2117496, episode_reward=493.07 +/- 510.49
Episode length: 490.60 +/- 95.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 493      |
| time/              |          |
|    total_timesteps | 2117496  |
---------------------------------
Eval num_timesteps=2119488, episode_reward=239.05 +/- 140.49
Episode length: 455.80 +/- 48.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | 239      |
| time/              |          |
|    total_timesteps | 2119488  |
---------------------------------
Eval num_timesteps=2121480, episode_reward=278.93 +/- 157.78
Episode length: 482.20 +/- 63.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 279      |
| time/              |          |
|    total_timesteps | 2121480  |
---------------------------------
Eval num_timesteps=2123472, episode_reward=217.30 +/- 106.39
Episode length: 458.20 +/- 50.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 458      |
|    mean_reward     | 217      |
| time/              |          |
|    total_timesteps | 2123472  |
---------------------------------
Eval num_timesteps=2125464, episode_reward=331.75 +/- 289.82
Episode length: 461.60 +/- 59.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 462      |
|    mean_reward     | 332      |
| time/              |          |
|    total_timesteps | 2125464  |
---------------------------------
Eval num_timesteps=2127456, episode_reward=152.08 +/- 205.76
Episode length: 443.20 +/- 81.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | 152      |
| time/              |          |
|    total_timesteps | 2127456  |
---------------------------------
Eval num_timesteps=2129448, episode_reward=456.90 +/- 329.99
Episode length: 527.60 +/- 18.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 457      |
| time/              |          |
|    total_timesteps | 2129448  |
---------------------------------
Eval num_timesteps=2131440, episode_reward=222.64 +/- 153.39
Episode length: 463.40 +/- 60.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 463      |
|    mean_reward     | 223      |
| time/              |          |
|    total_timesteps | 2131440  |
---------------------------------
Eval num_timesteps=2133432, episode_reward=205.34 +/- 140.83
Episode length: 448.80 +/- 64.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | 205      |
| time/              |          |
|    total_timesteps | 2133432  |
---------------------------------
Eval num_timesteps=2135424, episode_reward=224.09 +/- 172.33
Episode length: 414.00 +/- 74.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 414      |
|    mean_reward     | 224      |
| time/              |          |
|    total_timesteps | 2135424  |
---------------------------------
Eval num_timesteps=2137416, episode_reward=171.13 +/- 121.22
Episode length: 464.80 +/- 29.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | 171      |
| time/              |          |
|    total_timesteps | 2137416  |
---------------------------------
Eval num_timesteps=2139408, episode_reward=235.40 +/- 183.15
Episode length: 423.80 +/- 62.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | 235      |
| time/              |          |
|    total_timesteps | 2139408  |
---------------------------------
Eval num_timesteps=2141400, episode_reward=356.88 +/- 381.68
Episode length: 523.40 +/- 71.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 357      |
| time/              |          |
|    total_timesteps | 2141400  |
---------------------------------
Eval num_timesteps=2143392, episode_reward=113.15 +/- 122.16
Episode length: 424.80 +/- 68.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | 113      |
| time/              |          |
|    total_timesteps | 2143392  |
---------------------------------
Eval num_timesteps=2145384, episode_reward=429.22 +/- 223.13
Episode length: 460.00 +/- 30.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 429      |
| time/              |          |
|    total_timesteps | 2145384  |
---------------------------------
Eval num_timesteps=2147376, episode_reward=98.66 +/- 132.99
Episode length: 472.00 +/- 106.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | 98.7     |
| time/              |          |
|    total_timesteps | 2147376  |
---------------------------------
Eval num_timesteps=2149368, episode_reward=248.10 +/- 192.63
Episode length: 508.60 +/- 52.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 248      |
| time/              |          |
|    total_timesteps | 2149368  |
---------------------------------
Eval num_timesteps=2151360, episode_reward=242.11 +/- 212.54
Episode length: 519.40 +/- 60.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 242      |
| time/              |          |
|    total_timesteps | 2151360  |
---------------------------------
Eval num_timesteps=2153352, episode_reward=266.72 +/- 156.64
Episode length: 428.20 +/- 37.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | 267      |
| time/              |          |
|    total_timesteps | 2153352  |
---------------------------------
Eval num_timesteps=2155344, episode_reward=276.66 +/- 147.73
Episode length: 466.00 +/- 27.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 277      |
| time/              |          |
|    total_timesteps | 2155344  |
---------------------------------
Eval num_timesteps=2157336, episode_reward=358.75 +/- 110.83
Episode length: 477.00 +/- 33.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 359      |
| time/              |          |
|    total_timesteps | 2157336  |
---------------------------------
Eval num_timesteps=2159328, episode_reward=566.77 +/- 427.89
Episode length: 509.60 +/- 95.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 567      |
| time/              |          |
|    total_timesteps | 2159328  |
---------------------------------
Eval num_timesteps=2161320, episode_reward=266.06 +/- 313.07
Episode length: 460.20 +/- 67.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 266      |
| time/              |          |
|    total_timesteps | 2161320  |
---------------------------------
Eval num_timesteps=2163312, episode_reward=208.14 +/- 129.78
Episode length: 408.00 +/- 42.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 408         |
|    mean_reward          | 208         |
| time/                   |             |
|    total_timesteps      | 2163312     |
| train/                  |             |
|    approx_kl            | 0.008236473 |
|    clip_fraction        | 0.093       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.34       |
|    explained_variance   | 0.923       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0912      |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00163    |
|    std                  | 1.18        |
|    value_loss           | 0.385       |
-----------------------------------------
Eval num_timesteps=2165304, episode_reward=313.42 +/- 175.54
Episode length: 412.80 +/- 45.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 413      |
|    mean_reward     | 313      |
| time/              |          |
|    total_timesteps | 2165304  |
---------------------------------
Eval num_timesteps=2167296, episode_reward=198.40 +/- 108.19
Episode length: 429.20 +/- 55.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 429      |
|    mean_reward     | 198      |
| time/              |          |
|    total_timesteps | 2167296  |
---------------------------------
Eval num_timesteps=2169288, episode_reward=228.49 +/- 110.65
Episode length: 385.80 +/- 28.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 228      |
| time/              |          |
|    total_timesteps | 2169288  |
---------------------------------
Eval num_timesteps=2171280, episode_reward=-0.76 +/- 51.71
Episode length: 351.40 +/- 66.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 351      |
|    mean_reward     | -0.764   |
| time/              |          |
|    total_timesteps | 2171280  |
---------------------------------
Eval num_timesteps=2173272, episode_reward=128.54 +/- 57.80
Episode length: 393.00 +/- 24.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 393      |
|    mean_reward     | 129      |
| time/              |          |
|    total_timesteps | 2173272  |
---------------------------------
Eval num_timesteps=2175264, episode_reward=268.62 +/- 160.74
Episode length: 425.00 +/- 36.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | 269      |
| time/              |          |
|    total_timesteps | 2175264  |
---------------------------------
Eval num_timesteps=2177256, episode_reward=237.80 +/- 193.36
Episode length: 423.80 +/- 42.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | 238      |
| time/              |          |
|    total_timesteps | 2177256  |
---------------------------------
Eval num_timesteps=2179248, episode_reward=156.96 +/- 84.21
Episode length: 405.60 +/- 49.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 406      |
|    mean_reward     | 157      |
| time/              |          |
|    total_timesteps | 2179248  |
---------------------------------
Eval num_timesteps=2181240, episode_reward=311.30 +/- 239.52
Episode length: 414.40 +/- 64.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 414      |
|    mean_reward     | 311      |
| time/              |          |
|    total_timesteps | 2181240  |
---------------------------------
Eval num_timesteps=2183232, episode_reward=245.15 +/- 317.92
Episode length: 408.00 +/- 79.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | 245      |
| time/              |          |
|    total_timesteps | 2183232  |
---------------------------------
Eval num_timesteps=2185224, episode_reward=164.52 +/- 256.99
Episode length: 370.60 +/- 100.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 371      |
|    mean_reward     | 165      |
| time/              |          |
|    total_timesteps | 2185224  |
---------------------------------
Eval num_timesteps=2187216, episode_reward=46.16 +/- 141.67
Episode length: 368.60 +/- 91.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 369      |
|    mean_reward     | 46.2     |
| time/              |          |
|    total_timesteps | 2187216  |
---------------------------------
Eval num_timesteps=2189208, episode_reward=206.39 +/- 179.48
Episode length: 425.40 +/- 64.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | 206      |
| time/              |          |
|    total_timesteps | 2189208  |
---------------------------------
Eval num_timesteps=2191200, episode_reward=183.04 +/- 181.42
Episode length: 376.20 +/- 65.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 376      |
|    mean_reward     | 183      |
| time/              |          |
|    total_timesteps | 2191200  |
---------------------------------
Eval num_timesteps=2193192, episode_reward=148.47 +/- 123.08
Episode length: 397.20 +/- 64.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 397      |
|    mean_reward     | 148      |
| time/              |          |
|    total_timesteps | 2193192  |
---------------------------------
Eval num_timesteps=2195184, episode_reward=132.47 +/- 122.60
Episode length: 368.00 +/- 49.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 368      |
|    mean_reward     | 132      |
| time/              |          |
|    total_timesteps | 2195184  |
---------------------------------
Eval num_timesteps=2197176, episode_reward=253.10 +/- 169.60
Episode length: 431.20 +/- 46.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 431      |
|    mean_reward     | 253      |
| time/              |          |
|    total_timesteps | 2197176  |
---------------------------------
Eval num_timesteps=2199168, episode_reward=251.01 +/- 180.00
Episode length: 415.80 +/- 66.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | 251      |
| time/              |          |
|    total_timesteps | 2199168  |
---------------------------------
Eval num_timesteps=2201160, episode_reward=107.32 +/- 57.14
Episode length: 397.60 +/- 30.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 398      |
|    mean_reward     | 107      |
| time/              |          |
|    total_timesteps | 2201160  |
---------------------------------
Eval num_timesteps=2203152, episode_reward=84.68 +/- 111.73
Episode length: 380.00 +/- 73.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | 84.7     |
| time/              |          |
|    total_timesteps | 2203152  |
---------------------------------
Eval num_timesteps=2205144, episode_reward=95.15 +/- 60.66
Episode length: 372.20 +/- 25.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 372      |
|    mean_reward     | 95.1     |
| time/              |          |
|    total_timesteps | 2205144  |
---------------------------------
Eval num_timesteps=2207136, episode_reward=423.65 +/- 232.34
Episode length: 476.60 +/- 87.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 424      |
| time/              |          |
|    total_timesteps | 2207136  |
---------------------------------
Eval num_timesteps=2209128, episode_reward=229.31 +/- 105.40
Episode length: 385.00 +/- 22.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 385      |
|    mean_reward     | 229      |
| time/              |          |
|    total_timesteps | 2209128  |
---------------------------------
Eval num_timesteps=2211120, episode_reward=76.97 +/- 175.95
Episode length: 347.40 +/- 74.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 347      |
|    mean_reward     | 77       |
| time/              |          |
|    total_timesteps | 2211120  |
---------------------------------
Eval num_timesteps=2213112, episode_reward=170.05 +/- 167.54
Episode length: 379.80 +/- 60.49
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 380          |
|    mean_reward          | 170          |
| time/                   |              |
|    total_timesteps      | 2213112      |
| train/                  |              |
|    approx_kl            | 0.0068956534 |
|    clip_fraction        | 0.0953       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.36        |
|    explained_variance   | 0.94         |
|    learning_rate        | 0.001        |
|    loss                 | 0.049        |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00116     |
|    std                  | 1.19         |
|    value_loss           | 0.258        |
------------------------------------------
Eval num_timesteps=2215104, episode_reward=164.55 +/- 121.73
Episode length: 400.80 +/- 58.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 401      |
|    mean_reward     | 165      |
| time/              |          |
|    total_timesteps | 2215104  |
---------------------------------
Eval num_timesteps=2217096, episode_reward=366.67 +/- 248.22
Episode length: 435.40 +/- 58.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | 367      |
| time/              |          |
|    total_timesteps | 2217096  |
---------------------------------
Eval num_timesteps=2219088, episode_reward=87.44 +/- 93.32
Episode length: 364.80 +/- 38.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 365      |
|    mean_reward     | 87.4     |
| time/              |          |
|    total_timesteps | 2219088  |
---------------------------------
Eval num_timesteps=2221080, episode_reward=326.08 +/- 211.48
Episode length: 406.60 +/- 36.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 407      |
|    mean_reward     | 326      |
| time/              |          |
|    total_timesteps | 2221080  |
---------------------------------
Eval num_timesteps=2223072, episode_reward=253.24 +/- 190.62
Episode length: 401.60 +/- 36.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 402      |
|    mean_reward     | 253      |
| time/              |          |
|    total_timesteps | 2223072  |
---------------------------------
Eval num_timesteps=2225064, episode_reward=237.34 +/- 244.87
Episode length: 379.80 +/- 52.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | 237      |
| time/              |          |
|    total_timesteps | 2225064  |
---------------------------------
Eval num_timesteps=2227056, episode_reward=149.11 +/- 188.40
Episode length: 437.80 +/- 151.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | 149      |
| time/              |          |
|    total_timesteps | 2227056  |
---------------------------------
Eval num_timesteps=2229048, episode_reward=202.04 +/- 100.38
Episode length: 395.60 +/- 17.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 396      |
|    mean_reward     | 202      |
| time/              |          |
|    total_timesteps | 2229048  |
---------------------------------
Eval num_timesteps=2231040, episode_reward=222.12 +/- 230.43
Episode length: 391.00 +/- 49.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | 222      |
| time/              |          |
|    total_timesteps | 2231040  |
---------------------------------
Eval num_timesteps=2233032, episode_reward=354.71 +/- 308.79
Episode length: 407.40 +/- 35.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 407      |
|    mean_reward     | 355      |
| time/              |          |
|    total_timesteps | 2233032  |
---------------------------------
Eval num_timesteps=2235024, episode_reward=142.54 +/- 164.39
Episode length: 366.40 +/- 52.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 366      |
|    mean_reward     | 143      |
| time/              |          |
|    total_timesteps | 2235024  |
---------------------------------
Eval num_timesteps=2237016, episode_reward=220.12 +/- 144.51
Episode length: 416.20 +/- 59.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 416      |
|    mean_reward     | 220      |
| time/              |          |
|    total_timesteps | 2237016  |
---------------------------------
Eval num_timesteps=2239008, episode_reward=201.73 +/- 93.12
Episode length: 385.60 +/- 20.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 202      |
| time/              |          |
|    total_timesteps | 2239008  |
---------------------------------
Eval num_timesteps=2241000, episode_reward=279.66 +/- 194.75
Episode length: 418.20 +/- 65.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 418      |
|    mean_reward     | 280      |
| time/              |          |
|    total_timesteps | 2241000  |
---------------------------------
Eval num_timesteps=2242992, episode_reward=37.57 +/- 82.35
Episode length: 334.20 +/- 38.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 334      |
|    mean_reward     | 37.6     |
| time/              |          |
|    total_timesteps | 2242992  |
---------------------------------
Eval num_timesteps=2244984, episode_reward=71.31 +/- 144.11
Episode length: 350.00 +/- 34.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 71.3     |
| time/              |          |
|    total_timesteps | 2244984  |
---------------------------------
Eval num_timesteps=2246976, episode_reward=159.27 +/- 131.76
Episode length: 381.60 +/- 32.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 382      |
|    mean_reward     | 159      |
| time/              |          |
|    total_timesteps | 2246976  |
---------------------------------
Eval num_timesteps=2248968, episode_reward=67.65 +/- 130.31
Episode length: 347.60 +/- 63.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 348      |
|    mean_reward     | 67.6     |
| time/              |          |
|    total_timesteps | 2248968  |
---------------------------------
Eval num_timesteps=2250960, episode_reward=152.00 +/- 96.89
Episode length: 413.80 +/- 54.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 414      |
|    mean_reward     | 152      |
| time/              |          |
|    total_timesteps | 2250960  |
---------------------------------
Eval num_timesteps=2252952, episode_reward=92.87 +/- 146.36
Episode length: 345.60 +/- 48.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 346      |
|    mean_reward     | 92.9     |
| time/              |          |
|    total_timesteps | 2252952  |
---------------------------------
Eval num_timesteps=2254944, episode_reward=149.27 +/- 39.74
Episode length: 395.80 +/- 16.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 396      |
|    mean_reward     | 149      |
| time/              |          |
|    total_timesteps | 2254944  |
---------------------------------
Eval num_timesteps=2256936, episode_reward=158.55 +/- 126.22
Episode length: 373.40 +/- 27.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 373      |
|    mean_reward     | 159      |
| time/              |          |
|    total_timesteps | 2256936  |
---------------------------------
Eval num_timesteps=2258928, episode_reward=161.36 +/- 129.75
Episode length: 362.80 +/- 46.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 363      |
|    mean_reward     | 161      |
| time/              |          |
|    total_timesteps | 2258928  |
---------------------------------
Eval num_timesteps=2260920, episode_reward=138.11 +/- 150.07
Episode length: 386.40 +/- 50.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 138      |
| time/              |          |
|    total_timesteps | 2260920  |
---------------------------------
Eval num_timesteps=2262912, episode_reward=407.70 +/- 274.66
Episode length: 447.80 +/- 99.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 448         |
|    mean_reward          | 408         |
| time/                   |             |
|    total_timesteps      | 2262912     |
| train/                  |             |
|    approx_kl            | 0.005790944 |
|    clip_fraction        | 0.0698      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.38       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.001       |
|    loss                 | 0.024       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00128    |
|    std                  | 1.2         |
|    value_loss           | 0.203       |
-----------------------------------------
Eval num_timesteps=2264904, episode_reward=290.96 +/- 154.34
Episode length: 406.00 +/- 40.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 406      |
|    mean_reward     | 291      |
| time/              |          |
|    total_timesteps | 2264904  |
---------------------------------
Eval num_timesteps=2266896, episode_reward=494.41 +/- 206.36
Episode length: 439.00 +/- 48.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | 494      |
| time/              |          |
|    total_timesteps | 2266896  |
---------------------------------
Eval num_timesteps=2268888, episode_reward=362.84 +/- 213.37
Episode length: 446.20 +/- 58.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 2268888  |
---------------------------------
Eval num_timesteps=2270880, episode_reward=499.83 +/- 69.57
Episode length: 457.00 +/- 54.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 457      |
|    mean_reward     | 500      |
| time/              |          |
|    total_timesteps | 2270880  |
---------------------------------
Eval num_timesteps=2272872, episode_reward=260.97 +/- 276.53
Episode length: 395.40 +/- 43.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 395      |
|    mean_reward     | 261      |
| time/              |          |
|    total_timesteps | 2272872  |
---------------------------------
Eval num_timesteps=2274864, episode_reward=508.72 +/- 336.30
Episode length: 469.00 +/- 21.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 469      |
|    mean_reward     | 509      |
| time/              |          |
|    total_timesteps | 2274864  |
---------------------------------
Eval num_timesteps=2276856, episode_reward=327.25 +/- 167.04
Episode length: 436.80 +/- 38.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 437      |
|    mean_reward     | 327      |
| time/              |          |
|    total_timesteps | 2276856  |
---------------------------------
Eval num_timesteps=2278848, episode_reward=609.76 +/- 326.32
Episode length: 511.80 +/- 86.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 610      |
| time/              |          |
|    total_timesteps | 2278848  |
---------------------------------
Eval num_timesteps=2280840, episode_reward=175.27 +/- 180.63
Episode length: 388.60 +/- 27.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | 175      |
| time/              |          |
|    total_timesteps | 2280840  |
---------------------------------
Eval num_timesteps=2282832, episode_reward=513.13 +/- 586.81
Episode length: 435.60 +/- 112.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | 513      |
| time/              |          |
|    total_timesteps | 2282832  |
---------------------------------
Eval num_timesteps=2284824, episode_reward=399.37 +/- 175.49
Episode length: 473.20 +/- 27.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | 399      |
| time/              |          |
|    total_timesteps | 2284824  |
---------------------------------
Eval num_timesteps=2286816, episode_reward=358.44 +/- 111.59
Episode length: 476.60 +/- 62.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 358      |
| time/              |          |
|    total_timesteps | 2286816  |
---------------------------------
Eval num_timesteps=2288808, episode_reward=427.38 +/- 353.80
Episode length: 435.60 +/- 62.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | 427      |
| time/              |          |
|    total_timesteps | 2288808  |
---------------------------------
Eval num_timesteps=2290800, episode_reward=185.72 +/- 30.17
Episode length: 396.60 +/- 11.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 397      |
|    mean_reward     | 186      |
| time/              |          |
|    total_timesteps | 2290800  |
---------------------------------
Eval num_timesteps=2292792, episode_reward=506.10 +/- 268.00
Episode length: 449.00 +/- 94.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 449      |
|    mean_reward     | 506      |
| time/              |          |
|    total_timesteps | 2292792  |
---------------------------------
Eval num_timesteps=2294784, episode_reward=528.99 +/- 323.68
Episode length: 449.80 +/- 52.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 529      |
| time/              |          |
|    total_timesteps | 2294784  |
---------------------------------
Eval num_timesteps=2296776, episode_reward=337.20 +/- 241.73
Episode length: 459.60 +/- 68.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 337      |
| time/              |          |
|    total_timesteps | 2296776  |
---------------------------------
Eval num_timesteps=2298768, episode_reward=236.64 +/- 100.23
Episode length: 405.20 +/- 39.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 405      |
|    mean_reward     | 237      |
| time/              |          |
|    total_timesteps | 2298768  |
---------------------------------
Eval num_timesteps=2300760, episode_reward=245.68 +/- 155.39
Episode length: 443.00 +/- 32.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | 246      |
| time/              |          |
|    total_timesteps | 2300760  |
---------------------------------
Eval num_timesteps=2302752, episode_reward=519.88 +/- 155.70
Episode length: 472.60 +/- 55.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | 520      |
| time/              |          |
|    total_timesteps | 2302752  |
---------------------------------
Eval num_timesteps=2304744, episode_reward=78.37 +/- 51.65
Episode length: 415.00 +/- 51.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 415      |
|    mean_reward     | 78.4     |
| time/              |          |
|    total_timesteps | 2304744  |
---------------------------------
Eval num_timesteps=2306736, episode_reward=486.23 +/- 361.62
Episode length: 422.80 +/- 64.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 423      |
|    mean_reward     | 486      |
| time/              |          |
|    total_timesteps | 2306736  |
---------------------------------
Eval num_timesteps=2308728, episode_reward=307.62 +/- 178.11
Episode length: 408.00 +/- 50.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 408      |
|    mean_reward     | 308      |
| time/              |          |
|    total_timesteps | 2308728  |
---------------------------------
Eval num_timesteps=2310720, episode_reward=644.50 +/- 336.66
Episode length: 477.40 +/- 70.98
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 477          |
|    mean_reward          | 645          |
| time/                   |              |
|    total_timesteps      | 2310720      |
| train/                  |              |
|    approx_kl            | 0.0059147803 |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.4         |
|    explained_variance   | 0.968        |
|    learning_rate        | 0.001        |
|    loss                 | -0.00676     |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00218     |
|    std                  | 1.2          |
|    value_loss           | 0.161        |
------------------------------------------
Eval num_timesteps=2312712, episode_reward=868.50 +/- 396.16
Episode length: 499.80 +/- 60.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 868      |
| time/              |          |
|    total_timesteps | 2312712  |
---------------------------------
New best mean reward!
Eval num_timesteps=2314704, episode_reward=772.50 +/- 427.39
Episode length: 503.60 +/- 97.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 773      |
| time/              |          |
|    total_timesteps | 2314704  |
---------------------------------
Eval num_timesteps=2316696, episode_reward=537.45 +/- 208.42
Episode length: 423.60 +/- 27.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | 537      |
| time/              |          |
|    total_timesteps | 2316696  |
---------------------------------
Eval num_timesteps=2318688, episode_reward=474.52 +/- 264.05
Episode length: 462.40 +/- 55.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 462      |
|    mean_reward     | 475      |
| time/              |          |
|    total_timesteps | 2318688  |
---------------------------------
Eval num_timesteps=2320680, episode_reward=547.61 +/- 160.99
Episode length: 535.00 +/- 73.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 548      |
| time/              |          |
|    total_timesteps | 2320680  |
---------------------------------
Eval num_timesteps=2322672, episode_reward=616.64 +/- 111.97
Episode length: 490.00 +/- 89.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | 617      |
| time/              |          |
|    total_timesteps | 2322672  |
---------------------------------
Eval num_timesteps=2324664, episode_reward=546.82 +/- 258.91
Episode length: 442.60 +/- 58.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 443      |
|    mean_reward     | 547      |
| time/              |          |
|    total_timesteps | 2324664  |
---------------------------------
Eval num_timesteps=2326656, episode_reward=883.98 +/- 355.30
Episode length: 488.80 +/- 54.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 884      |
| time/              |          |
|    total_timesteps | 2326656  |
---------------------------------
New best mean reward!
Eval num_timesteps=2328648, episode_reward=611.02 +/- 303.92
Episode length: 491.60 +/- 51.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 2328648  |
---------------------------------
Eval num_timesteps=2330640, episode_reward=609.10 +/- 188.40
Episode length: 465.40 +/- 65.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | 609      |
| time/              |          |
|    total_timesteps | 2330640  |
---------------------------------
Eval num_timesteps=2332632, episode_reward=605.03 +/- 302.18
Episode length: 482.40 +/- 58.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 605      |
| time/              |          |
|    total_timesteps | 2332632  |
---------------------------------
Eval num_timesteps=2334624, episode_reward=492.05 +/- 280.61
Episode length: 459.80 +/- 51.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 492      |
| time/              |          |
|    total_timesteps | 2334624  |
---------------------------------
Eval num_timesteps=2336616, episode_reward=588.12 +/- 150.76
Episode length: 484.80 +/- 77.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 485      |
|    mean_reward     | 588      |
| time/              |          |
|    total_timesteps | 2336616  |
---------------------------------
Eval num_timesteps=2338608, episode_reward=639.18 +/- 412.17
Episode length: 499.20 +/- 87.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 499      |
|    mean_reward     | 639      |
| time/              |          |
|    total_timesteps | 2338608  |
---------------------------------
Eval num_timesteps=2340600, episode_reward=505.73 +/- 225.87
Episode length: 477.60 +/- 31.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | 506      |
| time/              |          |
|    total_timesteps | 2340600  |
---------------------------------
Eval num_timesteps=2342592, episode_reward=772.31 +/- 432.59
Episode length: 509.80 +/- 62.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 772      |
| time/              |          |
|    total_timesteps | 2342592  |
---------------------------------
Eval num_timesteps=2344584, episode_reward=465.97 +/- 196.88
Episode length: 438.00 +/- 48.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | 466      |
| time/              |          |
|    total_timesteps | 2344584  |
---------------------------------
Eval num_timesteps=2346576, episode_reward=536.74 +/- 79.58
Episode length: 482.80 +/- 21.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | 537      |
| time/              |          |
|    total_timesteps | 2346576  |
---------------------------------
Eval num_timesteps=2348568, episode_reward=575.33 +/- 153.94
Episode length: 447.80 +/- 18.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | 575      |
| time/              |          |
|    total_timesteps | 2348568  |
---------------------------------
Eval num_timesteps=2350560, episode_reward=523.99 +/- 129.16
Episode length: 467.40 +/- 36.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 467      |
|    mean_reward     | 524      |
| time/              |          |
|    total_timesteps | 2350560  |
---------------------------------
Eval num_timesteps=2352552, episode_reward=606.91 +/- 284.60
Episode length: 530.20 +/- 77.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 607      |
| time/              |          |
|    total_timesteps | 2352552  |
---------------------------------
Eval num_timesteps=2354544, episode_reward=309.68 +/- 197.89
Episode length: 473.20 +/- 125.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | 310      |
| time/              |          |
|    total_timesteps | 2354544  |
---------------------------------
Eval num_timesteps=2356536, episode_reward=918.24 +/- 547.84
Episode length: 579.20 +/- 153.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 579      |
|    mean_reward     | 918      |
| time/              |          |
|    total_timesteps | 2356536  |
---------------------------------
New best mean reward!
Eval num_timesteps=2358528, episode_reward=736.48 +/- 455.29
Episode length: 525.00 +/- 97.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 736      |
| time/              |          |
|    total_timesteps | 2358528  |
---------------------------------
Eval num_timesteps=2360520, episode_reward=676.75 +/- 331.25
Episode length: 480.60 +/- 29.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 481         |
|    mean_reward          | 677         |
| time/                   |             |
|    total_timesteps      | 2360520     |
| train/                  |             |
|    approx_kl            | 0.005644265 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.41       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.001       |
|    loss                 | 0.086       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.000964   |
|    std                  | 1.2         |
|    value_loss           | 0.32        |
-----------------------------------------
Eval num_timesteps=2362512, episode_reward=671.18 +/- 112.46
Episode length: 531.60 +/- 81.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 671      |
| time/              |          |
|    total_timesteps | 2362512  |
---------------------------------
Eval num_timesteps=2364504, episode_reward=657.43 +/- 87.60
Episode length: 582.00 +/- 110.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 657      |
| time/              |          |
|    total_timesteps | 2364504  |
---------------------------------
Eval num_timesteps=2366496, episode_reward=737.51 +/- 150.97
Episode length: 605.00 +/- 160.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | 738      |
| time/              |          |
|    total_timesteps | 2366496  |
---------------------------------
Eval num_timesteps=2368488, episode_reward=756.34 +/- 255.93
Episode length: 526.20 +/- 33.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 756      |
| time/              |          |
|    total_timesteps | 2368488  |
---------------------------------
Eval num_timesteps=2370480, episode_reward=603.41 +/- 90.82
Episode length: 518.20 +/- 59.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 518      |
|    mean_reward     | 603      |
| time/              |          |
|    total_timesteps | 2370480  |
---------------------------------
Eval num_timesteps=2372472, episode_reward=718.36 +/- 177.37
Episode length: 503.20 +/- 41.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | 718      |
| time/              |          |
|    total_timesteps | 2372472  |
---------------------------------
Eval num_timesteps=2374464, episode_reward=879.93 +/- 247.89
Episode length: 594.00 +/- 112.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 880      |
| time/              |          |
|    total_timesteps | 2374464  |
---------------------------------
Eval num_timesteps=2376456, episode_reward=672.17 +/- 172.32
Episode length: 475.20 +/- 42.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | 672      |
| time/              |          |
|    total_timesteps | 2376456  |
---------------------------------
Eval num_timesteps=2378448, episode_reward=933.01 +/- 413.26
Episode length: 574.20 +/- 63.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | 933      |
| time/              |          |
|    total_timesteps | 2378448  |
---------------------------------
New best mean reward!
Eval num_timesteps=2380440, episode_reward=572.27 +/- 254.25
Episode length: 500.80 +/- 35.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 572      |
| time/              |          |
|    total_timesteps | 2380440  |
---------------------------------
Eval num_timesteps=2382432, episode_reward=907.21 +/- 294.14
Episode length: 586.60 +/- 74.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 907      |
| time/              |          |
|    total_timesteps | 2382432  |
---------------------------------
Eval num_timesteps=2384424, episode_reward=508.21 +/- 281.55
Episode length: 544.80 +/- 37.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 508      |
| time/              |          |
|    total_timesteps | 2384424  |
---------------------------------
Eval num_timesteps=2386416, episode_reward=748.88 +/- 399.76
Episode length: 555.80 +/- 130.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 2386416  |
---------------------------------
Eval num_timesteps=2388408, episode_reward=577.79 +/- 370.02
Episode length: 557.60 +/- 107.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | 578      |
| time/              |          |
|    total_timesteps | 2388408  |
---------------------------------
Eval num_timesteps=2390400, episode_reward=796.35 +/- 386.71
Episode length: 528.60 +/- 32.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 796      |
| time/              |          |
|    total_timesteps | 2390400  |
---------------------------------
Eval num_timesteps=2392392, episode_reward=695.14 +/- 360.17
Episode length: 622.60 +/- 114.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 695      |
| time/              |          |
|    total_timesteps | 2392392  |
---------------------------------
Eval num_timesteps=2394384, episode_reward=744.98 +/- 455.82
Episode length: 561.80 +/- 105.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 745      |
| time/              |          |
|    total_timesteps | 2394384  |
---------------------------------
Eval num_timesteps=2396376, episode_reward=619.44 +/- 29.36
Episode length: 562.20 +/- 49.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 619      |
| time/              |          |
|    total_timesteps | 2396376  |
---------------------------------
Eval num_timesteps=2398368, episode_reward=1126.00 +/- 315.28
Episode length: 648.80 +/- 134.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 649      |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 2398368  |
---------------------------------
New best mean reward!
Eval num_timesteps=2400360, episode_reward=842.10 +/- 77.04
Episode length: 537.20 +/- 28.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 842      |
| time/              |          |
|    total_timesteps | 2400360  |
---------------------------------
Eval num_timesteps=2402352, episode_reward=915.84 +/- 385.99
Episode length: 551.00 +/- 89.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | 916      |
| time/              |          |
|    total_timesteps | 2402352  |
---------------------------------
Eval num_timesteps=2404344, episode_reward=621.64 +/- 427.71
Episode length: 535.60 +/- 41.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 2404344  |
---------------------------------
Eval num_timesteps=2406336, episode_reward=484.02 +/- 194.17
Episode length: 453.80 +/- 33.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | 484      |
| time/              |          |
|    total_timesteps | 2406336  |
---------------------------------
Eval num_timesteps=2408328, episode_reward=744.52 +/- 59.26
Episode length: 533.80 +/- 49.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 745      |
| time/              |          |
|    total_timesteps | 2408328  |
---------------------------------
Eval num_timesteps=2410320, episode_reward=433.57 +/- 270.06
Episode length: 524.60 +/- 20.64
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 525          |
|    mean_reward          | 434          |
| time/                   |              |
|    total_timesteps      | 2410320      |
| train/                  |              |
|    approx_kl            | 0.0065705143 |
|    clip_fraction        | 0.028        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.4         |
|    explained_variance   | 0.931        |
|    learning_rate        | 0.001        |
|    loss                 | 0.147        |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.000913    |
|    std                  | 1.2          |
|    value_loss           | 0.48         |
------------------------------------------
Eval num_timesteps=2412312, episode_reward=610.52 +/- 332.27
Episode length: 704.20 +/- 230.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 704      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 2412312  |
---------------------------------
Eval num_timesteps=2414304, episode_reward=915.38 +/- 257.76
Episode length: 648.80 +/- 181.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 649      |
|    mean_reward     | 915      |
| time/              |          |
|    total_timesteps | 2414304  |
---------------------------------
Eval num_timesteps=2416296, episode_reward=682.37 +/- 401.98
Episode length: 570.60 +/- 53.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 682      |
| time/              |          |
|    total_timesteps | 2416296  |
---------------------------------
Eval num_timesteps=2418288, episode_reward=1027.13 +/- 634.30
Episode length: 707.60 +/- 202.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 708      |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2418288  |
---------------------------------
Eval num_timesteps=2420280, episode_reward=539.04 +/- 200.67
Episode length: 558.20 +/- 82.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | 539      |
| time/              |          |
|    total_timesteps | 2420280  |
---------------------------------
Eval num_timesteps=2422272, episode_reward=740.99 +/- 379.46
Episode length: 592.20 +/- 105.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 741      |
| time/              |          |
|    total_timesteps | 2422272  |
---------------------------------
Eval num_timesteps=2424264, episode_reward=749.18 +/- 271.18
Episode length: 613.60 +/- 86.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 2424264  |
---------------------------------
Eval num_timesteps=2426256, episode_reward=640.00 +/- 21.74
Episode length: 555.60 +/- 61.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | 640      |
| time/              |          |
|    total_timesteps | 2426256  |
---------------------------------
Eval num_timesteps=2428248, episode_reward=704.27 +/- 120.49
Episode length: 551.60 +/- 61.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 704      |
| time/              |          |
|    total_timesteps | 2428248  |
---------------------------------
Eval num_timesteps=2430240, episode_reward=662.90 +/- 71.29
Episode length: 559.00 +/- 68.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 2430240  |
---------------------------------
Eval num_timesteps=2432232, episode_reward=659.39 +/- 116.99
Episode length: 597.60 +/- 78.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 598      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 2432232  |
---------------------------------
Eval num_timesteps=2434224, episode_reward=593.12 +/- 190.82
Episode length: 605.00 +/- 156.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 2434224  |
---------------------------------
Eval num_timesteps=2436216, episode_reward=789.57 +/- 173.91
Episode length: 638.80 +/- 128.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 790      |
| time/              |          |
|    total_timesteps | 2436216  |
---------------------------------
Eval num_timesteps=2438208, episode_reward=638.25 +/- 264.29
Episode length: 550.20 +/- 79.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 638      |
| time/              |          |
|    total_timesteps | 2438208  |
---------------------------------
Eval num_timesteps=2440200, episode_reward=630.79 +/- 29.84
Episode length: 546.60 +/- 109.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 631      |
| time/              |          |
|    total_timesteps | 2440200  |
---------------------------------
Eval num_timesteps=2442192, episode_reward=765.07 +/- 322.84
Episode length: 559.60 +/- 79.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | 765      |
| time/              |          |
|    total_timesteps | 2442192  |
---------------------------------
Eval num_timesteps=2444184, episode_reward=590.34 +/- 697.12
Episode length: 634.00 +/- 168.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 634      |
|    mean_reward     | 590      |
| time/              |          |
|    total_timesteps | 2444184  |
---------------------------------
Eval num_timesteps=2446176, episode_reward=810.90 +/- 252.52
Episode length: 627.40 +/- 112.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 811      |
| time/              |          |
|    total_timesteps | 2446176  |
---------------------------------
Eval num_timesteps=2448168, episode_reward=679.83 +/- 118.52
Episode length: 554.80 +/- 43.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 680      |
| time/              |          |
|    total_timesteps | 2448168  |
---------------------------------
Eval num_timesteps=2450160, episode_reward=557.17 +/- 109.73
Episode length: 561.60 +/- 146.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 557      |
| time/              |          |
|    total_timesteps | 2450160  |
---------------------------------
Eval num_timesteps=2452152, episode_reward=637.62 +/- 287.63
Episode length: 718.00 +/- 167.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 718      |
|    mean_reward     | 638      |
| time/              |          |
|    total_timesteps | 2452152  |
---------------------------------
Eval num_timesteps=2454144, episode_reward=1008.48 +/- 532.23
Episode length: 632.60 +/- 112.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 2454144  |
---------------------------------
Eval num_timesteps=2456136, episode_reward=728.72 +/- 281.40
Episode length: 654.60 +/- 200.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 655      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 2456136  |
---------------------------------
Eval num_timesteps=2458128, episode_reward=669.49 +/- 114.60
Episode length: 625.00 +/- 145.61
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 625          |
|    mean_reward          | 669          |
| time/                   |              |
|    total_timesteps      | 2458128      |
| train/                  |              |
|    approx_kl            | 0.0045466917 |
|    clip_fraction        | 0.0265       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.4         |
|    explained_variance   | 0.927        |
|    learning_rate        | 0.001        |
|    loss                 | 0.163        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.000867    |
|    std                  | 1.2          |
|    value_loss           | 0.501        |
------------------------------------------
Eval num_timesteps=2460120, episode_reward=573.46 +/- 147.18
Episode length: 633.00 +/- 165.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 573      |
| time/              |          |
|    total_timesteps | 2460120  |
---------------------------------
Eval num_timesteps=2462112, episode_reward=502.49 +/- 134.07
Episode length: 576.60 +/- 71.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | 502      |
| time/              |          |
|    total_timesteps | 2462112  |
---------------------------------
Eval num_timesteps=2464104, episode_reward=702.42 +/- 345.03
Episode length: 642.20 +/- 192.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 642      |
|    mean_reward     | 702      |
| time/              |          |
|    total_timesteps | 2464104  |
---------------------------------
Eval num_timesteps=2466096, episode_reward=803.98 +/- 616.76
Episode length: 612.40 +/- 171.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | 804      |
| time/              |          |
|    total_timesteps | 2466096  |
---------------------------------
Eval num_timesteps=2468088, episode_reward=363.68 +/- 279.57
Episode length: 599.60 +/- 127.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 600      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 2468088  |
---------------------------------
Eval num_timesteps=2470080, episode_reward=540.55 +/- 309.29
Episode length: 629.40 +/- 182.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | 541      |
| time/              |          |
|    total_timesteps | 2470080  |
---------------------------------
Eval num_timesteps=2472072, episode_reward=880.24 +/- 336.53
Episode length: 633.20 +/- 92.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 880      |
| time/              |          |
|    total_timesteps | 2472072  |
---------------------------------
Eval num_timesteps=2474064, episode_reward=638.62 +/- 526.89
Episode length: 568.60 +/- 82.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 639      |
| time/              |          |
|    total_timesteps | 2474064  |
---------------------------------
Eval num_timesteps=2476056, episode_reward=453.06 +/- 354.14
Episode length: 587.60 +/- 124.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 2476056  |
---------------------------------
Eval num_timesteps=2478048, episode_reward=589.74 +/- 275.91
Episode length: 570.60 +/- 81.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 590      |
| time/              |          |
|    total_timesteps | 2478048  |
---------------------------------
Eval num_timesteps=2480040, episode_reward=586.07 +/- 94.02
Episode length: 597.40 +/- 70.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | 586      |
| time/              |          |
|    total_timesteps | 2480040  |
---------------------------------
Eval num_timesteps=2482032, episode_reward=544.36 +/- 201.20
Episode length: 635.80 +/- 109.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 636      |
|    mean_reward     | 544      |
| time/              |          |
|    total_timesteps | 2482032  |
---------------------------------
Eval num_timesteps=2484024, episode_reward=565.41 +/- 252.95
Episode length: 669.40 +/- 179.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 669      |
|    mean_reward     | 565      |
| time/              |          |
|    total_timesteps | 2484024  |
---------------------------------
Eval num_timesteps=2486016, episode_reward=790.08 +/- 663.09
Episode length: 572.40 +/- 73.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 790      |
| time/              |          |
|    total_timesteps | 2486016  |
---------------------------------
Eval num_timesteps=2488008, episode_reward=224.87 +/- 379.03
Episode length: 714.80 +/- 158.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 715      |
|    mean_reward     | 225      |
| time/              |          |
|    total_timesteps | 2488008  |
---------------------------------
Eval num_timesteps=2490000, episode_reward=517.10 +/- 333.84
Episode length: 527.40 +/- 57.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 517      |
| time/              |          |
|    total_timesteps | 2490000  |
---------------------------------
Eval num_timesteps=2491992, episode_reward=663.99 +/- 453.97
Episode length: 668.00 +/- 192.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 668      |
|    mean_reward     | 664      |
| time/              |          |
|    total_timesteps | 2491992  |
---------------------------------
Eval num_timesteps=2493984, episode_reward=447.06 +/- 238.73
Episode length: 557.40 +/- 69.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 447      |
| time/              |          |
|    total_timesteps | 2493984  |
---------------------------------
Eval num_timesteps=2495976, episode_reward=971.73 +/- 352.75
Episode length: 714.40 +/- 165.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 714      |
|    mean_reward     | 972      |
| time/              |          |
|    total_timesteps | 2495976  |
---------------------------------
Eval num_timesteps=2497968, episode_reward=463.84 +/- 166.72
Episode length: 575.80 +/- 61.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 464      |
| time/              |          |
|    total_timesteps | 2497968  |
---------------------------------
Eval num_timesteps=2499960, episode_reward=427.75 +/- 305.21
Episode length: 808.80 +/- 153.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 809      |
|    mean_reward     | 428      |
| time/              |          |
|    total_timesteps | 2499960  |
---------------------------------
Eval num_timesteps=2501952, episode_reward=605.93 +/- 218.33
Episode length: 628.40 +/- 81.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 606      |
| time/              |          |
|    total_timesteps | 2501952  |
---------------------------------
Eval num_timesteps=2503944, episode_reward=420.22 +/- 372.66
Episode length: 611.00 +/- 197.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 420      |
| time/              |          |
|    total_timesteps | 2503944  |
---------------------------------
Eval num_timesteps=2505936, episode_reward=1155.01 +/- 580.96
Episode length: 759.00 +/- 119.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 759      |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 2505936  |
---------------------------------
New best mean reward!
Eval num_timesteps=2507928, episode_reward=551.14 +/- 228.09
Episode length: 541.40 +/- 47.96
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 541          |
|    mean_reward          | 551          |
| time/                   |              |
|    total_timesteps      | 2507928      |
| train/                  |              |
|    approx_kl            | 0.0038867171 |
|    clip_fraction        | 0.0379       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.41        |
|    explained_variance   | 0.937        |
|    learning_rate        | 0.001        |
|    loss                 | 0.102        |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.00136     |
|    std                  | 1.2          |
|    value_loss           | 0.402        |
------------------------------------------
Eval num_timesteps=2509920, episode_reward=318.21 +/- 330.34
Episode length: 627.40 +/- 84.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 318      |
| time/              |          |
|    total_timesteps | 2509920  |
---------------------------------
Eval num_timesteps=2511912, episode_reward=106.95 +/- 406.50
Episode length: 582.80 +/- 77.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 107      |
| time/              |          |
|    total_timesteps | 2511912  |
---------------------------------
Eval num_timesteps=2513904, episode_reward=285.89 +/- 315.65
Episode length: 512.40 +/- 59.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 286      |
| time/              |          |
|    total_timesteps | 2513904  |
---------------------------------
Eval num_timesteps=2515896, episode_reward=491.45 +/- 474.65
Episode length: 654.20 +/- 94.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 654      |
|    mean_reward     | 491      |
| time/              |          |
|    total_timesteps | 2515896  |
---------------------------------
Eval num_timesteps=2517888, episode_reward=153.58 +/- 208.36
Episode length: 595.80 +/- 137.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 596      |
|    mean_reward     | 154      |
| time/              |          |
|    total_timesteps | 2517888  |
---------------------------------
Eval num_timesteps=2519880, episode_reward=692.66 +/- 68.48
Episode length: 564.00 +/- 77.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 693      |
| time/              |          |
|    total_timesteps | 2519880  |
---------------------------------
Eval num_timesteps=2521872, episode_reward=793.47 +/- 697.77
Episode length: 611.40 +/- 162.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 793      |
| time/              |          |
|    total_timesteps | 2521872  |
---------------------------------
Eval num_timesteps=2523864, episode_reward=157.42 +/- 264.56
Episode length: 595.00 +/- 129.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 157      |
| time/              |          |
|    total_timesteps | 2523864  |
---------------------------------
Eval num_timesteps=2525856, episode_reward=460.43 +/- 275.59
Episode length: 550.40 +/- 76.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 460      |
| time/              |          |
|    total_timesteps | 2525856  |
---------------------------------
Eval num_timesteps=2527848, episode_reward=343.87 +/- 558.56
Episode length: 665.40 +/- 192.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 665      |
|    mean_reward     | 344      |
| time/              |          |
|    total_timesteps | 2527848  |
---------------------------------
Eval num_timesteps=2529840, episode_reward=344.92 +/- 530.78
Episode length: 666.20 +/- 197.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 666      |
|    mean_reward     | 345      |
| time/              |          |
|    total_timesteps | 2529840  |
---------------------------------
Eval num_timesteps=2531832, episode_reward=226.42 +/- 282.35
Episode length: 589.20 +/- 104.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 226      |
| time/              |          |
|    total_timesteps | 2531832  |
---------------------------------
Eval num_timesteps=2533824, episode_reward=357.06 +/- 592.44
Episode length: 776.00 +/- 347.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 776      |
|    mean_reward     | 357      |
| time/              |          |
|    total_timesteps | 2533824  |
---------------------------------
Eval num_timesteps=2535816, episode_reward=295.02 +/- 332.55
Episode length: 888.80 +/- 514.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 889      |
|    mean_reward     | 295      |
| time/              |          |
|    total_timesteps | 2535816  |
---------------------------------
Eval num_timesteps=2537808, episode_reward=150.83 +/- 184.74
Episode length: 552.80 +/- 86.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 151      |
| time/              |          |
|    total_timesteps | 2537808  |
---------------------------------
Eval num_timesteps=2539800, episode_reward=201.65 +/- 352.47
Episode length: 605.20 +/- 68.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | 202      |
| time/              |          |
|    total_timesteps | 2539800  |
---------------------------------
Eval num_timesteps=2541792, episode_reward=103.90 +/- 279.38
Episode length: 584.00 +/- 76.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 104      |
| time/              |          |
|    total_timesteps | 2541792  |
---------------------------------
Eval num_timesteps=2543784, episode_reward=533.33 +/- 412.92
Episode length: 605.00 +/- 155.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | 533      |
| time/              |          |
|    total_timesteps | 2543784  |
---------------------------------
Eval num_timesteps=2545776, episode_reward=298.80 +/- 252.52
Episode length: 520.20 +/- 30.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 299      |
| time/              |          |
|    total_timesteps | 2545776  |
---------------------------------
Eval num_timesteps=2547768, episode_reward=525.69 +/- 176.63
Episode length: 531.60 +/- 49.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 2547768  |
---------------------------------
Eval num_timesteps=2549760, episode_reward=168.35 +/- 241.08
Episode length: 679.20 +/- 133.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 679      |
|    mean_reward     | 168      |
| time/              |          |
|    total_timesteps | 2549760  |
---------------------------------
Eval num_timesteps=2551752, episode_reward=182.89 +/- 380.07
Episode length: 552.40 +/- 61.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 183      |
| time/              |          |
|    total_timesteps | 2551752  |
---------------------------------
Eval num_timesteps=2553744, episode_reward=475.81 +/- 387.41
Episode length: 505.80 +/- 28.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 476      |
| time/              |          |
|    total_timesteps | 2553744  |
---------------------------------
Eval num_timesteps=2555736, episode_reward=415.56 +/- 418.95
Episode length: 546.00 +/- 53.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 416      |
| time/              |          |
|    total_timesteps | 2555736  |
---------------------------------
Eval num_timesteps=2557728, episode_reward=261.00 +/- 276.40
Episode length: 549.00 +/- 87.55
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 549          |
|    mean_reward          | 261          |
| time/                   |              |
|    total_timesteps      | 2557728      |
| train/                  |              |
|    approx_kl            | 0.0025558134 |
|    clip_fraction        | 0.0483       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.41        |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0438       |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00092     |
|    std                  | 1.21         |
|    value_loss           | 0.272        |
------------------------------------------
Eval num_timesteps=2559720, episode_reward=-6.87 +/- 144.97
Episode length: 552.20 +/- 102.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -6.87    |
| time/              |          |
|    total_timesteps | 2559720  |
---------------------------------
Eval num_timesteps=2561712, episode_reward=-55.32 +/- 98.91
Episode length: 639.80 +/- 169.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 640      |
|    mean_reward     | -55.3    |
| time/              |          |
|    total_timesteps | 2561712  |
---------------------------------
Eval num_timesteps=2563704, episode_reward=284.41 +/- 233.70
Episode length: 603.60 +/- 156.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 284      |
| time/              |          |
|    total_timesteps | 2563704  |
---------------------------------
Eval num_timesteps=2565696, episode_reward=245.37 +/- 450.94
Episode length: 557.80 +/- 59.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | 245      |
| time/              |          |
|    total_timesteps | 2565696  |
---------------------------------
Eval num_timesteps=2567688, episode_reward=210.89 +/- 303.41
Episode length: 582.00 +/- 132.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 211      |
| time/              |          |
|    total_timesteps | 2567688  |
---------------------------------
Eval num_timesteps=2569680, episode_reward=462.57 +/- 526.68
Episode length: 693.20 +/- 112.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 693      |
|    mean_reward     | 463      |
| time/              |          |
|    total_timesteps | 2569680  |
---------------------------------
Eval num_timesteps=2571672, episode_reward=352.66 +/- 297.98
Episode length: 568.80 +/- 51.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 353      |
| time/              |          |
|    total_timesteps | 2571672  |
---------------------------------
Eval num_timesteps=2573664, episode_reward=24.64 +/- 265.40
Episode length: 524.20 +/- 42.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | 24.6     |
| time/              |          |
|    total_timesteps | 2573664  |
---------------------------------
Eval num_timesteps=2575656, episode_reward=190.89 +/- 333.15
Episode length: 483.40 +/- 26.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | 191      |
| time/              |          |
|    total_timesteps | 2575656  |
---------------------------------
Eval num_timesteps=2577648, episode_reward=398.27 +/- 327.29
Episode length: 630.40 +/- 53.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 398      |
| time/              |          |
|    total_timesteps | 2577648  |
---------------------------------
Eval num_timesteps=2579640, episode_reward=320.81 +/- 339.93
Episode length: 607.60 +/- 60.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | 321      |
| time/              |          |
|    total_timesteps | 2579640  |
---------------------------------
Eval num_timesteps=2581632, episode_reward=-53.69 +/- 173.28
Episode length: 546.40 +/- 37.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | -53.7    |
| time/              |          |
|    total_timesteps | 2581632  |
---------------------------------
Eval num_timesteps=2583624, episode_reward=449.68 +/- 359.31
Episode length: 565.40 +/- 100.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 450      |
| time/              |          |
|    total_timesteps | 2583624  |
---------------------------------
Eval num_timesteps=2585616, episode_reward=606.07 +/- 279.58
Episode length: 690.80 +/- 175.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 691      |
|    mean_reward     | 606      |
| time/              |          |
|    total_timesteps | 2585616  |
---------------------------------
Eval num_timesteps=2587608, episode_reward=594.53 +/- 472.22
Episode length: 641.20 +/- 75.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 641      |
|    mean_reward     | 595      |
| time/              |          |
|    total_timesteps | 2587608  |
---------------------------------
Eval num_timesteps=2589600, episode_reward=30.16 +/- 358.07
Episode length: 608.80 +/- 84.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 30.2     |
| time/              |          |
|    total_timesteps | 2589600  |
---------------------------------
Eval num_timesteps=2591592, episode_reward=262.15 +/- 245.09
Episode length: 566.60 +/- 79.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 262      |
| time/              |          |
|    total_timesteps | 2591592  |
---------------------------------
Eval num_timesteps=2593584, episode_reward=306.50 +/- 302.31
Episode length: 584.20 +/- 50.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 306      |
| time/              |          |
|    total_timesteps | 2593584  |
---------------------------------
Eval num_timesteps=2595576, episode_reward=329.65 +/- 524.22
Episode length: 564.40 +/- 56.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 330      |
| time/              |          |
|    total_timesteps | 2595576  |
---------------------------------
Eval num_timesteps=2597568, episode_reward=118.11 +/- 292.66
Episode length: 514.60 +/- 21.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 118      |
| time/              |          |
|    total_timesteps | 2597568  |
---------------------------------
Eval num_timesteps=2599560, episode_reward=174.30 +/- 268.79
Episode length: 582.60 +/- 61.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 174      |
| time/              |          |
|    total_timesteps | 2599560  |
---------------------------------
Eval num_timesteps=2601552, episode_reward=263.00 +/- 461.29
Episode length: 567.60 +/- 93.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 263      |
| time/              |          |
|    total_timesteps | 2601552  |
---------------------------------
Eval num_timesteps=2603544, episode_reward=246.70 +/- 412.92
Episode length: 555.00 +/- 120.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 247      |
| time/              |          |
|    total_timesteps | 2603544  |
---------------------------------
Eval num_timesteps=2605536, episode_reward=155.37 +/- 282.02
Episode length: 625.80 +/- 69.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 626          |
|    mean_reward          | 155          |
| time/                   |              |
|    total_timesteps      | 2605536      |
| train/                  |              |
|    approx_kl            | 0.0033552148 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.43        |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0115       |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.00103     |
|    std                  | 1.21         |
|    value_loss           | 0.191        |
------------------------------------------
Eval num_timesteps=2607528, episode_reward=-13.31 +/- 140.25
Episode length: 555.20 +/- 54.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | -13.3    |
| time/              |          |
|    total_timesteps | 2607528  |
---------------------------------
Eval num_timesteps=2609520, episode_reward=107.21 +/- 293.94
Episode length: 575.80 +/- 82.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 107      |
| time/              |          |
|    total_timesteps | 2609520  |
---------------------------------
Eval num_timesteps=2611512, episode_reward=9.26 +/- 346.34
Episode length: 664.60 +/- 109.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 665      |
|    mean_reward     | 9.26     |
| time/              |          |
|    total_timesteps | 2611512  |
---------------------------------
Eval num_timesteps=2613504, episode_reward=253.28 +/- 359.14
Episode length: 561.00 +/- 41.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 253      |
| time/              |          |
|    total_timesteps | 2613504  |
---------------------------------
Eval num_timesteps=2615496, episode_reward=150.91 +/- 332.38
Episode length: 592.40 +/- 86.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 151      |
| time/              |          |
|    total_timesteps | 2615496  |
---------------------------------
Eval num_timesteps=2617488, episode_reward=124.39 +/- 192.77
Episode length: 561.20 +/- 61.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 124      |
| time/              |          |
|    total_timesteps | 2617488  |
---------------------------------
Eval num_timesteps=2619480, episode_reward=381.26 +/- 326.02
Episode length: 606.80 +/- 79.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 607      |
|    mean_reward     | 381      |
| time/              |          |
|    total_timesteps | 2619480  |
---------------------------------
Eval num_timesteps=2621472, episode_reward=205.95 +/- 290.16
Episode length: 526.80 +/- 71.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 206      |
| time/              |          |
|    total_timesteps | 2621472  |
---------------------------------
Eval num_timesteps=2623464, episode_reward=191.19 +/- 279.86
Episode length: 630.80 +/- 97.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 191      |
| time/              |          |
|    total_timesteps | 2623464  |
---------------------------------
Eval num_timesteps=2625456, episode_reward=-48.97 +/- 166.58
Episode length: 579.00 +/- 37.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 579      |
|    mean_reward     | -49      |
| time/              |          |
|    total_timesteps | 2625456  |
---------------------------------
Eval num_timesteps=2627448, episode_reward=-105.12 +/- 141.38
Episode length: 551.00 +/- 38.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | -105     |
| time/              |          |
|    total_timesteps | 2627448  |
---------------------------------
Eval num_timesteps=2629440, episode_reward=263.64 +/- 264.19
Episode length: 624.40 +/- 105.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 624      |
|    mean_reward     | 264      |
| time/              |          |
|    total_timesteps | 2629440  |
---------------------------------
Eval num_timesteps=2631432, episode_reward=83.65 +/- 343.44
Episode length: 616.60 +/- 68.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 617      |
|    mean_reward     | 83.7     |
| time/              |          |
|    total_timesteps | 2631432  |
---------------------------------
Eval num_timesteps=2633424, episode_reward=296.15 +/- 195.55
Episode length: 561.20 +/- 36.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 296      |
| time/              |          |
|    total_timesteps | 2633424  |
---------------------------------
Eval num_timesteps=2635416, episode_reward=87.22 +/- 282.45
Episode length: 547.20 +/- 71.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 87.2     |
| time/              |          |
|    total_timesteps | 2635416  |
---------------------------------
Eval num_timesteps=2637408, episode_reward=176.61 +/- 389.77
Episode length: 602.00 +/- 65.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 177      |
| time/              |          |
|    total_timesteps | 2637408  |
---------------------------------
Eval num_timesteps=2639400, episode_reward=74.46 +/- 282.72
Episode length: 678.80 +/- 165.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 679      |
|    mean_reward     | 74.5     |
| time/              |          |
|    total_timesteps | 2639400  |
---------------------------------
Eval num_timesteps=2641392, episode_reward=419.91 +/- 347.71
Episode length: 575.40 +/- 44.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 575      |
|    mean_reward     | 420      |
| time/              |          |
|    total_timesteps | 2641392  |
---------------------------------
Eval num_timesteps=2643384, episode_reward=300.64 +/- 346.78
Episode length: 542.60 +/- 38.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | 301      |
| time/              |          |
|    total_timesteps | 2643384  |
---------------------------------
Eval num_timesteps=2645376, episode_reward=226.76 +/- 339.66
Episode length: 559.00 +/- 66.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 227      |
| time/              |          |
|    total_timesteps | 2645376  |
---------------------------------
Eval num_timesteps=2647368, episode_reward=200.76 +/- 282.79
Episode length: 724.60 +/- 164.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 725      |
|    mean_reward     | 201      |
| time/              |          |
|    total_timesteps | 2647368  |
---------------------------------
Eval num_timesteps=2649360, episode_reward=149.88 +/- 365.54
Episode length: 610.60 +/- 176.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 150      |
| time/              |          |
|    total_timesteps | 2649360  |
---------------------------------
Eval num_timesteps=2651352, episode_reward=76.27 +/- 246.74
Episode length: 571.20 +/- 39.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 76.3     |
| time/              |          |
|    total_timesteps | 2651352  |
---------------------------------
Eval num_timesteps=2653344, episode_reward=288.65 +/- 374.61
Episode length: 547.00 +/- 40.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 289      |
| time/              |          |
|    total_timesteps | 2653344  |
---------------------------------
Eval num_timesteps=2655336, episode_reward=42.86 +/- 416.19
Episode length: 601.20 +/- 78.37
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 601          |
|    mean_reward          | 42.9         |
| time/                   |              |
|    total_timesteps      | 2655336      |
| train/                  |              |
|    approx_kl            | 0.0028722682 |
|    clip_fraction        | 0.0575       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.45        |
|    explained_variance   | 0.969        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0311      |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.000994    |
|    std                  | 1.22         |
|    value_loss           | 0.106        |
------------------------------------------
Eval num_timesteps=2657328, episode_reward=-137.95 +/- 99.60
Episode length: 561.80 +/- 60.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | -138     |
| time/              |          |
|    total_timesteps | 2657328  |
---------------------------------
Eval num_timesteps=2659320, episode_reward=-73.57 +/- 135.67
Episode length: 616.20 +/- 63.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 616      |
|    mean_reward     | -73.6    |
| time/              |          |
|    total_timesteps | 2659320  |
---------------------------------
Eval num_timesteps=2661312, episode_reward=-53.10 +/- 123.07
Episode length: 547.20 +/- 39.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | -53.1    |
| time/              |          |
|    total_timesteps | 2661312  |
---------------------------------
Eval num_timesteps=2663304, episode_reward=-99.64 +/- 170.86
Episode length: 573.60 +/- 69.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | -99.6    |
| time/              |          |
|    total_timesteps | 2663304  |
---------------------------------
Eval num_timesteps=2665296, episode_reward=-82.02 +/- 186.65
Episode length: 612.40 +/- 176.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | -82      |
| time/              |          |
|    total_timesteps | 2665296  |
---------------------------------
Eval num_timesteps=2667288, episode_reward=180.63 +/- 320.34
Episode length: 659.60 +/- 94.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 660      |
|    mean_reward     | 181      |
| time/              |          |
|    total_timesteps | 2667288  |
---------------------------------
Eval num_timesteps=2669280, episode_reward=344.08 +/- 232.77
Episode length: 550.40 +/- 19.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 344      |
| time/              |          |
|    total_timesteps | 2669280  |
---------------------------------
Eval num_timesteps=2671272, episode_reward=-145.00 +/- 118.59
Episode length: 583.00 +/- 68.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | -145     |
| time/              |          |
|    total_timesteps | 2671272  |
---------------------------------
Eval num_timesteps=2673264, episode_reward=-168.65 +/- 153.35
Episode length: 604.60 +/- 70.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | -169     |
| time/              |          |
|    total_timesteps | 2673264  |
---------------------------------
Eval num_timesteps=2675256, episode_reward=3.58 +/- 223.89
Episode length: 578.80 +/- 62.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 579      |
|    mean_reward     | 3.58     |
| time/              |          |
|    total_timesteps | 2675256  |
---------------------------------
Eval num_timesteps=2677248, episode_reward=-212.22 +/- 25.62
Episode length: 630.60 +/- 64.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | -212     |
| time/              |          |
|    total_timesteps | 2677248  |
---------------------------------
Eval num_timesteps=2679240, episode_reward=-105.65 +/- 204.88
Episode length: 600.00 +/- 82.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 600      |
|    mean_reward     | -106     |
| time/              |          |
|    total_timesteps | 2679240  |
---------------------------------
Eval num_timesteps=2681232, episode_reward=155.16 +/- 368.82
Episode length: 553.80 +/- 40.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 155      |
| time/              |          |
|    total_timesteps | 2681232  |
---------------------------------
Eval num_timesteps=2683224, episode_reward=72.80 +/- 321.75
Episode length: 619.40 +/- 45.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 72.8     |
| time/              |          |
|    total_timesteps | 2683224  |
---------------------------------
Eval num_timesteps=2685216, episode_reward=-137.46 +/- 157.34
Episode length: 612.60 +/- 79.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | -137     |
| time/              |          |
|    total_timesteps | 2685216  |
---------------------------------
Eval num_timesteps=2687208, episode_reward=-66.85 +/- 113.14
Episode length: 620.20 +/- 63.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | -66.8    |
| time/              |          |
|    total_timesteps | 2687208  |
---------------------------------
Eval num_timesteps=2689200, episode_reward=115.55 +/- 246.66
Episode length: 678.00 +/- 83.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 678      |
|    mean_reward     | 116      |
| time/              |          |
|    total_timesteps | 2689200  |
---------------------------------
Eval num_timesteps=2691192, episode_reward=-159.50 +/- 147.87
Episode length: 547.40 +/- 74.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | -159     |
| time/              |          |
|    total_timesteps | 2691192  |
---------------------------------
Eval num_timesteps=2693184, episode_reward=-152.08 +/- 128.74
Episode length: 620.00 +/- 55.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | -152     |
| time/              |          |
|    total_timesteps | 2693184  |
---------------------------------
Eval num_timesteps=2695176, episode_reward=-151.86 +/- 124.73
Episode length: 580.80 +/- 27.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | -152     |
| time/              |          |
|    total_timesteps | 2695176  |
---------------------------------
Eval num_timesteps=2697168, episode_reward=-21.76 +/- 310.55
Episode length: 562.60 +/- 73.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | -21.8    |
| time/              |          |
|    total_timesteps | 2697168  |
---------------------------------
Eval num_timesteps=2699160, episode_reward=-156.35 +/- 73.16
Episode length: 597.00 +/- 56.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | -156     |
| time/              |          |
|    total_timesteps | 2699160  |
---------------------------------
Eval num_timesteps=2701152, episode_reward=57.56 +/- 206.20
Episode length: 542.40 +/- 45.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | 57.6     |
| time/              |          |
|    total_timesteps | 2701152  |
---------------------------------
Eval num_timesteps=2703144, episode_reward=-31.44 +/- 237.87
Episode length: 628.40 +/- 71.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | -31.4    |
| time/              |          |
|    total_timesteps | 2703144  |
---------------------------------
Eval num_timesteps=2705136, episode_reward=85.00 +/- 386.38
Episode length: 575.60 +/- 103.93
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 576          |
|    mean_reward          | 85           |
| time/                   |              |
|    total_timesteps      | 2705136      |
| train/                  |              |
|    approx_kl            | 0.0074810972 |
|    clip_fraction        | 0.0549       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.46        |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.001        |
|    loss                 | -0.0321      |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00134     |
|    std                  | 1.22         |
|    value_loss           | 0.0838       |
------------------------------------------
Eval num_timesteps=2707128, episode_reward=-163.83 +/- 111.44
Episode length: 622.40 +/- 51.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 622      |
|    mean_reward     | -164     |
| time/              |          |
|    total_timesteps | 2707128  |
---------------------------------
Eval num_timesteps=2709120, episode_reward=-202.14 +/- 81.53
Episode length: 630.40 +/- 59.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | -202     |
| time/              |          |
|    total_timesteps | 2709120  |
---------------------------------
Eval num_timesteps=2711112, episode_reward=46.85 +/- 349.22
Episode length: 666.20 +/- 108.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 666      |
|    mean_reward     | 46.9     |
| time/              |          |
|    total_timesteps | 2711112  |
---------------------------------
Eval num_timesteps=2713104, episode_reward=-229.99 +/- 38.32
Episode length: 568.60 +/- 55.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | -230     |
| time/              |          |
|    total_timesteps | 2713104  |
---------------------------------
Eval num_timesteps=2715096, episode_reward=-222.83 +/- 20.32
Episode length: 620.80 +/- 66.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 621      |
|    mean_reward     | -223     |
| time/              |          |
|    total_timesteps | 2715096  |
---------------------------------
Eval num_timesteps=2717088, episode_reward=-234.62 +/- 54.43
Episode length: 642.60 +/- 103.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 643      |
|    mean_reward     | -235     |
| time/              |          |
|    total_timesteps | 2717088  |
---------------------------------
Eval num_timesteps=2719080, episode_reward=-22.06 +/- 280.52
Episode length: 612.00 +/- 56.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | -22.1    |
| time/              |          |
|    total_timesteps | 2719080  |
---------------------------------
Eval num_timesteps=2721072, episode_reward=-123.27 +/- 150.53
Episode length: 614.00 +/- 119.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | -123     |
| time/              |          |
|    total_timesteps | 2721072  |
---------------------------------
Eval num_timesteps=2723064, episode_reward=7.80 +/- 367.52
Episode length: 567.60 +/- 42.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 7.8      |
| time/              |          |
|    total_timesteps | 2723064  |
---------------------------------
Eval num_timesteps=2725056, episode_reward=-187.22 +/- 109.05
Episode length: 644.40 +/- 99.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 644      |
|    mean_reward     | -187     |
| time/              |          |
|    total_timesteps | 2725056  |
---------------------------------
Eval num_timesteps=2727048, episode_reward=-14.56 +/- 327.75
Episode length: 603.40 +/- 48.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | -14.6    |
| time/              |          |
|    total_timesteps | 2727048  |
---------------------------------
Eval num_timesteps=2729040, episode_reward=-259.60 +/- 20.81
Episode length: 609.60 +/- 44.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | -260     |
| time/              |          |
|    total_timesteps | 2729040  |
---------------------------------
Eval num_timesteps=2731032, episode_reward=-118.66 +/- 123.27
Episode length: 586.80 +/- 31.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | -119     |
| time/              |          |
|    total_timesteps | 2731032  |
---------------------------------
Eval num_timesteps=2733024, episode_reward=253.35 +/- 424.78
Episode length: 622.60 +/- 48.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 253      |
| time/              |          |
|    total_timesteps | 2733024  |
---------------------------------
Eval num_timesteps=2735016, episode_reward=-250.75 +/- 47.10
Episode length: 534.00 +/- 35.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 2735016  |
---------------------------------
Eval num_timesteps=2737008, episode_reward=-187.86 +/- 38.29
Episode length: 576.40 +/- 37.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | -188     |
| time/              |          |
|    total_timesteps | 2737008  |
---------------------------------
Eval num_timesteps=2739000, episode_reward=-241.20 +/- 34.38
Episode length: 620.20 +/- 36.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | -241     |
| time/              |          |
|    total_timesteps | 2739000  |
---------------------------------
Eval num_timesteps=2740992, episode_reward=-31.30 +/- 126.63
Episode length: 570.80 +/- 72.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | -31.3    |
| time/              |          |
|    total_timesteps | 2740992  |
---------------------------------
Eval num_timesteps=2742984, episode_reward=-82.92 +/- 285.24
Episode length: 631.00 +/- 89.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | -82.9    |
| time/              |          |
|    total_timesteps | 2742984  |
---------------------------------
Eval num_timesteps=2744976, episode_reward=-115.41 +/- 79.87
Episode length: 570.20 +/- 33.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | -115     |
| time/              |          |
|    total_timesteps | 2744976  |
---------------------------------
Eval num_timesteps=2746968, episode_reward=-76.86 +/- 229.01
Episode length: 567.40 +/- 60.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | -76.9    |
| time/              |          |
|    total_timesteps | 2746968  |
---------------------------------
Eval num_timesteps=2748960, episode_reward=-84.52 +/- 297.57
Episode length: 572.40 +/- 19.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | -84.5    |
| time/              |          |
|    total_timesteps | 2748960  |
---------------------------------
Eval num_timesteps=2750952, episode_reward=-198.06 +/- 57.96
Episode length: 595.40 +/- 30.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | -198     |
| time/              |          |
|    total_timesteps | 2750952  |
---------------------------------
Eval num_timesteps=2752944, episode_reward=-261.90 +/- 25.70
Episode length: 563.00 +/- 35.10
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 563          |
|    mean_reward          | -262         |
| time/                   |              |
|    total_timesteps      | 2752944      |
| train/                  |              |
|    approx_kl            | 0.0054688673 |
|    clip_fraction        | 0.0324       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.48        |
|    explained_variance   | 0.969        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0463      |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00107     |
|    std                  | 1.23         |
|    value_loss           | 0.0534       |
------------------------------------------
Eval num_timesteps=2754936, episode_reward=-185.88 +/- 102.86
Episode length: 568.40 +/- 46.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | -186     |
| time/              |          |
|    total_timesteps | 2754936  |
---------------------------------
Eval num_timesteps=2756928, episode_reward=-276.03 +/- 27.18
Episode length: 520.40 +/- 47.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 2756928  |
---------------------------------
Eval num_timesteps=2758920, episode_reward=-281.05 +/- 13.60
Episode length: 619.00 +/- 88.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 2758920  |
---------------------------------
Eval num_timesteps=2760912, episode_reward=-275.07 +/- 21.88
Episode length: 560.60 +/- 51.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | -275     |
| time/              |          |
|    total_timesteps | 2760912  |
---------------------------------
Eval num_timesteps=2762904, episode_reward=-240.08 +/- 39.40
Episode length: 549.20 +/- 91.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | -240     |
| time/              |          |
|    total_timesteps | 2762904  |
---------------------------------
Eval num_timesteps=2764896, episode_reward=-279.91 +/- 9.60
Episode length: 576.40 +/- 58.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 2764896  |
---------------------------------
Eval num_timesteps=2766888, episode_reward=-277.41 +/- 13.31
Episode length: 563.40 +/- 79.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | -277     |
| time/              |          |
|    total_timesteps | 2766888  |
---------------------------------
Eval num_timesteps=2768880, episode_reward=-279.72 +/- 13.49
Episode length: 539.80 +/- 54.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | -280     |
| time/              |          |
|    total_timesteps | 2768880  |
---------------------------------
Eval num_timesteps=2770872, episode_reward=-258.47 +/- 36.23
Episode length: 596.20 +/- 63.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 596      |
|    mean_reward     | -258     |
| time/              |          |
|    total_timesteps | 2770872  |
---------------------------------
Eval num_timesteps=2772864, episode_reward=-251.30 +/- 91.63
Episode length: 523.20 +/- 39.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 2772864  |
---------------------------------
Eval num_timesteps=2774856, episode_reward=-263.46 +/- 21.62
Episode length: 516.40 +/- 30.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | -263     |
| time/              |          |
|    total_timesteps | 2774856  |
---------------------------------
Eval num_timesteps=2776848, episode_reward=-180.80 +/- 221.83
Episode length: 614.40 +/- 80.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | -181     |
| time/              |          |
|    total_timesteps | 2776848  |
---------------------------------
Eval num_timesteps=2778840, episode_reward=-270.23 +/- 18.50
Episode length: 542.60 +/- 66.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 2778840  |
---------------------------------
Eval num_timesteps=2780832, episode_reward=-207.71 +/- 129.74
Episode length: 637.40 +/- 116.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | -208     |
| time/              |          |
|    total_timesteps | 2780832  |
---------------------------------
Eval num_timesteps=2782824, episode_reward=-285.28 +/- 13.56
Episode length: 612.20 +/- 113.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | -285     |
| time/              |          |
|    total_timesteps | 2782824  |
---------------------------------
Eval num_timesteps=2784816, episode_reward=-265.68 +/- 43.68
Episode length: 515.80 +/- 61.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 2784816  |
---------------------------------
Eval num_timesteps=2786808, episode_reward=-271.96 +/- 20.21
Episode length: 550.60 +/- 49.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | -272     |
| time/              |          |
|    total_timesteps | 2786808  |
---------------------------------
Eval num_timesteps=2788800, episode_reward=-282.64 +/- 9.79
Episode length: 557.00 +/- 55.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | -283     |
| time/              |          |
|    total_timesteps | 2788800  |
---------------------------------
Eval num_timesteps=2790792, episode_reward=-253.55 +/- 37.07
Episode length: 586.00 +/- 46.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 2790792  |
---------------------------------
Eval num_timesteps=2792784, episode_reward=-266.25 +/- 38.07
Episode length: 505.00 +/- 56.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 2792784  |
---------------------------------
Eval num_timesteps=2794776, episode_reward=-253.67 +/- 32.19
Episode length: 569.60 +/- 28.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | -254     |
| time/              |          |
|    total_timesteps | 2794776  |
---------------------------------
Eval num_timesteps=2796768, episode_reward=-236.91 +/- 78.68
Episode length: 514.80 +/- 62.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | -237     |
| time/              |          |
|    total_timesteps | 2796768  |
---------------------------------
Eval num_timesteps=2798760, episode_reward=-267.91 +/- 26.29
Episode length: 534.80 +/- 74.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | -268     |
| time/              |          |
|    total_timesteps | 2798760  |
---------------------------------
Eval num_timesteps=2800752, episode_reward=-288.36 +/- 6.46
Episode length: 543.60 +/- 67.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | -288     |
| time/              |          |
|    total_timesteps | 2800752  |
---------------------------------
Eval num_timesteps=2802744, episode_reward=-264.12 +/- 72.98
Episode length: 549.40 +/- 64.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 549         |
|    mean_reward          | -264        |
| time/                   |             |
|    total_timesteps      | 2802744     |
| train/                  |             |
|    approx_kl            | 0.016695244 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | 0.959       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0383     |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00149     |
|    std                  | 1.23        |
|    value_loss           | 0.0613      |
-----------------------------------------
Eval num_timesteps=2804736, episode_reward=-288.68 +/- 4.51
Episode length: 560.40 +/- 36.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 2804736  |
---------------------------------
Eval num_timesteps=2806728, episode_reward=-266.88 +/- 35.72
Episode length: 631.80 +/- 109.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 632      |
|    mean_reward     | -267     |
| time/              |          |
|    total_timesteps | 2806728  |
---------------------------------
Eval num_timesteps=2808720, episode_reward=-289.78 +/- 14.64
Episode length: 560.00 +/- 104.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 2808720  |
---------------------------------
Eval num_timesteps=2810712, episode_reward=-280.63 +/- 17.63
Episode length: 624.00 +/- 107.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 624      |
|    mean_reward     | -281     |
| time/              |          |
|    total_timesteps | 2810712  |
---------------------------------
Eval num_timesteps=2812704, episode_reward=-290.04 +/- 5.40
Episode length: 582.00 +/- 69.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | -290     |
| time/              |          |
|    total_timesteps | 2812704  |
---------------------------------
Eval num_timesteps=2814696, episode_reward=-287.35 +/- 21.89
Episode length: 590.40 +/- 84.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 590      |
|    mean_reward     | -287     |
| time/              |          |
|    total_timesteps | 2814696  |
---------------------------------
Eval num_timesteps=2816688, episode_reward=-297.26 +/- 21.83
Episode length: 629.80 +/- 81.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | -297     |
| time/              |          |
|    total_timesteps | 2816688  |
---------------------------------
Eval num_timesteps=2818680, episode_reward=-259.53 +/- 74.37
Episode length: 548.40 +/- 59.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | -260     |
| time/              |          |
|    total_timesteps | 2818680  |
---------------------------------
Eval num_timesteps=2820672, episode_reward=-286.43 +/- 12.22
Episode length: 651.40 +/- 119.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 651      |
|    mean_reward     | -286     |
| time/              |          |
|    total_timesteps | 2820672  |
---------------------------------
Eval num_timesteps=2822664, episode_reward=-296.00 +/- 24.88
Episode length: 552.40 +/- 103.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | -296     |
| time/              |          |
|    total_timesteps | 2822664  |
---------------------------------
Eval num_timesteps=2824656, episode_reward=-275.88 +/- 36.90
Episode length: 583.80 +/- 84.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 2824656  |
---------------------------------
Eval num_timesteps=2826648, episode_reward=-276.27 +/- 19.93
Episode length: 638.60 +/- 122.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 2826648  |
---------------------------------
Eval num_timesteps=2828640, episode_reward=-291.96 +/- 10.83
Episode length: 538.40 +/- 46.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 538      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 2828640  |
---------------------------------
Eval num_timesteps=2830632, episode_reward=-299.86 +/- 8.41
Episode length: 604.00 +/- 62.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | -300     |
| time/              |          |
|    total_timesteps | 2830632  |
---------------------------------
Eval num_timesteps=2832624, episode_reward=-288.61 +/- 4.94
Episode length: 544.00 +/- 60.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | -289     |
| time/              |          |
|    total_timesteps | 2832624  |
---------------------------------
Eval num_timesteps=2834616, episode_reward=-276.19 +/- 20.22
Episode length: 572.60 +/- 107.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | -276     |
| time/              |          |
|    total_timesteps | 2834616  |
---------------------------------
Eval num_timesteps=2836608, episode_reward=-291.52 +/- 9.18
Episode length: 512.40 +/- 26.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 2836608  |
---------------------------------
Eval num_timesteps=2838600, episode_reward=-302.07 +/- 10.80
Episode length: 539.60 +/- 63.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | -302     |
| time/              |          |
|    total_timesteps | 2838600  |
---------------------------------
Eval num_timesteps=2840592, episode_reward=-269.49 +/- 46.45
Episode length: 679.80 +/- 15.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 680      |
|    mean_reward     | -269     |
| time/              |          |
|    total_timesteps | 2840592  |
---------------------------------
Eval num_timesteps=2842584, episode_reward=-306.44 +/- 13.87
Episode length: 654.40 +/- 78.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 654      |
|    mean_reward     | -306     |
| time/              |          |
|    total_timesteps | 2842584  |
---------------------------------
Eval num_timesteps=2844576, episode_reward=-184.13 +/- 90.68
Episode length: 770.20 +/- 152.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 770      |
|    mean_reward     | -184     |
| time/              |          |
|    total_timesteps | 2844576  |
---------------------------------
Eval num_timesteps=2846568, episode_reward=-291.67 +/- 24.15
Episode length: 599.80 +/- 102.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 600      |
|    mean_reward     | -292     |
| time/              |          |
|    total_timesteps | 2846568  |
---------------------------------
Eval num_timesteps=2848560, episode_reward=-269.85 +/- 22.87
Episode length: 630.00 +/- 102.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | -270     |
| time/              |          |
|    total_timesteps | 2848560  |
---------------------------------
Eval num_timesteps=2850552, episode_reward=-175.15 +/- 101.07
Episode length: 637.80 +/- 91.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 638      |
|    mean_reward     | -175     |
| time/              |          |
|    total_timesteps | 2850552  |
---------------------------------
Eval num_timesteps=2852544, episode_reward=-184.68 +/- 51.22
Episode length: 689.60 +/- 113.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 690         |
|    mean_reward          | -185        |
| time/                   |             |
|    total_timesteps      | 2852544     |
| train/                  |             |
|    approx_kl            | 0.007056252 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.49       |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0409     |
|    n_updates            | 580         |
|    policy_gradient_loss | 0.00348     |
|    std                  | 1.24        |
|    value_loss           | 0.054       |
-----------------------------------------
Eval num_timesteps=2854536, episode_reward=15.13 +/- 378.60
Episode length: 663.40 +/- 41.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 663      |
|    mean_reward     | 15.1     |
| time/              |          |
|    total_timesteps | 2854536  |
---------------------------------
Eval num_timesteps=2856528, episode_reward=-156.03 +/- 194.04
Episode length: 649.60 +/- 54.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 650      |
|    mean_reward     | -156     |
| time/              |          |
|    total_timesteps | 2856528  |
---------------------------------
Eval num_timesteps=2858520, episode_reward=128.15 +/- 712.20
Episode length: 683.60 +/- 112.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 684      |
|    mean_reward     | 128      |
| time/              |          |
|    total_timesteps | 2858520  |
---------------------------------
Eval num_timesteps=2860512, episode_reward=-200.91 +/- 60.71
Episode length: 659.80 +/- 60.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 660      |
|    mean_reward     | -201     |
| time/              |          |
|    total_timesteps | 2860512  |
---------------------------------
Eval num_timesteps=2862504, episode_reward=-180.34 +/- 64.04
Episode length: 663.60 +/- 98.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 664      |
|    mean_reward     | -180     |
| time/              |          |
|    total_timesteps | 2862504  |
---------------------------------
Eval num_timesteps=2864496, episode_reward=-103.90 +/- 329.58
Episode length: 689.20 +/- 141.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | -104     |
| time/              |          |
|    total_timesteps | 2864496  |
---------------------------------
Eval num_timesteps=2866488, episode_reward=-250.88 +/- 42.25
Episode length: 634.80 +/- 45.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | -251     |
| time/              |          |
|    total_timesteps | 2866488  |
---------------------------------
Eval num_timesteps=2868480, episode_reward=-259.96 +/- 30.09
Episode length: 584.20 +/- 62.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | -260     |
| time/              |          |
|    total_timesteps | 2868480  |
---------------------------------
Eval num_timesteps=2870472, episode_reward=-151.12 +/- 161.59
Episode length: 748.00 +/- 112.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 748      |
|    mean_reward     | -151     |
| time/              |          |
|    total_timesteps | 2870472  |
---------------------------------
Eval num_timesteps=2872464, episode_reward=-265.98 +/- 41.77
Episode length: 617.00 +/- 43.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 617      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 2872464  |
---------------------------------
Eval num_timesteps=2874456, episode_reward=-220.14 +/- 72.38
Episode length: 772.20 +/- 208.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 772      |
|    mean_reward     | -220     |
| time/              |          |
|    total_timesteps | 2874456  |
---------------------------------
Eval num_timesteps=2876448, episode_reward=-160.51 +/- 144.71
Episode length: 712.20 +/- 64.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 712      |
|    mean_reward     | -161     |
| time/              |          |
|    total_timesteps | 2876448  |
---------------------------------
Eval num_timesteps=2878440, episode_reward=-84.46 +/- 236.06
Episode length: 598.20 +/- 97.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 598      |
|    mean_reward     | -84.5    |
| time/              |          |
|    total_timesteps | 2878440  |
---------------------------------
Eval num_timesteps=2880432, episode_reward=-249.36 +/- 76.28
Episode length: 688.80 +/- 143.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | -249     |
| time/              |          |
|    total_timesteps | 2880432  |
---------------------------------
Eval num_timesteps=2882424, episode_reward=-42.59 +/- 216.27
Episode length: 699.20 +/- 128.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 699      |
|    mean_reward     | -42.6    |
| time/              |          |
|    total_timesteps | 2882424  |
---------------------------------
Eval num_timesteps=2884416, episode_reward=-215.83 +/- 87.05
Episode length: 675.60 +/- 161.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 676      |
|    mean_reward     | -216     |
| time/              |          |
|    total_timesteps | 2884416  |
---------------------------------
Eval num_timesteps=2886408, episode_reward=-44.65 +/- 272.56
Episode length: 715.60 +/- 124.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 716      |
|    mean_reward     | -44.7    |
| time/              |          |
|    total_timesteps | 2886408  |
---------------------------------
Eval num_timesteps=2888400, episode_reward=-163.63 +/- 214.34
Episode length: 652.60 +/- 66.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 653      |
|    mean_reward     | -164     |
| time/              |          |
|    total_timesteps | 2888400  |
---------------------------------
Eval num_timesteps=2890392, episode_reward=-265.72 +/- 40.81
Episode length: 684.00 +/- 64.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 684      |
|    mean_reward     | -266     |
| time/              |          |
|    total_timesteps | 2890392  |
---------------------------------
Eval num_timesteps=2892384, episode_reward=-95.55 +/- 228.68
Episode length: 632.80 +/- 80.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | -95.5    |
| time/              |          |
|    total_timesteps | 2892384  |
---------------------------------
Eval num_timesteps=2894376, episode_reward=-170.23 +/- 123.45
Episode length: 611.60 +/- 33.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | -170     |
| time/              |          |
|    total_timesteps | 2894376  |
---------------------------------
Eval num_timesteps=2896368, episode_reward=-160.07 +/- 101.46
Episode length: 697.20 +/- 76.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | -160     |
| time/              |          |
|    total_timesteps | 2896368  |
---------------------------------
Eval num_timesteps=2898360, episode_reward=-268.27 +/- 34.77
Episode length: 671.00 +/- 93.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | -268     |
| time/              |          |
|    total_timesteps | 2898360  |
---------------------------------
Eval num_timesteps=2900352, episode_reward=249.20 +/- 557.49
Episode length: 706.20 +/- 128.81
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 706          |
|    mean_reward          | 249          |
| time/                   |              |
|    total_timesteps      | 2900352      |
| train/                  |              |
|    approx_kl            | 0.0063704527 |
|    clip_fraction        | 0.0646       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.53        |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0409      |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00139     |
|    std                  | 1.24         |
|    value_loss           | 0.0652       |
------------------------------------------
Eval num_timesteps=2902344, episode_reward=157.07 +/- 621.14
Episode length: 703.20 +/- 75.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 703      |
|    mean_reward     | 157      |
| time/              |          |
|    total_timesteps | 2902344  |
---------------------------------
Eval num_timesteps=2904336, episode_reward=261.41 +/- 788.21
Episode length: 760.00 +/- 165.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 760      |
|    mean_reward     | 261      |
| time/              |          |
|    total_timesteps | 2904336  |
---------------------------------
Eval num_timesteps=2906328, episode_reward=204.65 +/- 488.61
Episode length: 745.60 +/- 89.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 746      |
|    mean_reward     | 205      |
| time/              |          |
|    total_timesteps | 2906328  |
---------------------------------
Eval num_timesteps=2908320, episode_reward=-31.76 +/- 297.11
Episode length: 691.60 +/- 48.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 692      |
|    mean_reward     | -31.8    |
| time/              |          |
|    total_timesteps | 2908320  |
---------------------------------
Eval num_timesteps=2910312, episode_reward=-221.09 +/- 51.61
Episode length: 669.60 +/- 81.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 670      |
|    mean_reward     | -221     |
| time/              |          |
|    total_timesteps | 2910312  |
---------------------------------
Eval num_timesteps=2912304, episode_reward=-159.53 +/- 113.50
Episode length: 730.60 +/- 138.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 731      |
|    mean_reward     | -160     |
| time/              |          |
|    total_timesteps | 2912304  |
---------------------------------
Eval num_timesteps=2914296, episode_reward=-29.31 +/- 331.66
Episode length: 701.60 +/- 83.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | -29.3    |
| time/              |          |
|    total_timesteps | 2914296  |
---------------------------------
Eval num_timesteps=2916288, episode_reward=80.59 +/- 471.83
Episode length: 670.60 +/- 98.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | 80.6     |
| time/              |          |
|    total_timesteps | 2916288  |
---------------------------------
Eval num_timesteps=2918280, episode_reward=133.40 +/- 324.55
Episode length: 690.20 +/- 127.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 690      |
|    mean_reward     | 133      |
| time/              |          |
|    total_timesteps | 2918280  |
---------------------------------
Eval num_timesteps=2920272, episode_reward=-118.99 +/- 166.55
Episode length: 754.20 +/- 130.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 754      |
|    mean_reward     | -119     |
| time/              |          |
|    total_timesteps | 2920272  |
---------------------------------
Eval num_timesteps=2922264, episode_reward=-106.39 +/- 275.85
Episode length: 653.00 +/- 92.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 653      |
|    mean_reward     | -106     |
| time/              |          |
|    total_timesteps | 2922264  |
---------------------------------
Eval num_timesteps=2924256, episode_reward=27.12 +/- 310.14
Episode length: 660.60 +/- 69.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 661      |
|    mean_reward     | 27.1     |
| time/              |          |
|    total_timesteps | 2924256  |
---------------------------------
Eval num_timesteps=2926248, episode_reward=201.15 +/- 421.53
Episode length: 679.60 +/- 87.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 680      |
|    mean_reward     | 201      |
| time/              |          |
|    total_timesteps | 2926248  |
---------------------------------
Eval num_timesteps=2928240, episode_reward=134.97 +/- 364.15
Episode length: 803.20 +/- 66.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 803      |
|    mean_reward     | 135      |
| time/              |          |
|    total_timesteps | 2928240  |
---------------------------------
Eval num_timesteps=2930232, episode_reward=-97.58 +/- 173.74
Episode length: 738.60 +/- 77.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 739      |
|    mean_reward     | -97.6    |
| time/              |          |
|    total_timesteps | 2930232  |
---------------------------------
Eval num_timesteps=2932224, episode_reward=-216.61 +/- 40.26
Episode length: 758.00 +/- 94.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 758      |
|    mean_reward     | -217     |
| time/              |          |
|    total_timesteps | 2932224  |
---------------------------------
Eval num_timesteps=2934216, episode_reward=10.45 +/- 175.27
Episode length: 865.40 +/- 58.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 865      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 2934216  |
---------------------------------
Eval num_timesteps=2936208, episode_reward=-33.83 +/- 319.50
Episode length: 860.60 +/- 145.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 861      |
|    mean_reward     | -33.8    |
| time/              |          |
|    total_timesteps | 2936208  |
---------------------------------
Eval num_timesteps=2938200, episode_reward=-77.66 +/- 115.12
Episode length: 778.60 +/- 93.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 779      |
|    mean_reward     | -77.7    |
| time/              |          |
|    total_timesteps | 2938200  |
---------------------------------
Eval num_timesteps=2940192, episode_reward=40.42 +/- 256.64
Episode length: 772.40 +/- 90.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 772      |
|    mean_reward     | 40.4     |
| time/              |          |
|    total_timesteps | 2940192  |
---------------------------------
Eval num_timesteps=2942184, episode_reward=-270.91 +/- 32.24
Episode length: 654.80 +/- 91.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 655      |
|    mean_reward     | -271     |
| time/              |          |
|    total_timesteps | 2942184  |
---------------------------------
Eval num_timesteps=2944176, episode_reward=-168.72 +/- 104.77
Episode length: 697.20 +/- 119.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | -169     |
| time/              |          |
|    total_timesteps | 2944176  |
---------------------------------
Eval num_timesteps=2946168, episode_reward=-59.23 +/- 208.41
Episode length: 660.20 +/- 40.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 660      |
|    mean_reward     | -59.2    |
| time/              |          |
|    total_timesteps | 2946168  |
---------------------------------
Eval num_timesteps=2948160, episode_reward=135.29 +/- 468.63
Episode length: 805.00 +/- 131.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 805      |
|    mean_reward     | 135      |
| time/              |          |
|    total_timesteps | 2948160  |
---------------------------------
Eval num_timesteps=2950152, episode_reward=144.26 +/- 343.63
Episode length: 630.40 +/- 107.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 630         |
|    mean_reward          | 144         |
| time/                   |             |
|    total_timesteps      | 2950152     |
| train/                  |             |
|    approx_kl            | 0.005604717 |
|    clip_fraction        | 0.0505      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.55       |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0384     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0018     |
|    std                  | 1.25        |
|    value_loss           | 0.0698      |
-----------------------------------------
Eval num_timesteps=2952144, episode_reward=336.02 +/- 245.08
Episode length: 569.80 +/- 20.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 336      |
| time/              |          |
|    total_timesteps | 2952144  |
---------------------------------
Eval num_timesteps=2954136, episode_reward=168.52 +/- 270.67
Episode length: 664.40 +/- 141.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 664      |
|    mean_reward     | 169      |
| time/              |          |
|    total_timesteps | 2954136  |
---------------------------------
Eval num_timesteps=2956128, episode_reward=289.89 +/- 229.88
Episode length: 703.20 +/- 186.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 703      |
|    mean_reward     | 290      |
| time/              |          |
|    total_timesteps | 2956128  |
---------------------------------
Eval num_timesteps=2958120, episode_reward=95.61 +/- 336.03
Episode length: 707.40 +/- 116.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 707      |
|    mean_reward     | 95.6     |
| time/              |          |
|    total_timesteps | 2958120  |
---------------------------------
Eval num_timesteps=2960112, episode_reward=145.43 +/- 303.78
Episode length: 631.60 +/- 91.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 632      |
|    mean_reward     | 145      |
| time/              |          |
|    total_timesteps | 2960112  |
---------------------------------
Eval num_timesteps=2962104, episode_reward=95.94 +/- 339.94
Episode length: 735.80 +/- 99.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 736      |
|    mean_reward     | 95.9     |
| time/              |          |
|    total_timesteps | 2962104  |
---------------------------------
Eval num_timesteps=2964096, episode_reward=269.06 +/- 193.74
Episode length: 558.00 +/- 12.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | 269      |
| time/              |          |
|    total_timesteps | 2964096  |
---------------------------------
Eval num_timesteps=2966088, episode_reward=679.26 +/- 137.67
Episode length: 729.20 +/- 149.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 729      |
|    mean_reward     | 679      |
| time/              |          |
|    total_timesteps | 2966088  |
---------------------------------
Eval num_timesteps=2968080, episode_reward=370.13 +/- 409.78
Episode length: 651.40 +/- 139.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 651      |
|    mean_reward     | 370      |
| time/              |          |
|    total_timesteps | 2968080  |
---------------------------------
Eval num_timesteps=2970072, episode_reward=367.92 +/- 176.07
Episode length: 710.60 +/- 134.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 711      |
|    mean_reward     | 368      |
| time/              |          |
|    total_timesteps | 2970072  |
---------------------------------
Eval num_timesteps=2972064, episode_reward=402.45 +/- 516.62
Episode length: 619.20 +/- 99.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 402      |
| time/              |          |
|    total_timesteps | 2972064  |
---------------------------------
Eval num_timesteps=2974056, episode_reward=554.05 +/- 438.49
Episode length: 638.00 +/- 114.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 638      |
|    mean_reward     | 554      |
| time/              |          |
|    total_timesteps | 2974056  |
---------------------------------
Eval num_timesteps=2976048, episode_reward=215.35 +/- 365.79
Episode length: 569.60 +/- 73.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 215      |
| time/              |          |
|    total_timesteps | 2976048  |
---------------------------------
Eval num_timesteps=2978040, episode_reward=311.35 +/- 249.14
Episode length: 627.00 +/- 36.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 311      |
| time/              |          |
|    total_timesteps | 2978040  |
---------------------------------
Eval num_timesteps=2980032, episode_reward=546.16 +/- 373.90
Episode length: 653.00 +/- 65.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 653      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 2980032  |
---------------------------------
Eval num_timesteps=2982024, episode_reward=288.25 +/- 445.77
Episode length: 653.40 +/- 46.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 653      |
|    mean_reward     | 288      |
| time/              |          |
|    total_timesteps | 2982024  |
---------------------------------
Eval num_timesteps=2984016, episode_reward=173.42 +/- 391.21
Episode length: 673.80 +/- 107.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 674      |
|    mean_reward     | 173      |
| time/              |          |
|    total_timesteps | 2984016  |
---------------------------------
Eval num_timesteps=2986008, episode_reward=363.07 +/- 254.29
Episode length: 658.40 +/- 137.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 658      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 2986008  |
---------------------------------
Eval num_timesteps=2988000, episode_reward=568.62 +/- 177.49
Episode length: 628.00 +/- 176.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 2988000  |
---------------------------------
Eval num_timesteps=2989992, episode_reward=267.34 +/- 380.66
Episode length: 666.00 +/- 121.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 666      |
|    mean_reward     | 267      |
| time/              |          |
|    total_timesteps | 2989992  |
---------------------------------
Eval num_timesteps=2991984, episode_reward=586.28 +/- 372.69
Episode length: 617.00 +/- 44.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 617      |
|    mean_reward     | 586      |
| time/              |          |
|    total_timesteps | 2991984  |
---------------------------------
Eval num_timesteps=2993976, episode_reward=592.55 +/- 149.69
Episode length: 657.80 +/- 36.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 658      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 2993976  |
---------------------------------
Eval num_timesteps=2995968, episode_reward=675.83 +/- 536.41
Episode length: 634.60 +/- 76.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 676      |
| time/              |          |
|    total_timesteps | 2995968  |
---------------------------------
Eval num_timesteps=2997960, episode_reward=673.98 +/- 413.25
Episode length: 604.00 +/- 113.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 2997960  |
---------------------------------
Eval num_timesteps=2999952, episode_reward=-33.90 +/- 252.21
Episode length: 498.20 +/- 25.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 498         |
|    mean_reward          | -33.9       |
| time/                   |             |
|    total_timesteps      | 2999952     |
| train/                  |             |
|    approx_kl            | 0.007873161 |
|    clip_fraction        | 0.0663      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.001       |
|    loss                 | -0.003      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00195    |
|    std                  | 1.26        |
|    value_loss           | 0.15        |
-----------------------------------------
Eval num_timesteps=3001944, episode_reward=-94.58 +/- 94.99
Episode length: 679.60 +/- 414.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 680      |
|    mean_reward     | -94.6    |
| time/              |          |
|    total_timesteps | 3001944  |
---------------------------------
Eval num_timesteps=3003936, episode_reward=114.45 +/- 548.80
Episode length: 513.80 +/- 98.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 114      |
| time/              |          |
|    total_timesteps | 3003936  |
---------------------------------
Eval num_timesteps=3005928, episode_reward=-78.07 +/- 214.44
Episode length: 521.20 +/- 111.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | -78.1    |
| time/              |          |
|    total_timesteps | 3005928  |
---------------------------------
Eval num_timesteps=3007920, episode_reward=244.31 +/- 491.82
Episode length: 622.60 +/- 181.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 244      |
| time/              |          |
|    total_timesteps | 3007920  |
---------------------------------
Eval num_timesteps=3009912, episode_reward=-89.99 +/- 178.41
Episode length: 520.00 +/- 31.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | -90      |
| time/              |          |
|    total_timesteps | 3009912  |
---------------------------------
Eval num_timesteps=3011904, episode_reward=85.80 +/- 266.18
Episode length: 474.00 +/- 29.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 474      |
|    mean_reward     | 85.8     |
| time/              |          |
|    total_timesteps | 3011904  |
---------------------------------
Eval num_timesteps=3013896, episode_reward=33.85 +/- 142.09
Episode length: 637.20 +/- 260.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | 33.9     |
| time/              |          |
|    total_timesteps | 3013896  |
---------------------------------
Eval num_timesteps=3015888, episode_reward=144.03 +/- 355.17
Episode length: 533.00 +/- 37.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 144      |
| time/              |          |
|    total_timesteps | 3015888  |
---------------------------------
Eval num_timesteps=3017880, episode_reward=-110.74 +/- 124.94
Episode length: 561.20 +/- 122.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | -111     |
| time/              |          |
|    total_timesteps | 3017880  |
---------------------------------
Eval num_timesteps=3019872, episode_reward=-39.57 +/- 276.89
Episode length: 508.40 +/- 67.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -39.6    |
| time/              |          |
|    total_timesteps | 3019872  |
---------------------------------
Eval num_timesteps=3021864, episode_reward=57.80 +/- 165.67
Episode length: 631.00 +/- 199.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 57.8     |
| time/              |          |
|    total_timesteps | 3021864  |
---------------------------------
Eval num_timesteps=3023856, episode_reward=86.39 +/- 177.04
Episode length: 487.80 +/- 39.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | 86.4     |
| time/              |          |
|    total_timesteps | 3023856  |
---------------------------------
Eval num_timesteps=3025848, episode_reward=470.66 +/- 640.59
Episode length: 596.60 +/- 204.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | 471      |
| time/              |          |
|    total_timesteps | 3025848  |
---------------------------------
Eval num_timesteps=3027840, episode_reward=274.96 +/- 325.50
Episode length: 687.40 +/- 327.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 687      |
|    mean_reward     | 275      |
| time/              |          |
|    total_timesteps | 3027840  |
---------------------------------
Eval num_timesteps=3029832, episode_reward=139.45 +/- 387.05
Episode length: 485.20 +/- 40.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 485      |
|    mean_reward     | 139      |
| time/              |          |
|    total_timesteps | 3029832  |
---------------------------------
Eval num_timesteps=3031824, episode_reward=151.38 +/- 342.62
Episode length: 492.40 +/- 28.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | 151      |
| time/              |          |
|    total_timesteps | 3031824  |
---------------------------------
Eval num_timesteps=3033816, episode_reward=-20.85 +/- 201.03
Episode length: 505.20 +/- 61.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | -20.9    |
| time/              |          |
|    total_timesteps | 3033816  |
---------------------------------
Eval num_timesteps=3035808, episode_reward=274.68 +/- 355.50
Episode length: 541.00 +/- 110.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 275      |
| time/              |          |
|    total_timesteps | 3035808  |
---------------------------------
Eval num_timesteps=3037800, episode_reward=128.42 +/- 376.10
Episode length: 512.40 +/- 100.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 128      |
| time/              |          |
|    total_timesteps | 3037800  |
---------------------------------
Eval num_timesteps=3039792, episode_reward=8.65 +/- 206.69
Episode length: 480.60 +/- 34.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | 8.65     |
| time/              |          |
|    total_timesteps | 3039792  |
---------------------------------
Eval num_timesteps=3041784, episode_reward=15.28 +/- 145.33
Episode length: 573.80 +/- 129.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | 15.3     |
| time/              |          |
|    total_timesteps | 3041784  |
---------------------------------
Eval num_timesteps=3043776, episode_reward=94.91 +/- 179.01
Episode length: 610.00 +/- 154.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 94.9     |
| time/              |          |
|    total_timesteps | 3043776  |
---------------------------------
Eval num_timesteps=3045768, episode_reward=148.85 +/- 215.75
Episode length: 509.80 +/- 51.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 149      |
| time/              |          |
|    total_timesteps | 3045768  |
---------------------------------
Eval num_timesteps=3047760, episode_reward=24.62 +/- 111.67
Episode length: 535.20 +/- 134.03
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 535          |
|    mean_reward          | 24.6         |
| time/                   |              |
|    total_timesteps      | 3047760      |
| train/                  |              |
|    approx_kl            | 0.0067981062 |
|    clip_fraction        | 0.0467       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.6         |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0253      |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.0018      |
|    std                  | 1.27         |
|    value_loss           | 0.0981       |
------------------------------------------
Eval num_timesteps=3049752, episode_reward=-12.88 +/- 249.98
Episode length: 441.60 +/- 24.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -12.9    |
| time/              |          |
|    total_timesteps | 3049752  |
---------------------------------
Eval num_timesteps=3051744, episode_reward=-168.19 +/- 57.93
Episode length: 487.40 +/- 65.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | -168     |
| time/              |          |
|    total_timesteps | 3051744  |
---------------------------------
Eval num_timesteps=3053736, episode_reward=13.46 +/- 190.04
Episode length: 438.20 +/- 8.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 438      |
|    mean_reward     | 13.5     |
| time/              |          |
|    total_timesteps | 3053736  |
---------------------------------
Eval num_timesteps=3055728, episode_reward=-50.28 +/- 78.72
Episode length: 492.60 +/- 32.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | -50.3    |
| time/              |          |
|    total_timesteps | 3055728  |
---------------------------------
Eval num_timesteps=3057720, episode_reward=-102.32 +/- 137.71
Episode length: 464.40 +/- 8.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -102     |
| time/              |          |
|    total_timesteps | 3057720  |
---------------------------------
Eval num_timesteps=3059712, episode_reward=-82.51 +/- 87.94
Episode length: 437.20 +/- 20.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 437      |
|    mean_reward     | -82.5    |
| time/              |          |
|    total_timesteps | 3059712  |
---------------------------------
Eval num_timesteps=3061704, episode_reward=153.76 +/- 314.80
Episode length: 482.60 +/- 40.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | 154      |
| time/              |          |
|    total_timesteps | 3061704  |
---------------------------------
Eval num_timesteps=3063696, episode_reward=-133.53 +/- 84.16
Episode length: 478.40 +/- 20.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | -134     |
| time/              |          |
|    total_timesteps | 3063696  |
---------------------------------
Eval num_timesteps=3065688, episode_reward=-101.46 +/- 158.77
Episode length: 464.80 +/- 47.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | -101     |
| time/              |          |
|    total_timesteps | 3065688  |
---------------------------------
Eval num_timesteps=3067680, episode_reward=-40.12 +/- 284.35
Episode length: 470.40 +/- 45.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -40.1    |
| time/              |          |
|    total_timesteps | 3067680  |
---------------------------------
Eval num_timesteps=3069672, episode_reward=-13.86 +/- 106.66
Episode length: 472.00 +/- 26.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | -13.9    |
| time/              |          |
|    total_timesteps | 3069672  |
---------------------------------
Eval num_timesteps=3071664, episode_reward=81.02 +/- 361.06
Episode length: 501.20 +/- 60.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 81       |
| time/              |          |
|    total_timesteps | 3071664  |
---------------------------------
Eval num_timesteps=3073656, episode_reward=-68.61 +/- 111.23
Episode length: 469.60 +/- 23.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -68.6    |
| time/              |          |
|    total_timesteps | 3073656  |
---------------------------------
Eval num_timesteps=3075648, episode_reward=-61.83 +/- 89.20
Episode length: 459.00 +/- 21.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 459      |
|    mean_reward     | -61.8    |
| time/              |          |
|    total_timesteps | 3075648  |
---------------------------------
Eval num_timesteps=3077640, episode_reward=-71.15 +/- 117.13
Episode length: 436.00 +/- 32.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | -71.2    |
| time/              |          |
|    total_timesteps | 3077640  |
---------------------------------
Eval num_timesteps=3079632, episode_reward=-110.64 +/- 78.66
Episode length: 451.60 +/- 45.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 452      |
|    mean_reward     | -111     |
| time/              |          |
|    total_timesteps | 3079632  |
---------------------------------
Eval num_timesteps=3081624, episode_reward=-68.95 +/- 122.11
Episode length: 466.40 +/- 34.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | -69      |
| time/              |          |
|    total_timesteps | 3081624  |
---------------------------------
Eval num_timesteps=3083616, episode_reward=31.14 +/- 194.92
Episode length: 455.80 +/- 15.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | 31.1     |
| time/              |          |
|    total_timesteps | 3083616  |
---------------------------------
Eval num_timesteps=3085608, episode_reward=-73.89 +/- 189.57
Episode length: 553.60 +/- 167.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | -73.9    |
| time/              |          |
|    total_timesteps | 3085608  |
---------------------------------
Eval num_timesteps=3087600, episode_reward=-88.17 +/- 156.13
Episode length: 573.40 +/- 149.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | -88.2    |
| time/              |          |
|    total_timesteps | 3087600  |
---------------------------------
Eval num_timesteps=3089592, episode_reward=-83.86 +/- 102.29
Episode length: 432.00 +/- 34.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | -83.9    |
| time/              |          |
|    total_timesteps | 3089592  |
---------------------------------
Eval num_timesteps=3091584, episode_reward=-162.12 +/- 103.03
Episode length: 451.20 +/- 19.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 451      |
|    mean_reward     | -162     |
| time/              |          |
|    total_timesteps | 3091584  |
---------------------------------
Eval num_timesteps=3093576, episode_reward=-142.52 +/- 94.46
Episode length: 424.20 +/- 9.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 424      |
|    mean_reward     | -143     |
| time/              |          |
|    total_timesteps | 3093576  |
---------------------------------
Eval num_timesteps=3095568, episode_reward=-27.62 +/- 111.02
Episode length: 475.20 +/- 44.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | -27.6    |
| time/              |          |
|    total_timesteps | 3095568  |
---------------------------------
Eval num_timesteps=3097560, episode_reward=-105.39 +/- 91.41
Episode length: 474.60 +/- 55.39
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 475          |
|    mean_reward          | -105         |
| time/                   |              |
|    total_timesteps      | 3097560      |
| train/                  |              |
|    approx_kl            | 0.0074043265 |
|    clip_fraction        | 0.067        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.64        |
|    explained_variance   | 0.965        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0381      |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00205     |
|    std                  | 1.28         |
|    value_loss           | 0.0751       |
------------------------------------------
Eval num_timesteps=3099552, episode_reward=86.56 +/- 249.09
Episode length: 486.20 +/- 34.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 86.6     |
| time/              |          |
|    total_timesteps | 3099552  |
---------------------------------
Eval num_timesteps=3101544, episode_reward=-41.94 +/- 94.08
Episode length: 461.00 +/- 36.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | -41.9    |
| time/              |          |
|    total_timesteps | 3101544  |
---------------------------------
Eval num_timesteps=3103536, episode_reward=196.24 +/- 420.64
Episode length: 509.20 +/- 81.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 196      |
| time/              |          |
|    total_timesteps | 3103536  |
---------------------------------
Eval num_timesteps=3105528, episode_reward=-94.73 +/- 122.69
Episode length: 427.60 +/- 28.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 428      |
|    mean_reward     | -94.7    |
| time/              |          |
|    total_timesteps | 3105528  |
---------------------------------
Eval num_timesteps=3107520, episode_reward=-28.36 +/- 186.95
Episode length: 445.60 +/- 21.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -28.4    |
| time/              |          |
|    total_timesteps | 3107520  |
---------------------------------
Eval num_timesteps=3109512, episode_reward=98.15 +/- 299.65
Episode length: 465.60 +/- 17.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 98.2     |
| time/              |          |
|    total_timesteps | 3109512  |
---------------------------------
Eval num_timesteps=3111504, episode_reward=49.84 +/- 351.21
Episode length: 466.00 +/- 26.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 49.8     |
| time/              |          |
|    total_timesteps | 3111504  |
---------------------------------
Eval num_timesteps=3113496, episode_reward=77.25 +/- 199.03
Episode length: 481.40 +/- 38.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | 77.3     |
| time/              |          |
|    total_timesteps | 3113496  |
---------------------------------
Eval num_timesteps=3115488, episode_reward=48.11 +/- 192.99
Episode length: 492.80 +/- 64.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | 48.1     |
| time/              |          |
|    total_timesteps | 3115488  |
---------------------------------
Eval num_timesteps=3117480, episode_reward=-103.76 +/- 120.29
Episode length: 445.60 +/- 41.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 446      |
|    mean_reward     | -104     |
| time/              |          |
|    total_timesteps | 3117480  |
---------------------------------
Eval num_timesteps=3119472, episode_reward=-195.68 +/- 35.76
Episode length: 458.40 +/- 35.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 458      |
|    mean_reward     | -196     |
| time/              |          |
|    total_timesteps | 3119472  |
---------------------------------
Eval num_timesteps=3121464, episode_reward=-26.94 +/- 64.72
Episode length: 445.00 +/- 25.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | -26.9    |
| time/              |          |
|    total_timesteps | 3121464  |
---------------------------------
Eval num_timesteps=3123456, episode_reward=-107.15 +/- 67.00
Episode length: 441.80 +/- 16.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | -107     |
| time/              |          |
|    total_timesteps | 3123456  |
---------------------------------
Eval num_timesteps=3125448, episode_reward=38.64 +/- 167.27
Episode length: 455.00 +/- 21.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 38.6     |
| time/              |          |
|    total_timesteps | 3125448  |
---------------------------------
Eval num_timesteps=3127440, episode_reward=53.44 +/- 275.03
Episode length: 454.40 +/- 28.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | 53.4     |
| time/              |          |
|    total_timesteps | 3127440  |
---------------------------------
Eval num_timesteps=3129432, episode_reward=-155.25 +/- 37.85
Episode length: 472.80 +/- 28.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | -155     |
| time/              |          |
|    total_timesteps | 3129432  |
---------------------------------
Eval num_timesteps=3131424, episode_reward=-87.96 +/- 120.23
Episode length: 464.20 +/- 32.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | -88      |
| time/              |          |
|    total_timesteps | 3131424  |
---------------------------------
Eval num_timesteps=3133416, episode_reward=-2.36 +/- 197.58
Episode length: 470.40 +/- 46.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | -2.36    |
| time/              |          |
|    total_timesteps | 3133416  |
---------------------------------
Eval num_timesteps=3135408, episode_reward=-122.09 +/- 104.89
Episode length: 507.80 +/- 44.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | -122     |
| time/              |          |
|    total_timesteps | 3135408  |
---------------------------------
Eval num_timesteps=3137400, episode_reward=-41.04 +/- 139.74
Episode length: 456.20 +/- 48.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | -41      |
| time/              |          |
|    total_timesteps | 3137400  |
---------------------------------
Eval num_timesteps=3139392, episode_reward=-163.20 +/- 62.53
Episode length: 486.00 +/- 39.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | -163     |
| time/              |          |
|    total_timesteps | 3139392  |
---------------------------------
Eval num_timesteps=3141384, episode_reward=-24.11 +/- 297.84
Episode length: 460.40 +/- 37.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | -24.1    |
| time/              |          |
|    total_timesteps | 3141384  |
---------------------------------
Eval num_timesteps=3143376, episode_reward=5.90 +/- 179.13
Episode length: 477.20 +/- 22.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 5.9      |
| time/              |          |
|    total_timesteps | 3143376  |
---------------------------------
Eval num_timesteps=3145368, episode_reward=-43.63 +/- 76.27
Episode length: 455.40 +/- 30.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | -43.6    |
| time/              |          |
|    total_timesteps | 3145368  |
---------------------------------
Eval num_timesteps=3147360, episode_reward=155.73 +/- 280.88
Episode length: 473.20 +/- 39.28
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 473         |
|    mean_reward          | 156         |
| time/                   |             |
|    total_timesteps      | 3147360     |
| train/                  |             |
|    approx_kl            | 0.008024356 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.67       |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0226     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00277    |
|    std                  | 1.29        |
|    value_loss           | 0.128       |
-----------------------------------------
Eval num_timesteps=3149352, episode_reward=265.20 +/- 337.73
Episode length: 508.60 +/- 45.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 265      |
| time/              |          |
|    total_timesteps | 3149352  |
---------------------------------
Eval num_timesteps=3151344, episode_reward=111.26 +/- 299.65
Episode length: 496.20 +/- 46.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | 111      |
| time/              |          |
|    total_timesteps | 3151344  |
---------------------------------
Eval num_timesteps=3153336, episode_reward=258.00 +/- 326.06
Episode length: 515.40 +/- 44.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 258      |
| time/              |          |
|    total_timesteps | 3153336  |
---------------------------------
Eval num_timesteps=3155328, episode_reward=-34.17 +/- 57.73
Episode length: 453.40 +/- 29.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 453      |
|    mean_reward     | -34.2    |
| time/              |          |
|    total_timesteps | 3155328  |
---------------------------------
Eval num_timesteps=3157320, episode_reward=53.07 +/- 174.90
Episode length: 582.20 +/- 191.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 53.1     |
| time/              |          |
|    total_timesteps | 3157320  |
---------------------------------
Eval num_timesteps=3159312, episode_reward=363.81 +/- 377.98
Episode length: 523.00 +/- 73.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 3159312  |
---------------------------------
Eval num_timesteps=3161304, episode_reward=265.32 +/- 128.91
Episode length: 511.40 +/- 62.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 265      |
| time/              |          |
|    total_timesteps | 3161304  |
---------------------------------
Eval num_timesteps=3163296, episode_reward=359.37 +/- 245.19
Episode length: 515.40 +/- 62.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 359      |
| time/              |          |
|    total_timesteps | 3163296  |
---------------------------------
Eval num_timesteps=3165288, episode_reward=324.98 +/- 273.73
Episode length: 562.20 +/- 173.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 325      |
| time/              |          |
|    total_timesteps | 3165288  |
---------------------------------
Eval num_timesteps=3167280, episode_reward=253.87 +/- 233.19
Episode length: 476.00 +/- 13.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | 254      |
| time/              |          |
|    total_timesteps | 3167280  |
---------------------------------
Eval num_timesteps=3169272, episode_reward=496.74 +/- 200.70
Episode length: 505.40 +/- 66.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | 497      |
| time/              |          |
|    total_timesteps | 3169272  |
---------------------------------
Eval num_timesteps=3171264, episode_reward=278.43 +/- 385.01
Episode length: 557.40 +/- 138.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 278      |
| time/              |          |
|    total_timesteps | 3171264  |
---------------------------------
Eval num_timesteps=3173256, episode_reward=346.38 +/- 216.86
Episode length: 670.00 +/- 134.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 670      |
|    mean_reward     | 346      |
| time/              |          |
|    total_timesteps | 3173256  |
---------------------------------
Eval num_timesteps=3175248, episode_reward=42.31 +/- 299.21
Episode length: 685.20 +/- 182.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 685      |
|    mean_reward     | 42.3     |
| time/              |          |
|    total_timesteps | 3175248  |
---------------------------------
Eval num_timesteps=3177240, episode_reward=169.26 +/- 230.75
Episode length: 483.40 +/- 47.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 483      |
|    mean_reward     | 169      |
| time/              |          |
|    total_timesteps | 3177240  |
---------------------------------
Eval num_timesteps=3179232, episode_reward=208.51 +/- 221.13
Episode length: 550.20 +/- 158.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 209      |
| time/              |          |
|    total_timesteps | 3179232  |
---------------------------------
Eval num_timesteps=3181224, episode_reward=319.77 +/- 370.28
Episode length: 533.40 +/- 42.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 320      |
| time/              |          |
|    total_timesteps | 3181224  |
---------------------------------
Eval num_timesteps=3183216, episode_reward=224.64 +/- 224.20
Episode length: 461.40 +/- 22.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | 225      |
| time/              |          |
|    total_timesteps | 3183216  |
---------------------------------
Eval num_timesteps=3185208, episode_reward=133.96 +/- 107.30
Episode length: 464.20 +/- 25.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | 134      |
| time/              |          |
|    total_timesteps | 3185208  |
---------------------------------
Eval num_timesteps=3187200, episode_reward=160.17 +/- 167.30
Episode length: 508.80 +/- 25.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 160      |
| time/              |          |
|    total_timesteps | 3187200  |
---------------------------------
Eval num_timesteps=3189192, episode_reward=313.67 +/- 282.27
Episode length: 585.40 +/- 100.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 314      |
| time/              |          |
|    total_timesteps | 3189192  |
---------------------------------
Eval num_timesteps=3191184, episode_reward=163.05 +/- 156.56
Episode length: 490.40 +/- 48.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | 163      |
| time/              |          |
|    total_timesteps | 3191184  |
---------------------------------
Eval num_timesteps=3193176, episode_reward=158.80 +/- 177.08
Episode length: 486.00 +/- 27.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 159      |
| time/              |          |
|    total_timesteps | 3193176  |
---------------------------------
Eval num_timesteps=3195168, episode_reward=650.58 +/- 114.74
Episode length: 649.00 +/- 270.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 649         |
|    mean_reward          | 651         |
| time/                   |             |
|    total_timesteps      | 3195168     |
| train/                  |             |
|    approx_kl            | 0.010899892 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0264     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00233    |
|    std                  | 1.29        |
|    value_loss           | 0.0989      |
-----------------------------------------
Eval num_timesteps=3197160, episode_reward=309.56 +/- 238.15
Episode length: 479.80 +/- 9.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 480      |
|    mean_reward     | 310      |
| time/              |          |
|    total_timesteps | 3197160  |
---------------------------------
Eval num_timesteps=3199152, episode_reward=603.71 +/- 220.14
Episode length: 606.00 +/- 109.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 3199152  |
---------------------------------
Eval num_timesteps=3201144, episode_reward=575.88 +/- 62.58
Episode length: 589.00 +/- 142.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 3201144  |
---------------------------------
Eval num_timesteps=3203136, episode_reward=555.59 +/- 39.35
Episode length: 578.40 +/- 71.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 556      |
| time/              |          |
|    total_timesteps | 3203136  |
---------------------------------
Eval num_timesteps=3205128, episode_reward=542.39 +/- 122.24
Episode length: 536.60 +/- 87.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 542      |
| time/              |          |
|    total_timesteps | 3205128  |
---------------------------------
Eval num_timesteps=3207120, episode_reward=437.33 +/- 299.35
Episode length: 519.60 +/- 48.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 437      |
| time/              |          |
|    total_timesteps | 3207120  |
---------------------------------
Eval num_timesteps=3209112, episode_reward=578.46 +/- 62.60
Episode length: 502.40 +/- 55.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 578      |
| time/              |          |
|    total_timesteps | 3209112  |
---------------------------------
Eval num_timesteps=3211104, episode_reward=521.90 +/- 59.70
Episode length: 456.00 +/- 26.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | 522      |
| time/              |          |
|    total_timesteps | 3211104  |
---------------------------------
Eval num_timesteps=3213096, episode_reward=555.29 +/- 21.76
Episode length: 553.40 +/- 74.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 555      |
| time/              |          |
|    total_timesteps | 3213096  |
---------------------------------
Eval num_timesteps=3215088, episode_reward=624.50 +/- 44.50
Episode length: 505.20 +/- 69.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | 625      |
| time/              |          |
|    total_timesteps | 3215088  |
---------------------------------
Eval num_timesteps=3217080, episode_reward=548.27 +/- 37.31
Episode length: 507.80 +/- 50.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 548      |
| time/              |          |
|    total_timesteps | 3217080  |
---------------------------------
Eval num_timesteps=3219072, episode_reward=491.33 +/- 179.59
Episode length: 536.20 +/- 108.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 491      |
| time/              |          |
|    total_timesteps | 3219072  |
---------------------------------
Eval num_timesteps=3221064, episode_reward=579.74 +/- 65.66
Episode length: 503.20 +/- 42.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 3221064  |
---------------------------------
Eval num_timesteps=3223056, episode_reward=563.40 +/- 40.05
Episode length: 521.60 +/- 39.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 563      |
| time/              |          |
|    total_timesteps | 3223056  |
---------------------------------
Eval num_timesteps=3225048, episode_reward=601.02 +/- 40.49
Episode length: 501.20 +/- 43.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 3225048  |
---------------------------------
Eval num_timesteps=3227040, episode_reward=655.75 +/- 183.80
Episode length: 639.80 +/- 157.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 640      |
|    mean_reward     | 656      |
| time/              |          |
|    total_timesteps | 3227040  |
---------------------------------
Eval num_timesteps=3229032, episode_reward=435.73 +/- 202.89
Episode length: 533.40 +/- 65.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 436      |
| time/              |          |
|    total_timesteps | 3229032  |
---------------------------------
Eval num_timesteps=3231024, episode_reward=544.20 +/- 16.14
Episode length: 567.20 +/- 82.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 544      |
| time/              |          |
|    total_timesteps | 3231024  |
---------------------------------
Eval num_timesteps=3233016, episode_reward=612.33 +/- 51.00
Episode length: 548.20 +/- 64.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | 612      |
| time/              |          |
|    total_timesteps | 3233016  |
---------------------------------
Eval num_timesteps=3235008, episode_reward=680.44 +/- 93.30
Episode length: 627.80 +/- 99.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 680      |
| time/              |          |
|    total_timesteps | 3235008  |
---------------------------------
Eval num_timesteps=3237000, episode_reward=460.85 +/- 139.19
Episode length: 591.00 +/- 64.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 461      |
| time/              |          |
|    total_timesteps | 3237000  |
---------------------------------
Eval num_timesteps=3238992, episode_reward=543.74 +/- 110.07
Episode length: 702.20 +/- 269.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | 544      |
| time/              |          |
|    total_timesteps | 3238992  |
---------------------------------
Eval num_timesteps=3240984, episode_reward=544.27 +/- 31.29
Episode length: 527.40 +/- 82.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 544      |
| time/              |          |
|    total_timesteps | 3240984  |
---------------------------------
Eval num_timesteps=3242976, episode_reward=590.88 +/- 54.66
Episode length: 612.80 +/- 84.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 591      |
| time/              |          |
|    total_timesteps | 3242976  |
---------------------------------
Eval num_timesteps=3244968, episode_reward=518.04 +/- 122.18
Episode length: 501.20 +/- 27.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 501         |
|    mean_reward          | 518         |
| time/                   |             |
|    total_timesteps      | 3244968     |
| train/                  |             |
|    approx_kl            | 0.005163293 |
|    clip_fraction        | 0.0313      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0512      |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.000877   |
|    std                  | 1.3         |
|    value_loss           | 0.264       |
-----------------------------------------
Eval num_timesteps=3246960, episode_reward=519.08 +/- 123.69
Episode length: 532.20 +/- 85.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 519      |
| time/              |          |
|    total_timesteps | 3246960  |
---------------------------------
Eval num_timesteps=3248952, episode_reward=522.62 +/- 85.91
Episode length: 536.00 +/- 97.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 523      |
| time/              |          |
|    total_timesteps | 3248952  |
---------------------------------
Eval num_timesteps=3250944, episode_reward=590.65 +/- 88.37
Episode length: 489.00 +/- 35.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 591      |
| time/              |          |
|    total_timesteps | 3250944  |
---------------------------------
Eval num_timesteps=3252936, episode_reward=554.09 +/- 61.96
Episode length: 631.60 +/- 127.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 632      |
|    mean_reward     | 554      |
| time/              |          |
|    total_timesteps | 3252936  |
---------------------------------
Eval num_timesteps=3254928, episode_reward=481.24 +/- 127.34
Episode length: 514.80 +/- 52.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 481      |
| time/              |          |
|    total_timesteps | 3254928  |
---------------------------------
Eval num_timesteps=3256920, episode_reward=509.76 +/- 138.95
Episode length: 523.00 +/- 48.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 510      |
| time/              |          |
|    total_timesteps | 3256920  |
---------------------------------
Eval num_timesteps=3258912, episode_reward=630.88 +/- 158.83
Episode length: 531.80 +/- 82.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 631      |
| time/              |          |
|    total_timesteps | 3258912  |
---------------------------------
Eval num_timesteps=3260904, episode_reward=552.41 +/- 22.32
Episode length: 533.00 +/- 71.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 552      |
| time/              |          |
|    total_timesteps | 3260904  |
---------------------------------
Eval num_timesteps=3262896, episode_reward=485.08 +/- 106.78
Episode length: 489.80 +/- 58.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | 485      |
| time/              |          |
|    total_timesteps | 3262896  |
---------------------------------
Eval num_timesteps=3264888, episode_reward=532.94 +/- 76.17
Episode length: 507.20 +/- 62.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 533      |
| time/              |          |
|    total_timesteps | 3264888  |
---------------------------------
Eval num_timesteps=3266880, episode_reward=578.24 +/- 38.78
Episode length: 495.60 +/- 69.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | 578      |
| time/              |          |
|    total_timesteps | 3266880  |
---------------------------------
Eval num_timesteps=3268872, episode_reward=423.38 +/- 147.49
Episode length: 510.20 +/- 54.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 423      |
| time/              |          |
|    total_timesteps | 3268872  |
---------------------------------
Eval num_timesteps=3270864, episode_reward=473.76 +/- 213.90
Episode length: 472.20 +/- 21.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | 474      |
| time/              |          |
|    total_timesteps | 3270864  |
---------------------------------
Eval num_timesteps=3272856, episode_reward=544.67 +/- 40.41
Episode length: 554.00 +/- 39.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 545      |
| time/              |          |
|    total_timesteps | 3272856  |
---------------------------------
Eval num_timesteps=3274848, episode_reward=550.01 +/- 122.34
Episode length: 504.00 +/- 53.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 550      |
| time/              |          |
|    total_timesteps | 3274848  |
---------------------------------
Eval num_timesteps=3276840, episode_reward=611.30 +/- 62.50
Episode length: 547.00 +/- 106.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 3276840  |
---------------------------------
Eval num_timesteps=3278832, episode_reward=485.31 +/- 127.65
Episode length: 512.60 +/- 68.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 485      |
| time/              |          |
|    total_timesteps | 3278832  |
---------------------------------
Eval num_timesteps=3280824, episode_reward=366.12 +/- 227.35
Episode length: 515.40 +/- 99.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 366      |
| time/              |          |
|    total_timesteps | 3280824  |
---------------------------------
Eval num_timesteps=3282816, episode_reward=580.63 +/- 62.72
Episode length: 583.20 +/- 62.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 581      |
| time/              |          |
|    total_timesteps | 3282816  |
---------------------------------
Eval num_timesteps=3284808, episode_reward=574.34 +/- 181.03
Episode length: 524.40 +/- 71.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | 574      |
| time/              |          |
|    total_timesteps | 3284808  |
---------------------------------
Eval num_timesteps=3286800, episode_reward=542.48 +/- 270.71
Episode length: 627.80 +/- 149.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 542      |
| time/              |          |
|    total_timesteps | 3286800  |
---------------------------------
Eval num_timesteps=3288792, episode_reward=530.73 +/- 24.08
Episode length: 487.00 +/- 43.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | 531      |
| time/              |          |
|    total_timesteps | 3288792  |
---------------------------------
Eval num_timesteps=3290784, episode_reward=438.71 +/- 132.58
Episode length: 526.80 +/- 67.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 439      |
| time/              |          |
|    total_timesteps | 3290784  |
---------------------------------
Eval num_timesteps=3292776, episode_reward=540.21 +/- 48.05
Episode length: 487.60 +/- 38.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | 540      |
| time/              |          |
|    total_timesteps | 3292776  |
---------------------------------
Eval num_timesteps=3294768, episode_reward=473.52 +/- 126.33
Episode length: 583.20 +/- 80.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 583         |
|    mean_reward          | 474         |
| time/                   |             |
|    total_timesteps      | 3294768     |
| train/                  |             |
|    approx_kl            | 0.004373024 |
|    clip_fraction        | 0.0232      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.72       |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0542      |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00147    |
|    std                  | 1.3         |
|    value_loss           | 0.282       |
-----------------------------------------
Eval num_timesteps=3296760, episode_reward=550.11 +/- 39.45
Episode length: 509.40 +/- 54.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 550      |
| time/              |          |
|    total_timesteps | 3296760  |
---------------------------------
Eval num_timesteps=3298752, episode_reward=436.22 +/- 129.40
Episode length: 510.40 +/- 48.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 436      |
| time/              |          |
|    total_timesteps | 3298752  |
---------------------------------
Eval num_timesteps=3300744, episode_reward=524.15 +/- 307.87
Episode length: 515.40 +/- 55.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 524      |
| time/              |          |
|    total_timesteps | 3300744  |
---------------------------------
Eval num_timesteps=3302736, episode_reward=531.72 +/- 165.54
Episode length: 490.40 +/- 72.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 490      |
|    mean_reward     | 532      |
| time/              |          |
|    total_timesteps | 3302736  |
---------------------------------
Eval num_timesteps=3304728, episode_reward=576.21 +/- 46.75
Episode length: 476.60 +/- 38.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 3304728  |
---------------------------------
Eval num_timesteps=3306720, episode_reward=408.98 +/- 105.76
Episode length: 514.40 +/- 51.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 409      |
| time/              |          |
|    total_timesteps | 3306720  |
---------------------------------
Eval num_timesteps=3308712, episode_reward=420.69 +/- 272.33
Episode length: 551.60 +/- 105.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 421      |
| time/              |          |
|    total_timesteps | 3308712  |
---------------------------------
Eval num_timesteps=3310704, episode_reward=480.13 +/- 165.79
Episode length: 472.00 +/- 41.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 472      |
|    mean_reward     | 480      |
| time/              |          |
|    total_timesteps | 3310704  |
---------------------------------
Eval num_timesteps=3312696, episode_reward=535.63 +/- 127.39
Episode length: 556.60 +/- 51.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 536      |
| time/              |          |
|    total_timesteps | 3312696  |
---------------------------------
Eval num_timesteps=3314688, episode_reward=458.12 +/- 86.49
Episode length: 522.40 +/- 72.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 458      |
| time/              |          |
|    total_timesteps | 3314688  |
---------------------------------
Eval num_timesteps=3316680, episode_reward=601.34 +/- 65.74
Episode length: 549.80 +/- 54.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 3316680  |
---------------------------------
Eval num_timesteps=3318672, episode_reward=591.89 +/- 152.24
Episode length: 465.80 +/- 30.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 592      |
| time/              |          |
|    total_timesteps | 3318672  |
---------------------------------
Eval num_timesteps=3320664, episode_reward=363.03 +/- 126.28
Episode length: 567.00 +/- 76.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 3320664  |
---------------------------------
Eval num_timesteps=3322656, episode_reward=264.16 +/- 184.87
Episode length: 500.40 +/- 55.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 264      |
| time/              |          |
|    total_timesteps | 3322656  |
---------------------------------
Eval num_timesteps=3324648, episode_reward=611.25 +/- 117.48
Episode length: 648.40 +/- 159.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 648      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 3324648  |
---------------------------------
Eval num_timesteps=3326640, episode_reward=570.38 +/- 25.15
Episode length: 501.60 +/- 59.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 3326640  |
---------------------------------
Eval num_timesteps=3328632, episode_reward=434.21 +/- 179.02
Episode length: 518.60 +/- 40.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 434      |
| time/              |          |
|    total_timesteps | 3328632  |
---------------------------------
Eval num_timesteps=3330624, episode_reward=486.62 +/- 124.21
Episode length: 557.40 +/- 69.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 487      |
| time/              |          |
|    total_timesteps | 3330624  |
---------------------------------
Eval num_timesteps=3332616, episode_reward=548.33 +/- 54.50
Episode length: 506.00 +/- 57.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 548      |
| time/              |          |
|    total_timesteps | 3332616  |
---------------------------------
Eval num_timesteps=3334608, episode_reward=570.33 +/- 25.63
Episode length: 471.20 +/- 51.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 3334608  |
---------------------------------
Eval num_timesteps=3336600, episode_reward=557.02 +/- 45.85
Episode length: 615.20 +/- 92.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 557      |
| time/              |          |
|    total_timesteps | 3336600  |
---------------------------------
Eval num_timesteps=3338592, episode_reward=450.70 +/- 203.15
Episode length: 473.20 +/- 43.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | 451      |
| time/              |          |
|    total_timesteps | 3338592  |
---------------------------------
Eval num_timesteps=3340584, episode_reward=359.40 +/- 159.24
Episode length: 492.00 +/- 36.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | 359      |
| time/              |          |
|    total_timesteps | 3340584  |
---------------------------------
Eval num_timesteps=3342576, episode_reward=505.35 +/- 142.21
Episode length: 508.60 +/- 57.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 509         |
|    mean_reward          | 505         |
| time/                   |             |
|    total_timesteps      | 3342576     |
| train/                  |             |
|    approx_kl            | 0.005945736 |
|    clip_fraction        | 0.0323      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.74       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0569      |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.000598   |
|    std                  | 1.31        |
|    value_loss           | 0.27        |
-----------------------------------------
Eval num_timesteps=3344568, episode_reward=392.99 +/- 233.90
Episode length: 502.20 +/- 68.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 393      |
| time/              |          |
|    total_timesteps | 3344568  |
---------------------------------
Eval num_timesteps=3346560, episode_reward=508.93 +/- 154.50
Episode length: 504.40 +/- 68.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 509      |
| time/              |          |
|    total_timesteps | 3346560  |
---------------------------------
Eval num_timesteps=3348552, episode_reward=607.74 +/- 102.82
Episode length: 497.60 +/- 64.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | 608      |
| time/              |          |
|    total_timesteps | 3348552  |
---------------------------------
Eval num_timesteps=3350544, episode_reward=748.15 +/- 353.92
Episode length: 595.40 +/- 41.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 748      |
| time/              |          |
|    total_timesteps | 3350544  |
---------------------------------
Eval num_timesteps=3352536, episode_reward=536.69 +/- 26.95
Episode length: 490.80 +/- 34.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 537      |
| time/              |          |
|    total_timesteps | 3352536  |
---------------------------------
Eval num_timesteps=3354528, episode_reward=475.69 +/- 228.20
Episode length: 475.20 +/- 58.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | 476      |
| time/              |          |
|    total_timesteps | 3354528  |
---------------------------------
Eval num_timesteps=3356520, episode_reward=593.27 +/- 64.14
Episode length: 506.60 +/- 48.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 3356520  |
---------------------------------
Eval num_timesteps=3358512, episode_reward=427.36 +/- 175.35
Episode length: 521.00 +/- 61.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | 427      |
| time/              |          |
|    total_timesteps | 3358512  |
---------------------------------
Eval num_timesteps=3360504, episode_reward=499.01 +/- 127.21
Episode length: 440.60 +/- 16.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 441      |
|    mean_reward     | 499      |
| time/              |          |
|    total_timesteps | 3360504  |
---------------------------------
Eval num_timesteps=3362496, episode_reward=618.67 +/- 93.51
Episode length: 591.20 +/- 55.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 619      |
| time/              |          |
|    total_timesteps | 3362496  |
---------------------------------
Eval num_timesteps=3364488, episode_reward=476.20 +/- 223.49
Episode length: 508.20 +/- 82.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 476      |
| time/              |          |
|    total_timesteps | 3364488  |
---------------------------------
Eval num_timesteps=3366480, episode_reward=472.61 +/- 148.31
Episode length: 600.80 +/- 48.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 601      |
|    mean_reward     | 473      |
| time/              |          |
|    total_timesteps | 3366480  |
---------------------------------
Eval num_timesteps=3368472, episode_reward=364.09 +/- 248.98
Episode length: 507.80 +/- 85.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 3368472  |
---------------------------------
Eval num_timesteps=3370464, episode_reward=316.02 +/- 172.92
Episode length: 536.40 +/- 69.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 316      |
| time/              |          |
|    total_timesteps | 3370464  |
---------------------------------
Eval num_timesteps=3372456, episode_reward=588.36 +/- 67.82
Episode length: 501.40 +/- 68.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 588      |
| time/              |          |
|    total_timesteps | 3372456  |
---------------------------------
Eval num_timesteps=3374448, episode_reward=580.06 +/- 40.47
Episode length: 507.00 +/- 58.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 3374448  |
---------------------------------
Eval num_timesteps=3376440, episode_reward=643.55 +/- 370.94
Episode length: 522.80 +/- 122.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 644      |
| time/              |          |
|    total_timesteps | 3376440  |
---------------------------------
Eval num_timesteps=3378432, episode_reward=354.54 +/- 205.64
Episode length: 518.60 +/- 46.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 355      |
| time/              |          |
|    total_timesteps | 3378432  |
---------------------------------
Eval num_timesteps=3380424, episode_reward=450.26 +/- 146.90
Episode length: 477.20 +/- 26.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 450      |
| time/              |          |
|    total_timesteps | 3380424  |
---------------------------------
Eval num_timesteps=3382416, episode_reward=575.95 +/- 42.98
Episode length: 550.60 +/- 51.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 3382416  |
---------------------------------
Eval num_timesteps=3384408, episode_reward=302.65 +/- 285.43
Episode length: 590.80 +/- 130.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 303      |
| time/              |          |
|    total_timesteps | 3384408  |
---------------------------------
Eval num_timesteps=3386400, episode_reward=546.58 +/- 88.42
Episode length: 588.80 +/- 155.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 547      |
| time/              |          |
|    total_timesteps | 3386400  |
---------------------------------
Eval num_timesteps=3388392, episode_reward=817.87 +/- 530.57
Episode length: 554.20 +/- 137.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 818      |
| time/              |          |
|    total_timesteps | 3388392  |
---------------------------------
Eval num_timesteps=3390384, episode_reward=428.55 +/- 252.41
Episode length: 510.60 +/- 47.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 429      |
| time/              |          |
|    total_timesteps | 3390384  |
---------------------------------
Eval num_timesteps=3392376, episode_reward=329.48 +/- 262.20
Episode length: 523.20 +/- 66.75
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 523          |
|    mean_reward          | 329          |
| time/                   |              |
|    total_timesteps      | 3392376      |
| train/                  |              |
|    approx_kl            | 0.0037754136 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.77        |
|    explained_variance   | 0.964        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0286       |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.000755    |
|    std                  | 1.32         |
|    value_loss           | 0.204        |
------------------------------------------
Eval num_timesteps=3394368, episode_reward=541.50 +/- 105.60
Episode length: 475.60 +/- 55.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 476      |
|    mean_reward     | 542      |
| time/              |          |
|    total_timesteps | 3394368  |
---------------------------------
Eval num_timesteps=3396360, episode_reward=620.68 +/- 187.91
Episode length: 571.00 +/- 57.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 3396360  |
---------------------------------
Eval num_timesteps=3398352, episode_reward=573.68 +/- 238.16
Episode length: 533.80 +/- 70.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 574      |
| time/              |          |
|    total_timesteps | 3398352  |
---------------------------------
Eval num_timesteps=3400344, episode_reward=546.54 +/- 100.51
Episode length: 535.40 +/- 72.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 547      |
| time/              |          |
|    total_timesteps | 3400344  |
---------------------------------
Eval num_timesteps=3402336, episode_reward=360.20 +/- 208.74
Episode length: 528.60 +/- 54.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 360      |
| time/              |          |
|    total_timesteps | 3402336  |
---------------------------------
Eval num_timesteps=3404328, episode_reward=465.40 +/- 228.75
Episode length: 584.20 +/- 68.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 465      |
| time/              |          |
|    total_timesteps | 3404328  |
---------------------------------
Eval num_timesteps=3406320, episode_reward=546.12 +/- 288.25
Episode length: 477.00 +/- 55.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 3406320  |
---------------------------------
Eval num_timesteps=3408312, episode_reward=774.55 +/- 448.94
Episode length: 508.60 +/- 49.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 775      |
| time/              |          |
|    total_timesteps | 3408312  |
---------------------------------
Eval num_timesteps=3410304, episode_reward=533.06 +/- 29.16
Episode length: 514.60 +/- 80.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 533      |
| time/              |          |
|    total_timesteps | 3410304  |
---------------------------------
Eval num_timesteps=3412296, episode_reward=474.92 +/- 364.74
Episode length: 585.80 +/- 80.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 586      |
|    mean_reward     | 475      |
| time/              |          |
|    total_timesteps | 3412296  |
---------------------------------
Eval num_timesteps=3414288, episode_reward=776.09 +/- 232.32
Episode length: 618.80 +/- 57.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 776      |
| time/              |          |
|    total_timesteps | 3414288  |
---------------------------------
Eval num_timesteps=3416280, episode_reward=559.86 +/- 134.55
Episode length: 593.40 +/- 72.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 593      |
|    mean_reward     | 560      |
| time/              |          |
|    total_timesteps | 3416280  |
---------------------------------
Eval num_timesteps=3418272, episode_reward=442.75 +/- 171.32
Episode length: 533.20 +/- 67.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 443      |
| time/              |          |
|    total_timesteps | 3418272  |
---------------------------------
Eval num_timesteps=3420264, episode_reward=418.91 +/- 140.61
Episode length: 489.00 +/- 63.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 419      |
| time/              |          |
|    total_timesteps | 3420264  |
---------------------------------
Eval num_timesteps=3422256, episode_reward=577.91 +/- 166.96
Episode length: 632.00 +/- 85.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 632      |
|    mean_reward     | 578      |
| time/              |          |
|    total_timesteps | 3422256  |
---------------------------------
Eval num_timesteps=3424248, episode_reward=363.20 +/- 185.72
Episode length: 479.00 +/- 56.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 3424248  |
---------------------------------
Eval num_timesteps=3426240, episode_reward=618.18 +/- 86.58
Episode length: 682.00 +/- 257.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 682      |
|    mean_reward     | 618      |
| time/              |          |
|    total_timesteps | 3426240  |
---------------------------------
Eval num_timesteps=3428232, episode_reward=453.30 +/- 205.62
Episode length: 521.60 +/- 55.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3428232  |
---------------------------------
Eval num_timesteps=3430224, episode_reward=636.42 +/- 282.93
Episode length: 578.20 +/- 72.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 3430224  |
---------------------------------
Eval num_timesteps=3432216, episode_reward=570.19 +/- 146.23
Episode length: 509.40 +/- 34.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 3432216  |
---------------------------------
Eval num_timesteps=3434208, episode_reward=512.69 +/- 177.07
Episode length: 517.00 +/- 91.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 517      |
|    mean_reward     | 513      |
| time/              |          |
|    total_timesteps | 3434208  |
---------------------------------
Eval num_timesteps=3436200, episode_reward=558.73 +/- 102.08
Episode length: 546.20 +/- 89.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 559      |
| time/              |          |
|    total_timesteps | 3436200  |
---------------------------------
Eval num_timesteps=3438192, episode_reward=535.94 +/- 146.47
Episode length: 493.60 +/- 65.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 536      |
| time/              |          |
|    total_timesteps | 3438192  |
---------------------------------
Eval num_timesteps=3440184, episode_reward=447.97 +/- 163.85
Episode length: 549.00 +/- 40.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 448      |
| time/              |          |
|    total_timesteps | 3440184  |
---------------------------------
Eval num_timesteps=3442176, episode_reward=550.38 +/- 66.73
Episode length: 469.60 +/- 34.64
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 470          |
|    mean_reward          | 550          |
| time/                   |              |
|    total_timesteps      | 3442176      |
| train/                  |              |
|    approx_kl            | 0.0032990228 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.8         |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.001        |
|    loss                 | 0.0154       |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.000848    |
|    std                  | 1.33         |
|    value_loss           | 0.181        |
------------------------------------------
Eval num_timesteps=3444168, episode_reward=419.08 +/- 250.32
Episode length: 547.20 +/- 55.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 419      |
| time/              |          |
|    total_timesteps | 3444168  |
---------------------------------
Eval num_timesteps=3446160, episode_reward=452.73 +/- 124.66
Episode length: 567.00 +/- 47.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3446160  |
---------------------------------
Eval num_timesteps=3448152, episode_reward=497.04 +/- 196.20
Episode length: 602.40 +/- 50.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 497      |
| time/              |          |
|    total_timesteps | 3448152  |
---------------------------------
Eval num_timesteps=3450144, episode_reward=552.23 +/- 133.24
Episode length: 551.00 +/- 25.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | 552      |
| time/              |          |
|    total_timesteps | 3450144  |
---------------------------------
Eval num_timesteps=3452136, episode_reward=494.00 +/- 294.49
Episode length: 620.20 +/- 75.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | 494      |
| time/              |          |
|    total_timesteps | 3452136  |
---------------------------------
Eval num_timesteps=3454128, episode_reward=516.21 +/- 44.11
Episode length: 575.40 +/- 42.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 575      |
|    mean_reward     | 516      |
| time/              |          |
|    total_timesteps | 3454128  |
---------------------------------
Eval num_timesteps=3456120, episode_reward=780.03 +/- 344.26
Episode length: 624.60 +/- 92.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 780      |
| time/              |          |
|    total_timesteps | 3456120  |
---------------------------------
Eval num_timesteps=3458112, episode_reward=526.71 +/- 277.60
Episode length: 609.20 +/- 74.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 527      |
| time/              |          |
|    total_timesteps | 3458112  |
---------------------------------
Eval num_timesteps=3460104, episode_reward=313.53 +/- 228.06
Episode length: 552.00 +/- 33.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 314      |
| time/              |          |
|    total_timesteps | 3460104  |
---------------------------------
Eval num_timesteps=3462096, episode_reward=523.15 +/- 71.87
Episode length: 622.00 +/- 66.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 622      |
|    mean_reward     | 523      |
| time/              |          |
|    total_timesteps | 3462096  |
---------------------------------
Eval num_timesteps=3464088, episode_reward=358.42 +/- 172.19
Episode length: 555.00 +/- 73.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 358      |
| time/              |          |
|    total_timesteps | 3464088  |
---------------------------------
Eval num_timesteps=3466080, episode_reward=473.23 +/- 171.78
Episode length: 527.60 +/- 59.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 473      |
| time/              |          |
|    total_timesteps | 3466080  |
---------------------------------
Eval num_timesteps=3468072, episode_reward=205.13 +/- 174.31
Episode length: 524.60 +/- 64.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 205      |
| time/              |          |
|    total_timesteps | 3468072  |
---------------------------------
Eval num_timesteps=3470064, episode_reward=518.74 +/- 148.97
Episode length: 537.40 +/- 41.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 519      |
| time/              |          |
|    total_timesteps | 3470064  |
---------------------------------
Eval num_timesteps=3472056, episode_reward=638.61 +/- 106.29
Episode length: 509.60 +/- 44.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 639      |
| time/              |          |
|    total_timesteps | 3472056  |
---------------------------------
Eval num_timesteps=3474048, episode_reward=386.63 +/- 210.49
Episode length: 528.40 +/- 49.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 387      |
| time/              |          |
|    total_timesteps | 3474048  |
---------------------------------
Eval num_timesteps=3476040, episode_reward=532.13 +/- 143.77
Episode length: 560.40 +/- 64.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | 532      |
| time/              |          |
|    total_timesteps | 3476040  |
---------------------------------
Eval num_timesteps=3478032, episode_reward=453.42 +/- 188.82
Episode length: 610.80 +/- 80.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3478032  |
---------------------------------
Eval num_timesteps=3480024, episode_reward=507.42 +/- 183.06
Episode length: 602.40 +/- 31.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 507      |
| time/              |          |
|    total_timesteps | 3480024  |
---------------------------------
Eval num_timesteps=3482016, episode_reward=435.81 +/- 205.29
Episode length: 516.80 +/- 46.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 517      |
|    mean_reward     | 436      |
| time/              |          |
|    total_timesteps | 3482016  |
---------------------------------
Eval num_timesteps=3484008, episode_reward=290.07 +/- 234.57
Episode length: 527.80 +/- 52.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 290      |
| time/              |          |
|    total_timesteps | 3484008  |
---------------------------------
Eval num_timesteps=3486000, episode_reward=657.31 +/- 228.92
Episode length: 566.80 +/- 58.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 657      |
| time/              |          |
|    total_timesteps | 3486000  |
---------------------------------
Eval num_timesteps=3487992, episode_reward=546.22 +/- 41.51
Episode length: 550.60 +/- 54.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 3487992  |
---------------------------------
Eval num_timesteps=3489984, episode_reward=269.97 +/- 241.33
Episode length: 528.60 +/- 50.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 529         |
|    mean_reward          | 270         |
| time/                   |             |
|    total_timesteps      | 3489984     |
| train/                  |             |
|    approx_kl            | 0.004919256 |
|    clip_fraction        | 0.0356      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.001       |
|    loss                 | 0.00192     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00147    |
|    std                  | 1.34        |
|    value_loss           | 0.157       |
-----------------------------------------
Eval num_timesteps=3491976, episode_reward=284.49 +/- 128.16
Episode length: 511.20 +/- 54.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 284      |
| time/              |          |
|    total_timesteps | 3491976  |
---------------------------------
Eval num_timesteps=3493968, episode_reward=348.16 +/- 260.91
Episode length: 529.80 +/- 108.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 348      |
| time/              |          |
|    total_timesteps | 3493968  |
---------------------------------
Eval num_timesteps=3495960, episode_reward=241.19 +/- 158.93
Episode length: 504.80 +/- 14.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | 241      |
| time/              |          |
|    total_timesteps | 3495960  |
---------------------------------
Eval num_timesteps=3497952, episode_reward=493.69 +/- 199.14
Episode length: 543.80 +/- 55.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 494      |
| time/              |          |
|    total_timesteps | 3497952  |
---------------------------------
Eval num_timesteps=3499944, episode_reward=334.19 +/- 234.40
Episode length: 518.00 +/- 62.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 518      |
|    mean_reward     | 334      |
| time/              |          |
|    total_timesteps | 3499944  |
---------------------------------
Eval num_timesteps=3501936, episode_reward=351.16 +/- 227.56
Episode length: 576.00 +/- 147.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 351      |
| time/              |          |
|    total_timesteps | 3501936  |
---------------------------------
Eval num_timesteps=3503928, episode_reward=362.42 +/- 104.38
Episode length: 535.00 +/- 66.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 362      |
| time/              |          |
|    total_timesteps | 3503928  |
---------------------------------
Eval num_timesteps=3505920, episode_reward=320.01 +/- 286.03
Episode length: 530.40 +/- 13.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 320      |
| time/              |          |
|    total_timesteps | 3505920  |
---------------------------------
Eval num_timesteps=3507912, episode_reward=478.20 +/- 103.96
Episode length: 521.60 +/- 49.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 478      |
| time/              |          |
|    total_timesteps | 3507912  |
---------------------------------
Eval num_timesteps=3509904, episode_reward=403.01 +/- 236.75
Episode length: 557.20 +/- 81.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 403      |
| time/              |          |
|    total_timesteps | 3509904  |
---------------------------------
Eval num_timesteps=3511896, episode_reward=289.59 +/- 171.97
Episode length: 500.20 +/- 41.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 290      |
| time/              |          |
|    total_timesteps | 3511896  |
---------------------------------
Eval num_timesteps=3513888, episode_reward=439.65 +/- 205.95
Episode length: 540.80 +/- 33.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 440      |
| time/              |          |
|    total_timesteps | 3513888  |
---------------------------------
Eval num_timesteps=3515880, episode_reward=453.43 +/- 177.04
Episode length: 501.80 +/- 39.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3515880  |
---------------------------------
Eval num_timesteps=3517872, episode_reward=235.37 +/- 269.30
Episode length: 509.20 +/- 66.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 235      |
| time/              |          |
|    total_timesteps | 3517872  |
---------------------------------
Eval num_timesteps=3519864, episode_reward=541.38 +/- 193.56
Episode length: 495.60 +/- 44.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | 541      |
| time/              |          |
|    total_timesteps | 3519864  |
---------------------------------
Eval num_timesteps=3521856, episode_reward=283.67 +/- 203.95
Episode length: 494.00 +/- 23.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 284      |
| time/              |          |
|    total_timesteps | 3521856  |
---------------------------------
Eval num_timesteps=3523848, episode_reward=396.57 +/- 139.09
Episode length: 529.20 +/- 68.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 397      |
| time/              |          |
|    total_timesteps | 3523848  |
---------------------------------
Eval num_timesteps=3525840, episode_reward=420.26 +/- 275.08
Episode length: 533.20 +/- 66.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 420      |
| time/              |          |
|    total_timesteps | 3525840  |
---------------------------------
Eval num_timesteps=3527832, episode_reward=422.16 +/- 185.64
Episode length: 525.00 +/- 35.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 422      |
| time/              |          |
|    total_timesteps | 3527832  |
---------------------------------
Eval num_timesteps=3529824, episode_reward=373.16 +/- 159.44
Episode length: 530.80 +/- 51.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 373      |
| time/              |          |
|    total_timesteps | 3529824  |
---------------------------------
Eval num_timesteps=3531816, episode_reward=481.07 +/- 168.66
Episode length: 534.40 +/- 39.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 481      |
| time/              |          |
|    total_timesteps | 3531816  |
---------------------------------
Eval num_timesteps=3533808, episode_reward=494.78 +/- 226.86
Episode length: 527.60 +/- 55.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 495      |
| time/              |          |
|    total_timesteps | 3533808  |
---------------------------------
Eval num_timesteps=3535800, episode_reward=412.87 +/- 273.77
Episode length: 543.20 +/- 71.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | 413      |
| time/              |          |
|    total_timesteps | 3535800  |
---------------------------------
Eval num_timesteps=3537792, episode_reward=384.00 +/- 232.48
Episode length: 536.40 +/- 110.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 384      |
| time/              |          |
|    total_timesteps | 3537792  |
---------------------------------
Eval num_timesteps=3539784, episode_reward=686.44 +/- 191.41
Episode length: 583.60 +/- 60.45
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 584          |
|    mean_reward          | 686          |
| time/                   |              |
|    total_timesteps      | 3539784      |
| train/                  |              |
|    approx_kl            | 0.0049115224 |
|    clip_fraction        | 0.033        |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.85        |
|    explained_variance   | 0.976        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0277      |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.000971    |
|    std                  | 1.35         |
|    value_loss           | 0.095        |
------------------------------------------
Eval num_timesteps=3541776, episode_reward=256.97 +/- 218.81
Episode length: 530.20 +/- 40.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 257      |
| time/              |          |
|    total_timesteps | 3541776  |
---------------------------------
Eval num_timesteps=3543768, episode_reward=309.96 +/- 375.64
Episode length: 541.00 +/- 78.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 310      |
| time/              |          |
|    total_timesteps | 3543768  |
---------------------------------
Eval num_timesteps=3545760, episode_reward=426.25 +/- 144.01
Episode length: 579.80 +/- 24.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 580      |
|    mean_reward     | 426      |
| time/              |          |
|    total_timesteps | 3545760  |
---------------------------------
Eval num_timesteps=3547752, episode_reward=550.39 +/- 402.04
Episode length: 628.60 +/- 92.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | 550      |
| time/              |          |
|    total_timesteps | 3547752  |
---------------------------------
Eval num_timesteps=3549744, episode_reward=204.02 +/- 97.64
Episode length: 535.00 +/- 39.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 204      |
| time/              |          |
|    total_timesteps | 3549744  |
---------------------------------
Eval num_timesteps=3551736, episode_reward=780.75 +/- 772.94
Episode length: 588.80 +/- 82.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 781      |
| time/              |          |
|    total_timesteps | 3551736  |
---------------------------------
Eval num_timesteps=3553728, episode_reward=252.43 +/- 192.41
Episode length: 575.80 +/- 77.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 252      |
| time/              |          |
|    total_timesteps | 3553728  |
---------------------------------
Eval num_timesteps=3555720, episode_reward=489.10 +/- 331.21
Episode length: 579.00 +/- 88.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 579      |
|    mean_reward     | 489      |
| time/              |          |
|    total_timesteps | 3555720  |
---------------------------------
Eval num_timesteps=3557712, episode_reward=326.85 +/- 165.36
Episode length: 533.60 +/- 48.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 327      |
| time/              |          |
|    total_timesteps | 3557712  |
---------------------------------
Eval num_timesteps=3559704, episode_reward=398.05 +/- 229.41
Episode length: 586.60 +/- 100.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 398      |
| time/              |          |
|    total_timesteps | 3559704  |
---------------------------------
Eval num_timesteps=3561696, episode_reward=346.41 +/- 242.18
Episode length: 568.60 +/- 84.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 346      |
| time/              |          |
|    total_timesteps | 3561696  |
---------------------------------
Eval num_timesteps=3563688, episode_reward=546.38 +/- 448.35
Episode length: 585.20 +/- 52.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 3563688  |
---------------------------------
Eval num_timesteps=3565680, episode_reward=622.17 +/- 729.96
Episode length: 630.40 +/- 174.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 3565680  |
---------------------------------
Eval num_timesteps=3567672, episode_reward=294.02 +/- 275.34
Episode length: 530.80 +/- 14.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 294      |
| time/              |          |
|    total_timesteps | 3567672  |
---------------------------------
Eval num_timesteps=3569664, episode_reward=558.46 +/- 399.95
Episode length: 578.20 +/- 74.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 558      |
| time/              |          |
|    total_timesteps | 3569664  |
---------------------------------
Eval num_timesteps=3571656, episode_reward=412.80 +/- 239.11
Episode length: 543.20 +/- 80.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | 413      |
| time/              |          |
|    total_timesteps | 3571656  |
---------------------------------
Eval num_timesteps=3573648, episode_reward=326.01 +/- 167.58
Episode length: 529.00 +/- 44.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 326      |
| time/              |          |
|    total_timesteps | 3573648  |
---------------------------------
Eval num_timesteps=3575640, episode_reward=398.88 +/- 201.02
Episode length: 533.20 +/- 66.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 399      |
| time/              |          |
|    total_timesteps | 3575640  |
---------------------------------
Eval num_timesteps=3577632, episode_reward=457.98 +/- 216.48
Episode length: 502.20 +/- 48.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 458      |
| time/              |          |
|    total_timesteps | 3577632  |
---------------------------------
Eval num_timesteps=3579624, episode_reward=461.89 +/- 271.48
Episode length: 514.60 +/- 50.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 462      |
| time/              |          |
|    total_timesteps | 3579624  |
---------------------------------
Eval num_timesteps=3581616, episode_reward=442.31 +/- 284.95
Episode length: 540.20 +/- 76.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | 442      |
| time/              |          |
|    total_timesteps | 3581616  |
---------------------------------
Eval num_timesteps=3583608, episode_reward=666.33 +/- 408.91
Episode length: 608.20 +/- 56.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | 666      |
| time/              |          |
|    total_timesteps | 3583608  |
---------------------------------
Eval num_timesteps=3585600, episode_reward=364.33 +/- 259.35
Episode length: 546.60 +/- 40.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 3585600  |
---------------------------------
Eval num_timesteps=3587592, episode_reward=447.07 +/- 190.88
Episode length: 555.00 +/- 52.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 447      |
| time/              |          |
|    total_timesteps | 3587592  |
---------------------------------
Eval num_timesteps=3589584, episode_reward=448.98 +/- 189.20
Episode length: 627.00 +/- 84.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 627         |
|    mean_reward          | 449         |
| time/                   |             |
|    total_timesteps      | 3589584     |
| train/                  |             |
|    approx_kl            | 0.004886808 |
|    clip_fraction        | 0.0332      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0349     |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00129    |
|    std                  | 1.35        |
|    value_loss           | 0.0824      |
-----------------------------------------
Eval num_timesteps=3591576, episode_reward=404.84 +/- 284.21
Episode length: 530.40 +/- 49.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 405      |
| time/              |          |
|    total_timesteps | 3591576  |
---------------------------------
Eval num_timesteps=3593568, episode_reward=311.12 +/- 202.61
Episode length: 624.40 +/- 78.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 624      |
|    mean_reward     | 311      |
| time/              |          |
|    total_timesteps | 3593568  |
---------------------------------
Eval num_timesteps=3595560, episode_reward=487.85 +/- 107.40
Episode length: 598.60 +/- 84.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 599      |
|    mean_reward     | 488      |
| time/              |          |
|    total_timesteps | 3595560  |
---------------------------------
Eval num_timesteps=3597552, episode_reward=518.39 +/- 184.49
Episode length: 535.80 +/- 77.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 536      |
|    mean_reward     | 518      |
| time/              |          |
|    total_timesteps | 3597552  |
---------------------------------
Eval num_timesteps=3599544, episode_reward=479.61 +/- 79.48
Episode length: 550.40 +/- 35.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 480      |
| time/              |          |
|    total_timesteps | 3599544  |
---------------------------------
Eval num_timesteps=3601536, episode_reward=386.93 +/- 150.83
Episode length: 503.00 +/- 45.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | 387      |
| time/              |          |
|    total_timesteps | 3601536  |
---------------------------------
Eval num_timesteps=3603528, episode_reward=636.39 +/- 225.04
Episode length: 668.80 +/- 104.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 669      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 3603528  |
---------------------------------
Eval num_timesteps=3605520, episode_reward=547.82 +/- 208.77
Episode length: 563.80 +/- 86.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 548      |
| time/              |          |
|    total_timesteps | 3605520  |
---------------------------------
Eval num_timesteps=3607512, episode_reward=412.06 +/- 169.68
Episode length: 539.60 +/- 32.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | 412      |
| time/              |          |
|    total_timesteps | 3607512  |
---------------------------------
Eval num_timesteps=3609504, episode_reward=459.57 +/- 184.39
Episode length: 542.00 +/- 62.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | 460      |
| time/              |          |
|    total_timesteps | 3609504  |
---------------------------------
Eval num_timesteps=3611496, episode_reward=385.52 +/- 367.95
Episode length: 506.60 +/- 41.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 386      |
| time/              |          |
|    total_timesteps | 3611496  |
---------------------------------
Eval num_timesteps=3613488, episode_reward=611.49 +/- 467.36
Episode length: 565.80 +/- 164.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 3613488  |
---------------------------------
Eval num_timesteps=3615480, episode_reward=396.14 +/- 140.06
Episode length: 567.60 +/- 31.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 396      |
| time/              |          |
|    total_timesteps | 3615480  |
---------------------------------
Eval num_timesteps=3617472, episode_reward=444.22 +/- 132.32
Episode length: 511.00 +/- 52.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 444      |
| time/              |          |
|    total_timesteps | 3617472  |
---------------------------------
Eval num_timesteps=3619464, episode_reward=423.07 +/- 240.43
Episode length: 508.80 +/- 33.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 423      |
| time/              |          |
|    total_timesteps | 3619464  |
---------------------------------
Eval num_timesteps=3621456, episode_reward=520.03 +/- 252.98
Episode length: 525.20 +/- 70.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 520      |
| time/              |          |
|    total_timesteps | 3621456  |
---------------------------------
Eval num_timesteps=3623448, episode_reward=640.17 +/- 288.95
Episode length: 554.00 +/- 31.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 640      |
| time/              |          |
|    total_timesteps | 3623448  |
---------------------------------
Eval num_timesteps=3625440, episode_reward=585.02 +/- 139.62
Episode length: 524.40 +/- 26.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | 585      |
| time/              |          |
|    total_timesteps | 3625440  |
---------------------------------
Eval num_timesteps=3627432, episode_reward=434.12 +/- 114.99
Episode length: 567.40 +/- 40.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 434      |
| time/              |          |
|    total_timesteps | 3627432  |
---------------------------------
Eval num_timesteps=3629424, episode_reward=549.09 +/- 179.83
Episode length: 553.20 +/- 67.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 549      |
| time/              |          |
|    total_timesteps | 3629424  |
---------------------------------
Eval num_timesteps=3631416, episode_reward=453.26 +/- 119.16
Episode length: 565.20 +/- 94.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3631416  |
---------------------------------
Eval num_timesteps=3633408, episode_reward=454.70 +/- 184.34
Episode length: 541.80 +/- 66.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | 455      |
| time/              |          |
|    total_timesteps | 3633408  |
---------------------------------
Eval num_timesteps=3635400, episode_reward=273.29 +/- 237.16
Episode length: 504.20 +/- 55.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 273      |
| time/              |          |
|    total_timesteps | 3635400  |
---------------------------------
Eval num_timesteps=3637392, episode_reward=416.00 +/- 170.65
Episode length: 539.40 +/- 59.92
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 539          |
|    mean_reward          | 416          |
| time/                   |              |
|    total_timesteps      | 3637392      |
| train/                  |              |
|    approx_kl            | 0.0043939124 |
|    clip_fraction        | 0.0451       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.89        |
|    explained_variance   | 0.975        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0302      |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.00182     |
|    std                  | 1.36         |
|    value_loss           | 0.091        |
------------------------------------------
Eval num_timesteps=3639384, episode_reward=453.26 +/- 147.16
Episode length: 548.00 +/- 47.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 3639384  |
---------------------------------
Eval num_timesteps=3641376, episode_reward=405.72 +/- 273.19
Episode length: 588.40 +/- 42.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 406      |
| time/              |          |
|    total_timesteps | 3641376  |
---------------------------------
Eval num_timesteps=3643368, episode_reward=588.17 +/- 39.63
Episode length: 731.20 +/- 116.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 731      |
|    mean_reward     | 588      |
| time/              |          |
|    total_timesteps | 3643368  |
---------------------------------
Eval num_timesteps=3645360, episode_reward=832.60 +/- 408.70
Episode length: 632.40 +/- 102.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 632      |
|    mean_reward     | 833      |
| time/              |          |
|    total_timesteps | 3645360  |
---------------------------------
Eval num_timesteps=3647352, episode_reward=469.75 +/- 114.92
Episode length: 567.00 +/- 26.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 470      |
| time/              |          |
|    total_timesteps | 3647352  |
---------------------------------
Eval num_timesteps=3649344, episode_reward=481.58 +/- 464.91
Episode length: 571.80 +/- 48.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 482      |
| time/              |          |
|    total_timesteps | 3649344  |
---------------------------------
Eval num_timesteps=3651336, episode_reward=771.08 +/- 631.41
Episode length: 590.00 +/- 66.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 590      |
|    mean_reward     | 771      |
| time/              |          |
|    total_timesteps | 3651336  |
---------------------------------
Eval num_timesteps=3653328, episode_reward=290.97 +/- 221.31
Episode length: 544.60 +/- 84.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 291      |
| time/              |          |
|    total_timesteps | 3653328  |
---------------------------------
Eval num_timesteps=3655320, episode_reward=395.41 +/- 124.04
Episode length: 580.40 +/- 125.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 580      |
|    mean_reward     | 395      |
| time/              |          |
|    total_timesteps | 3655320  |
---------------------------------
Eval num_timesteps=3657312, episode_reward=600.06 +/- 46.45
Episode length: 670.40 +/- 112.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 670      |
|    mean_reward     | 600      |
| time/              |          |
|    total_timesteps | 3657312  |
---------------------------------
Eval num_timesteps=3659304, episode_reward=703.15 +/- 404.40
Episode length: 588.40 +/- 43.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 703      |
| time/              |          |
|    total_timesteps | 3659304  |
---------------------------------
Eval num_timesteps=3661296, episode_reward=769.64 +/- 609.56
Episode length: 613.60 +/- 37.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 770      |
| time/              |          |
|    total_timesteps | 3661296  |
---------------------------------
Eval num_timesteps=3663288, episode_reward=508.31 +/- 127.20
Episode length: 542.20 +/- 32.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | 508      |
| time/              |          |
|    total_timesteps | 3663288  |
---------------------------------
Eval num_timesteps=3665280, episode_reward=489.21 +/- 334.38
Episode length: 529.00 +/- 33.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 489      |
| time/              |          |
|    total_timesteps | 3665280  |
---------------------------------
Eval num_timesteps=3667272, episode_reward=603.94 +/- 49.10
Episode length: 612.60 +/- 88.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 3667272  |
---------------------------------
Eval num_timesteps=3669264, episode_reward=304.42 +/- 241.51
Episode length: 506.00 +/- 41.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 304      |
| time/              |          |
|    total_timesteps | 3669264  |
---------------------------------
Eval num_timesteps=3671256, episode_reward=704.18 +/- 689.83
Episode length: 565.60 +/- 74.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 704      |
| time/              |          |
|    total_timesteps | 3671256  |
---------------------------------
Eval num_timesteps=3673248, episode_reward=466.42 +/- 215.10
Episode length: 664.00 +/- 91.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 664      |
|    mean_reward     | 466      |
| time/              |          |
|    total_timesteps | 3673248  |
---------------------------------
Eval num_timesteps=3675240, episode_reward=309.97 +/- 193.08
Episode length: 496.60 +/- 37.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | 310      |
| time/              |          |
|    total_timesteps | 3675240  |
---------------------------------
Eval num_timesteps=3677232, episode_reward=869.55 +/- 407.44
Episode length: 559.40 +/- 50.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 870      |
| time/              |          |
|    total_timesteps | 3677232  |
---------------------------------
Eval num_timesteps=3679224, episode_reward=459.90 +/- 318.93
Episode length: 530.00 +/- 48.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 460      |
| time/              |          |
|    total_timesteps | 3679224  |
---------------------------------
Eval num_timesteps=3681216, episode_reward=548.77 +/- 95.01
Episode length: 537.60 +/- 118.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 538      |
|    mean_reward     | 549      |
| time/              |          |
|    total_timesteps | 3681216  |
---------------------------------
Eval num_timesteps=3683208, episode_reward=680.38 +/- 244.91
Episode length: 588.20 +/- 77.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 680      |
| time/              |          |
|    total_timesteps | 3683208  |
---------------------------------
Eval num_timesteps=3685200, episode_reward=584.84 +/- 165.36
Episode length: 601.00 +/- 122.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 601      |
|    mean_reward     | 585      |
| time/              |          |
|    total_timesteps | 3685200  |
---------------------------------
Eval num_timesteps=3687192, episode_reward=882.04 +/- 485.10
Episode length: 663.80 +/- 121.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 664         |
|    mean_reward          | 882         |
| time/                   |             |
|    total_timesteps      | 3687192     |
| train/                  |             |
|    approx_kl            | 0.006108757 |
|    clip_fraction        | 0.0614      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0298     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00238    |
|    std                  | 1.38        |
|    value_loss           | 0.093       |
-----------------------------------------
Eval num_timesteps=3689184, episode_reward=582.28 +/- 27.79
Episode length: 572.20 +/- 64.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 582      |
| time/              |          |
|    total_timesteps | 3689184  |
---------------------------------
Eval num_timesteps=3691176, episode_reward=497.06 +/- 153.17
Episode length: 550.40 +/- 122.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 497      |
| time/              |          |
|    total_timesteps | 3691176  |
---------------------------------
Eval num_timesteps=3693168, episode_reward=575.89 +/- 169.09
Episode length: 552.80 +/- 59.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 3693168  |
---------------------------------
Eval num_timesteps=3695160, episode_reward=460.20 +/- 111.67
Episode length: 582.00 +/- 118.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 460      |
| time/              |          |
|    total_timesteps | 3695160  |
---------------------------------
Eval num_timesteps=3697152, episode_reward=486.14 +/- 155.67
Episode length: 530.20 +/- 37.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 486      |
| time/              |          |
|    total_timesteps | 3697152  |
---------------------------------
Eval num_timesteps=3699144, episode_reward=903.60 +/- 370.38
Episode length: 738.00 +/- 343.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 738      |
|    mean_reward     | 904      |
| time/              |          |
|    total_timesteps | 3699144  |
---------------------------------
Eval num_timesteps=3701136, episode_reward=564.06 +/- 309.08
Episode length: 510.20 +/- 28.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 564      |
| time/              |          |
|    total_timesteps | 3701136  |
---------------------------------
Eval num_timesteps=3703128, episode_reward=695.28 +/- 146.57
Episode length: 615.40 +/- 106.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 695      |
| time/              |          |
|    total_timesteps | 3703128  |
---------------------------------
Eval num_timesteps=3705120, episode_reward=553.03 +/- 191.51
Episode length: 563.00 +/- 30.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | 553      |
| time/              |          |
|    total_timesteps | 3705120  |
---------------------------------
Eval num_timesteps=3707112, episode_reward=510.22 +/- 42.93
Episode length: 692.00 +/- 191.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 692      |
|    mean_reward     | 510      |
| time/              |          |
|    total_timesteps | 3707112  |
---------------------------------
Eval num_timesteps=3709104, episode_reward=510.37 +/- 159.24
Episode length: 601.40 +/- 155.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 601      |
|    mean_reward     | 510      |
| time/              |          |
|    total_timesteps | 3709104  |
---------------------------------
Eval num_timesteps=3711096, episode_reward=820.20 +/- 514.62
Episode length: 697.00 +/- 131.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | 820      |
| time/              |          |
|    total_timesteps | 3711096  |
---------------------------------
Eval num_timesteps=3713088, episode_reward=1455.31 +/- 1343.96
Episode length: 612.40 +/- 127.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | 1.46e+03 |
| time/              |          |
|    total_timesteps | 3713088  |
---------------------------------
New best mean reward!
Eval num_timesteps=3715080, episode_reward=437.95 +/- 171.03
Episode length: 575.60 +/- 53.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 438      |
| time/              |          |
|    total_timesteps | 3715080  |
---------------------------------
Eval num_timesteps=3717072, episode_reward=450.23 +/- 166.19
Episode length: 676.20 +/- 139.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 676      |
|    mean_reward     | 450      |
| time/              |          |
|    total_timesteps | 3717072  |
---------------------------------
Eval num_timesteps=3719064, episode_reward=621.32 +/- 228.17
Episode length: 583.80 +/- 76.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 3719064  |
---------------------------------
Eval num_timesteps=3721056, episode_reward=627.07 +/- 269.41
Episode length: 594.00 +/- 122.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 3721056  |
---------------------------------
Eval num_timesteps=3723048, episode_reward=626.77 +/- 77.37
Episode length: 608.60 +/- 142.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 3723048  |
---------------------------------
Eval num_timesteps=3725040, episode_reward=620.75 +/- 91.74
Episode length: 567.60 +/- 48.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 3725040  |
---------------------------------
Eval num_timesteps=3727032, episode_reward=652.01 +/- 64.72
Episode length: 602.40 +/- 21.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 652      |
| time/              |          |
|    total_timesteps | 3727032  |
---------------------------------
Eval num_timesteps=3729024, episode_reward=748.87 +/- 238.32
Episode length: 554.80 +/- 22.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 3729024  |
---------------------------------
Eval num_timesteps=3731016, episode_reward=563.94 +/- 60.16
Episode length: 801.80 +/- 520.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 564      |
| time/              |          |
|    total_timesteps | 3731016  |
---------------------------------
Eval num_timesteps=3733008, episode_reward=921.69 +/- 509.58
Episode length: 570.00 +/- 106.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 922      |
| time/              |          |
|    total_timesteps | 3733008  |
---------------------------------
Eval num_timesteps=3735000, episode_reward=633.78 +/- 289.62
Episode length: 546.60 +/- 76.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 634      |
| time/              |          |
|    total_timesteps | 3735000  |
---------------------------------
Eval num_timesteps=3736992, episode_reward=564.05 +/- 26.63
Episode length: 566.20 +/- 58.11
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 566          |
|    mean_reward          | 564          |
| time/                   |              |
|    total_timesteps      | 3736992      |
| train/                  |              |
|    approx_kl            | 0.0062230304 |
|    clip_fraction        | 0.0694       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.96        |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.001        |
|    loss                 | -0.00508     |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.0016      |
|    std                  | 1.39         |
|    value_loss           | 0.146        |
------------------------------------------
Eval num_timesteps=3738984, episode_reward=838.64 +/- 324.86
Episode length: 688.00 +/- 99.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 688      |
|    mean_reward     | 839      |
| time/              |          |
|    total_timesteps | 3738984  |
---------------------------------
Eval num_timesteps=3740976, episode_reward=593.31 +/- 58.31
Episode length: 569.00 +/- 37.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 3740976  |
---------------------------------
Eval num_timesteps=3742968, episode_reward=758.43 +/- 361.67
Episode length: 591.80 +/- 149.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 758      |
| time/              |          |
|    total_timesteps | 3742968  |
---------------------------------
Eval num_timesteps=3744960, episode_reward=695.95 +/- 154.21
Episode length: 544.20 +/- 44.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 696      |
| time/              |          |
|    total_timesteps | 3744960  |
---------------------------------
Eval num_timesteps=3746952, episode_reward=659.12 +/- 247.42
Episode length: 590.60 +/- 29.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 3746952  |
---------------------------------
Eval num_timesteps=3748944, episode_reward=593.82 +/- 165.22
Episode length: 625.00 +/- 133.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 594      |
| time/              |          |
|    total_timesteps | 3748944  |
---------------------------------
Eval num_timesteps=3750936, episode_reward=624.26 +/- 67.96
Episode length: 640.80 +/- 208.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 641      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 3750936  |
---------------------------------
Eval num_timesteps=3752928, episode_reward=759.29 +/- 308.29
Episode length: 657.00 +/- 244.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 657      |
|    mean_reward     | 759      |
| time/              |          |
|    total_timesteps | 3752928  |
---------------------------------
Eval num_timesteps=3754920, episode_reward=594.52 +/- 61.76
Episode length: 618.60 +/- 43.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 595      |
| time/              |          |
|    total_timesteps | 3754920  |
---------------------------------
Eval num_timesteps=3756912, episode_reward=614.08 +/- 123.98
Episode length: 545.60 +/- 36.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 3756912  |
---------------------------------
Eval num_timesteps=3758904, episode_reward=667.87 +/- 171.23
Episode length: 583.60 +/- 65.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 668      |
| time/              |          |
|    total_timesteps | 3758904  |
---------------------------------
Eval num_timesteps=3760896, episode_reward=694.06 +/- 294.99
Episode length: 616.20 +/- 89.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 616      |
|    mean_reward     | 694      |
| time/              |          |
|    total_timesteps | 3760896  |
---------------------------------
Eval num_timesteps=3762888, episode_reward=872.48 +/- 642.18
Episode length: 622.80 +/- 131.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 3762888  |
---------------------------------
Eval num_timesteps=3764880, episode_reward=670.91 +/- 189.63
Episode length: 577.80 +/- 37.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 671      |
| time/              |          |
|    total_timesteps | 3764880  |
---------------------------------
Eval num_timesteps=3766872, episode_reward=691.49 +/- 190.28
Episode length: 574.00 +/- 42.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | 691      |
| time/              |          |
|    total_timesteps | 3766872  |
---------------------------------
Eval num_timesteps=3768864, episode_reward=580.92 +/- 23.21
Episode length: 565.00 +/- 80.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 581      |
| time/              |          |
|    total_timesteps | 3768864  |
---------------------------------
Eval num_timesteps=3770856, episode_reward=576.75 +/- 53.18
Episode length: 630.40 +/- 51.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 577      |
| time/              |          |
|    total_timesteps | 3770856  |
---------------------------------
Eval num_timesteps=3772848, episode_reward=748.97 +/- 367.31
Episode length: 635.80 +/- 100.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 636      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 3772848  |
---------------------------------
Eval num_timesteps=3774840, episode_reward=540.53 +/- 80.97
Episode length: 564.80 +/- 51.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 541      |
| time/              |          |
|    total_timesteps | 3774840  |
---------------------------------
Eval num_timesteps=3776832, episode_reward=762.23 +/- 409.68
Episode length: 584.60 +/- 54.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 762      |
| time/              |          |
|    total_timesteps | 3776832  |
---------------------------------
Eval num_timesteps=3778824, episode_reward=625.90 +/- 127.89
Episode length: 582.00 +/- 65.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 626      |
| time/              |          |
|    total_timesteps | 3778824  |
---------------------------------
Eval num_timesteps=3780816, episode_reward=833.28 +/- 437.67
Episode length: 561.60 +/- 50.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 833      |
| time/              |          |
|    total_timesteps | 3780816  |
---------------------------------
Eval num_timesteps=3782808, episode_reward=668.04 +/- 64.65
Episode length: 612.80 +/- 87.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 668      |
| time/              |          |
|    total_timesteps | 3782808  |
---------------------------------
Eval num_timesteps=3784800, episode_reward=542.81 +/- 14.66
Episode length: 524.60 +/- 47.99
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 525          |
|    mean_reward          | 543          |
| time/                   |              |
|    total_timesteps      | 3784800      |
| train/                  |              |
|    approx_kl            | 0.0062858253 |
|    clip_fraction        | 0.0436       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.99        |
|    explained_variance   | 0.957        |
|    learning_rate        | 0.001        |
|    loss                 | 0.016        |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00104     |
|    std                  | 1.4          |
|    value_loss           | 0.194        |
------------------------------------------
Eval num_timesteps=3786792, episode_reward=636.28 +/- 76.39
Episode length: 554.60 +/- 44.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 3786792  |
---------------------------------
Eval num_timesteps=3788784, episode_reward=694.46 +/- 205.90
Episode length: 608.40 +/- 69.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | 694      |
| time/              |          |
|    total_timesteps | 3788784  |
---------------------------------
Eval num_timesteps=3790776, episode_reward=486.82 +/- 105.67
Episode length: 510.20 +/- 32.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 487      |
| time/              |          |
|    total_timesteps | 3790776  |
---------------------------------
Eval num_timesteps=3792768, episode_reward=640.72 +/- 87.16
Episode length: 586.60 +/- 43.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 641      |
| time/              |          |
|    total_timesteps | 3792768  |
---------------------------------
Eval num_timesteps=3794760, episode_reward=769.14 +/- 299.08
Episode length: 532.60 +/- 46.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 769      |
| time/              |          |
|    total_timesteps | 3794760  |
---------------------------------
Eval num_timesteps=3796752, episode_reward=607.43 +/- 80.98
Episode length: 647.20 +/- 131.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 647      |
|    mean_reward     | 607      |
| time/              |          |
|    total_timesteps | 3796752  |
---------------------------------
Eval num_timesteps=3798744, episode_reward=569.37 +/- 22.36
Episode length: 524.60 +/- 29.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 3798744  |
---------------------------------
Eval num_timesteps=3800736, episode_reward=624.23 +/- 136.38
Episode length: 602.20 +/- 91.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 3800736  |
---------------------------------
Eval num_timesteps=3802728, episode_reward=412.11 +/- 249.83
Episode length: 537.20 +/- 68.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 412      |
| time/              |          |
|    total_timesteps | 3802728  |
---------------------------------
Eval num_timesteps=3804720, episode_reward=625.58 +/- 94.85
Episode length: 515.20 +/- 35.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 626      |
| time/              |          |
|    total_timesteps | 3804720  |
---------------------------------
Eval num_timesteps=3806712, episode_reward=819.06 +/- 350.01
Episode length: 558.80 +/- 71.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 819      |
| time/              |          |
|    total_timesteps | 3806712  |
---------------------------------
Eval num_timesteps=3808704, episode_reward=624.77 +/- 99.27
Episode length: 554.00 +/- 44.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 625      |
| time/              |          |
|    total_timesteps | 3808704  |
---------------------------------
Eval num_timesteps=3810696, episode_reward=531.96 +/- 30.22
Episode length: 504.00 +/- 50.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 532      |
| time/              |          |
|    total_timesteps | 3810696  |
---------------------------------
Eval num_timesteps=3812688, episode_reward=728.07 +/- 339.37
Episode length: 545.40 +/- 17.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 728      |
| time/              |          |
|    total_timesteps | 3812688  |
---------------------------------
Eval num_timesteps=3814680, episode_reward=694.70 +/- 196.98
Episode length: 546.80 +/- 61.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 695      |
| time/              |          |
|    total_timesteps | 3814680  |
---------------------------------
Eval num_timesteps=3816672, episode_reward=541.12 +/- 68.25
Episode length: 559.60 +/- 57.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | 541      |
| time/              |          |
|    total_timesteps | 3816672  |
---------------------------------
Eval num_timesteps=3818664, episode_reward=652.49 +/- 148.00
Episode length: 566.20 +/- 101.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 652      |
| time/              |          |
|    total_timesteps | 3818664  |
---------------------------------
Eval num_timesteps=3820656, episode_reward=557.43 +/- 34.72
Episode length: 615.40 +/- 114.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 557      |
| time/              |          |
|    total_timesteps | 3820656  |
---------------------------------
Eval num_timesteps=3822648, episode_reward=669.53 +/- 186.45
Episode length: 586.60 +/- 55.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 670      |
| time/              |          |
|    total_timesteps | 3822648  |
---------------------------------
Eval num_timesteps=3824640, episode_reward=710.11 +/- 202.75
Episode length: 511.20 +/- 38.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 710      |
| time/              |          |
|    total_timesteps | 3824640  |
---------------------------------
Eval num_timesteps=3826632, episode_reward=560.06 +/- 88.50
Episode length: 540.80 +/- 47.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 560      |
| time/              |          |
|    total_timesteps | 3826632  |
---------------------------------
Eval num_timesteps=3828624, episode_reward=531.49 +/- 37.85
Episode length: 534.40 +/- 46.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 531      |
| time/              |          |
|    total_timesteps | 3828624  |
---------------------------------
Eval num_timesteps=3830616, episode_reward=503.81 +/- 151.12
Episode length: 503.40 +/- 95.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | 504      |
| time/              |          |
|    total_timesteps | 3830616  |
---------------------------------
Eval num_timesteps=3832608, episode_reward=526.77 +/- 108.27
Episode length: 552.60 +/- 126.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 527      |
| time/              |          |
|    total_timesteps | 3832608  |
---------------------------------
Eval num_timesteps=3834600, episode_reward=602.98 +/- 339.09
Episode length: 524.40 +/- 43.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 524         |
|    mean_reward          | 603         |
| time/                   |             |
|    total_timesteps      | 3834600     |
| train/                  |             |
|    approx_kl            | 0.005305558 |
|    clip_fraction        | 0.0343      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.01       |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.001       |
|    loss                 | 0.0103      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.000991   |
|    std                  | 1.4         |
|    value_loss           | 0.159       |
-----------------------------------------
Eval num_timesteps=3836592, episode_reward=644.10 +/- 51.58
Episode length: 568.00 +/- 79.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 644      |
| time/              |          |
|    total_timesteps | 3836592  |
---------------------------------
Eval num_timesteps=3838584, episode_reward=652.92 +/- 96.56
Episode length: 569.00 +/- 95.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 653      |
| time/              |          |
|    total_timesteps | 3838584  |
---------------------------------
Eval num_timesteps=3840576, episode_reward=591.83 +/- 46.98
Episode length: 511.00 +/- 30.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 592      |
| time/              |          |
|    total_timesteps | 3840576  |
---------------------------------
Eval num_timesteps=3842568, episode_reward=865.58 +/- 325.61
Episode length: 479.00 +/- 57.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | 866      |
| time/              |          |
|    total_timesteps | 3842568  |
---------------------------------
Eval num_timesteps=3844560, episode_reward=599.51 +/- 83.59
Episode length: 487.60 +/- 36.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | 600      |
| time/              |          |
|    total_timesteps | 3844560  |
---------------------------------
Eval num_timesteps=3846552, episode_reward=959.84 +/- 417.90
Episode length: 536.80 +/- 104.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 960      |
| time/              |          |
|    total_timesteps | 3846552  |
---------------------------------
Eval num_timesteps=3848544, episode_reward=563.42 +/- 172.93
Episode length: 453.20 +/- 45.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 453      |
|    mean_reward     | 563      |
| time/              |          |
|    total_timesteps | 3848544  |
---------------------------------
Eval num_timesteps=3850536, episode_reward=646.11 +/- 93.86
Episode length: 526.20 +/- 41.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 3850536  |
---------------------------------
Eval num_timesteps=3852528, episode_reward=564.28 +/- 41.12
Episode length: 507.20 +/- 38.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 564      |
| time/              |          |
|    total_timesteps | 3852528  |
---------------------------------
Eval num_timesteps=3854520, episode_reward=590.19 +/- 40.20
Episode length: 515.80 +/- 33.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 590      |
| time/              |          |
|    total_timesteps | 3854520  |
---------------------------------
Eval num_timesteps=3856512, episode_reward=764.57 +/- 388.28
Episode length: 497.20 +/- 19.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | 765      |
| time/              |          |
|    total_timesteps | 3856512  |
---------------------------------
Eval num_timesteps=3858504, episode_reward=848.45 +/- 577.46
Episode length: 513.40 +/- 48.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 848      |
| time/              |          |
|    total_timesteps | 3858504  |
---------------------------------
Eval num_timesteps=3860496, episode_reward=575.75 +/- 49.10
Episode length: 540.20 +/- 72.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 3860496  |
---------------------------------
Eval num_timesteps=3862488, episode_reward=596.09 +/- 23.34
Episode length: 497.20 +/- 32.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | 596      |
| time/              |          |
|    total_timesteps | 3862488  |
---------------------------------
Eval num_timesteps=3864480, episode_reward=525.96 +/- 36.19
Episode length: 502.00 +/- 41.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 3864480  |
---------------------------------
Eval num_timesteps=3866472, episode_reward=636.49 +/- 162.60
Episode length: 502.40 +/- 46.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 3866472  |
---------------------------------
Eval num_timesteps=3868464, episode_reward=644.00 +/- 120.65
Episode length: 549.60 +/- 131.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 644      |
| time/              |          |
|    total_timesteps | 3868464  |
---------------------------------
Eval num_timesteps=3870456, episode_reward=601.26 +/- 182.21
Episode length: 491.00 +/- 88.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 3870456  |
---------------------------------
Eval num_timesteps=3872448, episode_reward=633.60 +/- 134.66
Episode length: 507.60 +/- 26.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 634      |
| time/              |          |
|    total_timesteps | 3872448  |
---------------------------------
Eval num_timesteps=3874440, episode_reward=709.64 +/- 236.85
Episode length: 534.60 +/- 16.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 710      |
| time/              |          |
|    total_timesteps | 3874440  |
---------------------------------
Eval num_timesteps=3876432, episode_reward=606.07 +/- 147.70
Episode length: 498.40 +/- 33.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | 606      |
| time/              |          |
|    total_timesteps | 3876432  |
---------------------------------
Eval num_timesteps=3878424, episode_reward=578.38 +/- 99.70
Episode length: 571.80 +/- 54.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 578      |
| time/              |          |
|    total_timesteps | 3878424  |
---------------------------------
Eval num_timesteps=3880416, episode_reward=527.59 +/- 110.82
Episode length: 506.40 +/- 47.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 528      |
| time/              |          |
|    total_timesteps | 3880416  |
---------------------------------
Eval num_timesteps=3882408, episode_reward=724.48 +/- 133.95
Episode length: 494.00 +/- 35.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 724      |
| time/              |          |
|    total_timesteps | 3882408  |
---------------------------------
Eval num_timesteps=3884400, episode_reward=662.95 +/- 185.60
Episode length: 483.80 +/- 18.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 484          |
|    mean_reward          | 663          |
| time/                   |              |
|    total_timesteps      | 3884400      |
| train/                  |              |
|    approx_kl            | 0.0045337626 |
|    clip_fraction        | 0.0505       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.03        |
|    explained_variance   | 0.963        |
|    learning_rate        | 0.001        |
|    loss                 | -0.00289     |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.000847    |
|    std                  | 1.41         |
|    value_loss           | 0.15         |
------------------------------------------
Eval num_timesteps=3886392, episode_reward=593.26 +/- 282.75
Episode length: 485.40 +/- 65.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 485      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 3886392  |
---------------------------------
Eval num_timesteps=3888384, episode_reward=674.61 +/- 168.87
Episode length: 502.00 +/- 22.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 675      |
| time/              |          |
|    total_timesteps | 3888384  |
---------------------------------
Eval num_timesteps=3890376, episode_reward=566.01 +/- 99.66
Episode length: 487.80 +/- 62.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 488      |
|    mean_reward     | 566      |
| time/              |          |
|    total_timesteps | 3890376  |
---------------------------------
Eval num_timesteps=3892368, episode_reward=522.26 +/- 83.51
Episode length: 476.80 +/- 14.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 522      |
| time/              |          |
|    total_timesteps | 3892368  |
---------------------------------
Eval num_timesteps=3894360, episode_reward=483.70 +/- 192.14
Episode length: 471.40 +/- 47.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 471      |
|    mean_reward     | 484      |
| time/              |          |
|    total_timesteps | 3894360  |
---------------------------------
Eval num_timesteps=3896352, episode_reward=569.81 +/- 258.49
Episode length: 506.80 +/- 17.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 3896352  |
---------------------------------
Eval num_timesteps=3898344, episode_reward=654.25 +/- 439.59
Episode length: 464.60 +/- 51.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 465      |
|    mean_reward     | 654      |
| time/              |          |
|    total_timesteps | 3898344  |
---------------------------------
Eval num_timesteps=3900336, episode_reward=698.50 +/- 193.60
Episode length: 512.80 +/- 28.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 698      |
| time/              |          |
|    total_timesteps | 3900336  |
---------------------------------
Eval num_timesteps=3902328, episode_reward=664.50 +/- 120.07
Episode length: 553.00 +/- 35.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 664      |
| time/              |          |
|    total_timesteps | 3902328  |
---------------------------------
Eval num_timesteps=3904320, episode_reward=360.89 +/- 166.33
Episode length: 411.60 +/- 40.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 412      |
|    mean_reward     | 361      |
| time/              |          |
|    total_timesteps | 3904320  |
---------------------------------
Eval num_timesteps=3906312, episode_reward=722.62 +/- 185.77
Episode length: 481.60 +/- 38.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 723      |
| time/              |          |
|    total_timesteps | 3906312  |
---------------------------------
Eval num_timesteps=3908304, episode_reward=535.82 +/- 145.77
Episode length: 502.80 +/- 54.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 503      |
|    mean_reward     | 536      |
| time/              |          |
|    total_timesteps | 3908304  |
---------------------------------
Eval num_timesteps=3910296, episode_reward=630.48 +/- 289.25
Episode length: 556.40 +/- 72.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | 630      |
| time/              |          |
|    total_timesteps | 3910296  |
---------------------------------
Eval num_timesteps=3912288, episode_reward=569.06 +/- 106.90
Episode length: 514.00 +/- 73.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 3912288  |
---------------------------------
Eval num_timesteps=3914280, episode_reward=547.02 +/- 160.18
Episode length: 484.20 +/- 27.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 484      |
|    mean_reward     | 547      |
| time/              |          |
|    total_timesteps | 3914280  |
---------------------------------
Eval num_timesteps=3916272, episode_reward=647.48 +/- 75.56
Episode length: 511.40 +/- 38.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 647      |
| time/              |          |
|    total_timesteps | 3916272  |
---------------------------------
Eval num_timesteps=3918264, episode_reward=524.95 +/- 237.03
Episode length: 481.00 +/- 23.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 481      |
|    mean_reward     | 525      |
| time/              |          |
|    total_timesteps | 3918264  |
---------------------------------
Eval num_timesteps=3920256, episode_reward=662.84 +/- 88.45
Episode length: 526.80 +/- 44.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 3920256  |
---------------------------------
Eval num_timesteps=3922248, episode_reward=492.92 +/- 150.52
Episode length: 478.20 +/- 50.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | 493      |
| time/              |          |
|    total_timesteps | 3922248  |
---------------------------------
Eval num_timesteps=3924240, episode_reward=504.17 +/- 338.43
Episode length: 477.60 +/- 60.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | 504      |
| time/              |          |
|    total_timesteps | 3924240  |
---------------------------------
Eval num_timesteps=3926232, episode_reward=652.04 +/- 58.05
Episode length: 534.80 +/- 50.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 652      |
| time/              |          |
|    total_timesteps | 3926232  |
---------------------------------
Eval num_timesteps=3928224, episode_reward=564.45 +/- 50.71
Episode length: 512.80 +/- 38.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 564      |
| time/              |          |
|    total_timesteps | 3928224  |
---------------------------------
Eval num_timesteps=3930216, episode_reward=579.33 +/- 59.88
Episode length: 475.20 +/- 30.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 475      |
|    mean_reward     | 579      |
| time/              |          |
|    total_timesteps | 3930216  |
---------------------------------
Eval num_timesteps=3932208, episode_reward=832.00 +/- 288.77
Episode length: 500.00 +/- 66.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | 832         |
| time/                   |             |
|    total_timesteps      | 3932208     |
| train/                  |             |
|    approx_kl            | 0.009688412 |
|    clip_fraction        | 0.0467      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.972       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0107     |
|    n_updates            | 800         |
|    policy_gradient_loss | 0.00115     |
|    std                  | 1.42        |
|    value_loss           | 0.117       |
-----------------------------------------
Eval num_timesteps=3934200, episode_reward=563.63 +/- 218.01
Episode length: 485.60 +/- 42.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 564      |
| time/              |          |
|    total_timesteps | 3934200  |
---------------------------------
Eval num_timesteps=3936192, episode_reward=738.84 +/- 140.54
Episode length: 527.00 +/- 68.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 3936192  |
---------------------------------
Eval num_timesteps=3938184, episode_reward=572.87 +/- 37.39
Episode length: 508.40 +/- 50.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 573      |
| time/              |          |
|    total_timesteps | 3938184  |
---------------------------------
Eval num_timesteps=3940176, episode_reward=603.97 +/- 180.92
Episode length: 534.80 +/- 77.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 3940176  |
---------------------------------
Eval num_timesteps=3942168, episode_reward=776.21 +/- 250.22
Episode length: 583.00 +/- 106.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 776      |
| time/              |          |
|    total_timesteps | 3942168  |
---------------------------------
Eval num_timesteps=3944160, episode_reward=672.61 +/- 184.87
Episode length: 487.00 +/- 33.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 3944160  |
---------------------------------
Eval num_timesteps=3946152, episode_reward=739.94 +/- 326.77
Episode length: 507.40 +/- 43.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 740      |
| time/              |          |
|    total_timesteps | 3946152  |
---------------------------------
Eval num_timesteps=3948144, episode_reward=660.18 +/- 399.35
Episode length: 511.60 +/- 65.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 660      |
| time/              |          |
|    total_timesteps | 3948144  |
---------------------------------
Eval num_timesteps=3950136, episode_reward=820.14 +/- 460.91
Episode length: 556.80 +/- 98.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 820      |
| time/              |          |
|    total_timesteps | 3950136  |
---------------------------------
Eval num_timesteps=3952128, episode_reward=1126.62 +/- 334.87
Episode length: 512.80 +/- 20.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 3952128  |
---------------------------------
Eval num_timesteps=3954120, episode_reward=753.24 +/- 307.00
Episode length: 486.60 +/- 44.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | 753      |
| time/              |          |
|    total_timesteps | 3954120  |
---------------------------------
Eval num_timesteps=3956112, episode_reward=739.27 +/- 207.34
Episode length: 569.20 +/- 132.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 3956112  |
---------------------------------
Eval num_timesteps=3958104, episode_reward=1012.83 +/- 359.34
Episode length: 524.40 +/- 43.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 3958104  |
---------------------------------
Eval num_timesteps=3960096, episode_reward=723.26 +/- 508.47
Episode length: 500.20 +/- 64.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 723      |
| time/              |          |
|    total_timesteps | 3960096  |
---------------------------------
Eval num_timesteps=3962088, episode_reward=569.53 +/- 316.25
Episode length: 477.00 +/- 44.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 3962088  |
---------------------------------
Eval num_timesteps=3964080, episode_reward=636.05 +/- 114.56
Episode length: 458.60 +/- 24.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 459      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 3964080  |
---------------------------------
Eval num_timesteps=3966072, episode_reward=605.93 +/- 126.11
Episode length: 500.40 +/- 43.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 606      |
| time/              |          |
|    total_timesteps | 3966072  |
---------------------------------
Eval num_timesteps=3968064, episode_reward=776.14 +/- 202.03
Episode length: 498.00 +/- 37.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 498      |
|    mean_reward     | 776      |
| time/              |          |
|    total_timesteps | 3968064  |
---------------------------------
Eval num_timesteps=3970056, episode_reward=823.53 +/- 341.87
Episode length: 538.80 +/- 39.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | 824      |
| time/              |          |
|    total_timesteps | 3970056  |
---------------------------------
Eval num_timesteps=3972048, episode_reward=446.11 +/- 141.37
Episode length: 460.80 +/- 36.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | 446      |
| time/              |          |
|    total_timesteps | 3972048  |
---------------------------------
Eval num_timesteps=3974040, episode_reward=517.78 +/- 173.14
Episode length: 478.80 +/- 38.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | 518      |
| time/              |          |
|    total_timesteps | 3974040  |
---------------------------------
Eval num_timesteps=3976032, episode_reward=788.94 +/- 376.96
Episode length: 524.00 +/- 57.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 524      |
|    mean_reward     | 789      |
| time/              |          |
|    total_timesteps | 3976032  |
---------------------------------
Eval num_timesteps=3978024, episode_reward=577.47 +/- 187.27
Episode length: 477.00 +/- 41.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 477      |
|    mean_reward     | 577      |
| time/              |          |
|    total_timesteps | 3978024  |
---------------------------------
Eval num_timesteps=3980016, episode_reward=732.24 +/- 435.95
Episode length: 507.20 +/- 68.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 732      |
| time/              |          |
|    total_timesteps | 3980016  |
---------------------------------
Eval num_timesteps=3982008, episode_reward=438.13 +/- 254.15
Episode length: 480.40 +/- 94.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 480         |
|    mean_reward          | 438         |
| time/                   |             |
|    total_timesteps      | 3982008     |
| train/                  |             |
|    approx_kl            | 0.003582197 |
|    clip_fraction        | 0.0298      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.09       |
|    explained_variance   | 0.977       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0365     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00104    |
|    std                  | 1.43        |
|    value_loss           | 0.0799      |
-----------------------------------------
Eval num_timesteps=3984000, episode_reward=867.36 +/- 244.46
Episode length: 502.20 +/- 34.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 867      |
| time/              |          |
|    total_timesteps | 3984000  |
---------------------------------
Eval num_timesteps=3985992, episode_reward=552.40 +/- 302.44
Episode length: 459.80 +/- 32.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 552      |
| time/              |          |
|    total_timesteps | 3985992  |
---------------------------------
Eval num_timesteps=3987984, episode_reward=885.54 +/- 374.40
Episode length: 509.80 +/- 27.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 886      |
| time/              |          |
|    total_timesteps | 3987984  |
---------------------------------
Eval num_timesteps=3989976, episode_reward=886.04 +/- 353.81
Episode length: 491.20 +/- 25.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 886      |
| time/              |          |
|    total_timesteps | 3989976  |
---------------------------------
Eval num_timesteps=3991968, episode_reward=506.90 +/- 325.98
Episode length: 466.00 +/- 48.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 507      |
| time/              |          |
|    total_timesteps | 3991968  |
---------------------------------
Eval num_timesteps=3993960, episode_reward=900.30 +/- 455.08
Episode length: 493.60 +/- 41.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 900      |
| time/              |          |
|    total_timesteps | 3993960  |
---------------------------------
Eval num_timesteps=3995952, episode_reward=822.86 +/- 240.14
Episode length: 558.60 +/- 98.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 823      |
| time/              |          |
|    total_timesteps | 3995952  |
---------------------------------
Eval num_timesteps=3997944, episode_reward=537.95 +/- 97.18
Episode length: 435.60 +/- 29.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 436      |
|    mean_reward     | 538      |
| time/              |          |
|    total_timesteps | 3997944  |
---------------------------------
Eval num_timesteps=3999936, episode_reward=583.04 +/- 72.50
Episode length: 518.80 +/- 72.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 583      |
| time/              |          |
|    total_timesteps | 3999936  |
---------------------------------
Eval num_timesteps=4001928, episode_reward=695.29 +/- 221.63
Episode length: 499.20 +/- 70.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 499      |
|    mean_reward     | 695      |
| time/              |          |
|    total_timesteps | 4001928  |
---------------------------------
Eval num_timesteps=4003920, episode_reward=766.30 +/- 218.64
Episode length: 512.40 +/- 22.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 766      |
| time/              |          |
|    total_timesteps | 4003920  |
---------------------------------
Eval num_timesteps=4005912, episode_reward=1059.05 +/- 607.17
Episode length: 594.00 +/- 136.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 594      |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 4005912  |
---------------------------------
Eval num_timesteps=4007904, episode_reward=624.79 +/- 159.56
Episode length: 531.80 +/- 50.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 625      |
| time/              |          |
|    total_timesteps | 4007904  |
---------------------------------
Eval num_timesteps=4009896, episode_reward=895.19 +/- 344.38
Episode length: 566.60 +/- 63.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 895      |
| time/              |          |
|    total_timesteps | 4009896  |
---------------------------------
Eval num_timesteps=4011888, episode_reward=569.69 +/- 129.06
Episode length: 481.80 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 4011888  |
---------------------------------
Eval num_timesteps=4013880, episode_reward=657.79 +/- 221.03
Episode length: 511.80 +/- 42.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 658      |
| time/              |          |
|    total_timesteps | 4013880  |
---------------------------------
Eval num_timesteps=4015872, episode_reward=652.58 +/- 142.86
Episode length: 486.00 +/- 46.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 653      |
| time/              |          |
|    total_timesteps | 4015872  |
---------------------------------
Eval num_timesteps=4017864, episode_reward=655.87 +/- 124.40
Episode length: 505.80 +/- 109.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 656      |
| time/              |          |
|    total_timesteps | 4017864  |
---------------------------------
Eval num_timesteps=4019856, episode_reward=672.85 +/- 204.21
Episode length: 494.00 +/- 39.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 4019856  |
---------------------------------
Eval num_timesteps=4021848, episode_reward=545.83 +/- 215.03
Episode length: 492.40 +/- 48.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 492      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 4021848  |
---------------------------------
Eval num_timesteps=4023840, episode_reward=656.83 +/- 451.82
Episode length: 519.80 +/- 30.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 657      |
| time/              |          |
|    total_timesteps | 4023840  |
---------------------------------
Eval num_timesteps=4025832, episode_reward=615.64 +/- 184.75
Episode length: 489.40 +/- 50.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 616      |
| time/              |          |
|    total_timesteps | 4025832  |
---------------------------------
Eval num_timesteps=4027824, episode_reward=603.53 +/- 273.29
Episode length: 469.80 +/- 70.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 470      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 4027824  |
---------------------------------
Eval num_timesteps=4029816, episode_reward=587.42 +/- 233.92
Episode length: 484.20 +/- 47.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 484      |
|    mean_reward     | 587      |
| time/              |          |
|    total_timesteps | 4029816  |
---------------------------------
Eval num_timesteps=4031808, episode_reward=571.11 +/- 173.98
Episode length: 506.00 +/- 28.73
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 506          |
|    mean_reward          | 571          |
| time/                   |              |
|    total_timesteps      | 4031808      |
| train/                  |              |
|    approx_kl            | 0.0038278122 |
|    clip_fraction        | 0.0402       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.12        |
|    explained_variance   | 0.977        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0412      |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00157     |
|    std                  | 1.45         |
|    value_loss           | 0.0737       |
------------------------------------------
Eval num_timesteps=4033800, episode_reward=530.54 +/- 164.12
Episode length: 496.60 +/- 32.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | 531      |
| time/              |          |
|    total_timesteps | 4033800  |
---------------------------------
Eval num_timesteps=4035792, episode_reward=706.96 +/- 149.69
Episode length: 513.60 +/- 50.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 707      |
| time/              |          |
|    total_timesteps | 4035792  |
---------------------------------
Eval num_timesteps=4037784, episode_reward=663.49 +/- 135.60
Episode length: 543.40 +/- 29.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 543      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 4037784  |
---------------------------------
Eval num_timesteps=4039776, episode_reward=645.95 +/- 154.55
Episode length: 489.00 +/- 40.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 4039776  |
---------------------------------
Eval num_timesteps=4041768, episode_reward=949.00 +/- 294.10
Episode length: 546.40 +/- 75.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 949      |
| time/              |          |
|    total_timesteps | 4041768  |
---------------------------------
Eval num_timesteps=4043760, episode_reward=1118.58 +/- 482.10
Episode length: 503.80 +/- 53.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 504      |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 4043760  |
---------------------------------
Eval num_timesteps=4045752, episode_reward=526.87 +/- 154.72
Episode length: 530.40 +/- 84.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 527      |
| time/              |          |
|    total_timesteps | 4045752  |
---------------------------------
Eval num_timesteps=4047744, episode_reward=810.96 +/- 373.01
Episode length: 491.20 +/- 18.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 811      |
| time/              |          |
|    total_timesteps | 4047744  |
---------------------------------
Eval num_timesteps=4049736, episode_reward=981.30 +/- 419.54
Episode length: 550.80 +/- 52.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 551      |
|    mean_reward     | 981      |
| time/              |          |
|    total_timesteps | 4049736  |
---------------------------------
Eval num_timesteps=4051728, episode_reward=597.25 +/- 114.67
Episode length: 552.40 +/- 83.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 597      |
| time/              |          |
|    total_timesteps | 4051728  |
---------------------------------
Eval num_timesteps=4053720, episode_reward=624.28 +/- 238.23
Episode length: 482.20 +/- 55.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 4053720  |
---------------------------------
Eval num_timesteps=4055712, episode_reward=632.72 +/- 100.27
Episode length: 515.20 +/- 29.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 515      |
|    mean_reward     | 633      |
| time/              |          |
|    total_timesteps | 4055712  |
---------------------------------
Eval num_timesteps=4057704, episode_reward=838.61 +/- 382.05
Episode length: 478.20 +/- 20.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | 839      |
| time/              |          |
|    total_timesteps | 4057704  |
---------------------------------
Eval num_timesteps=4059696, episode_reward=616.87 +/- 82.16
Episode length: 528.60 +/- 50.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 617      |
| time/              |          |
|    total_timesteps | 4059696  |
---------------------------------
Eval num_timesteps=4061688, episode_reward=827.97 +/- 528.76
Episode length: 466.40 +/- 40.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 466      |
|    mean_reward     | 828      |
| time/              |          |
|    total_timesteps | 4061688  |
---------------------------------
Eval num_timesteps=4063680, episode_reward=742.84 +/- 306.62
Episode length: 554.80 +/- 51.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 743      |
| time/              |          |
|    total_timesteps | 4063680  |
---------------------------------
Eval num_timesteps=4065672, episode_reward=551.57 +/- 129.61
Episode length: 516.40 +/- 39.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 552      |
| time/              |          |
|    total_timesteps | 4065672  |
---------------------------------
Eval num_timesteps=4067664, episode_reward=851.91 +/- 489.86
Episode length: 534.60 +/- 45.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 852      |
| time/              |          |
|    total_timesteps | 4067664  |
---------------------------------
Eval num_timesteps=4069656, episode_reward=888.72 +/- 386.43
Episode length: 544.00 +/- 68.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 889      |
| time/              |          |
|    total_timesteps | 4069656  |
---------------------------------
Eval num_timesteps=4071648, episode_reward=827.68 +/- 359.55
Episode length: 563.00 +/- 94.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | 828      |
| time/              |          |
|    total_timesteps | 4071648  |
---------------------------------
Eval num_timesteps=4073640, episode_reward=408.59 +/- 331.54
Episode length: 448.00 +/- 77.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | 409      |
| time/              |          |
|    total_timesteps | 4073640  |
---------------------------------
Eval num_timesteps=4075632, episode_reward=614.02 +/- 224.61
Episode length: 486.60 +/- 38.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 487      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 4075632  |
---------------------------------
Eval num_timesteps=4077624, episode_reward=701.14 +/- 283.52
Episode length: 494.80 +/- 67.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | 701      |
| time/              |          |
|    total_timesteps | 4077624  |
---------------------------------
Eval num_timesteps=4079616, episode_reward=877.50 +/- 415.37
Episode length: 478.60 +/- 25.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 479      |
|    mean_reward     | 878      |
| time/              |          |
|    total_timesteps | 4079616  |
---------------------------------
Eval num_timesteps=4081608, episode_reward=721.90 +/- 488.75
Episode length: 596.00 +/- 58.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 596          |
|    mean_reward          | 722          |
| time/                   |              |
|    total_timesteps      | 4081608      |
| train/                  |              |
|    approx_kl            | 0.0063306987 |
|    clip_fraction        | 0.0531       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.16        |
|    explained_variance   | 0.978        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0381      |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.0014      |
|    std                  | 1.46         |
|    value_loss           | 0.0781       |
------------------------------------------
Eval num_timesteps=4083600, episode_reward=761.68 +/- 181.31
Episode length: 506.60 +/- 57.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 762      |
| time/              |          |
|    total_timesteps | 4083600  |
---------------------------------
Eval num_timesteps=4085592, episode_reward=738.67 +/- 109.49
Episode length: 495.00 +/- 31.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 4085592  |
---------------------------------
Eval num_timesteps=4087584, episode_reward=599.00 +/- 54.87
Episode length: 618.60 +/- 73.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 599      |
| time/              |          |
|    total_timesteps | 4087584  |
---------------------------------
Eval num_timesteps=4089576, episode_reward=861.87 +/- 353.83
Episode length: 532.60 +/- 34.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 862      |
| time/              |          |
|    total_timesteps | 4089576  |
---------------------------------
Eval num_timesteps=4091568, episode_reward=788.99 +/- 276.15
Episode length: 574.00 +/- 40.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | 789      |
| time/              |          |
|    total_timesteps | 4091568  |
---------------------------------
Eval num_timesteps=4093560, episode_reward=765.00 +/- 307.72
Episode length: 567.80 +/- 38.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 765      |
| time/              |          |
|    total_timesteps | 4093560  |
---------------------------------
Eval num_timesteps=4095552, episode_reward=520.35 +/- 142.69
Episode length: 576.00 +/- 122.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 520      |
| time/              |          |
|    total_timesteps | 4095552  |
---------------------------------
Eval num_timesteps=4097544, episode_reward=761.99 +/- 331.12
Episode length: 497.40 +/- 23.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 497      |
|    mean_reward     | 762      |
| time/              |          |
|    total_timesteps | 4097544  |
---------------------------------
Eval num_timesteps=4099536, episode_reward=711.05 +/- 326.82
Episode length: 537.40 +/- 49.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 711      |
| time/              |          |
|    total_timesteps | 4099536  |
---------------------------------
Eval num_timesteps=4101528, episode_reward=949.24 +/- 342.93
Episode length: 522.00 +/- 45.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 949      |
| time/              |          |
|    total_timesteps | 4101528  |
---------------------------------
Eval num_timesteps=4103520, episode_reward=950.02 +/- 343.99
Episode length: 496.40 +/- 48.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 496      |
|    mean_reward     | 950      |
| time/              |          |
|    total_timesteps | 4103520  |
---------------------------------
Eval num_timesteps=4105512, episode_reward=636.29 +/- 130.69
Episode length: 511.80 +/- 24.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 4105512  |
---------------------------------
Eval num_timesteps=4107504, episode_reward=765.82 +/- 516.29
Episode length: 532.20 +/- 64.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 766      |
| time/              |          |
|    total_timesteps | 4107504  |
---------------------------------
Eval num_timesteps=4109496, episode_reward=684.46 +/- 139.72
Episode length: 512.00 +/- 54.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 684      |
| time/              |          |
|    total_timesteps | 4109496  |
---------------------------------
Eval num_timesteps=4111488, episode_reward=968.20 +/- 332.08
Episode length: 574.00 +/- 72.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 574      |
|    mean_reward     | 968      |
| time/              |          |
|    total_timesteps | 4111488  |
---------------------------------
Eval num_timesteps=4113480, episode_reward=819.82 +/- 385.74
Episode length: 491.20 +/- 57.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 491      |
|    mean_reward     | 820      |
| time/              |          |
|    total_timesteps | 4113480  |
---------------------------------
Eval num_timesteps=4115472, episode_reward=927.48 +/- 274.68
Episode length: 545.00 +/- 89.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 927      |
| time/              |          |
|    total_timesteps | 4115472  |
---------------------------------
Eval num_timesteps=4117464, episode_reward=747.27 +/- 391.42
Episode length: 518.80 +/- 91.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 747      |
| time/              |          |
|    total_timesteps | 4117464  |
---------------------------------
Eval num_timesteps=4119456, episode_reward=673.88 +/- 298.52
Episode length: 536.60 +/- 42.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 4119456  |
---------------------------------
Eval num_timesteps=4121448, episode_reward=1172.07 +/- 474.08
Episode length: 521.40 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | 1.17e+03 |
| time/              |          |
|    total_timesteps | 4121448  |
---------------------------------
Eval num_timesteps=4123440, episode_reward=673.08 +/- 297.32
Episode length: 559.20 +/- 108.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 4123440  |
---------------------------------
Eval num_timesteps=4125432, episode_reward=749.51 +/- 391.75
Episode length: 553.60 +/- 64.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 750      |
| time/              |          |
|    total_timesteps | 4125432  |
---------------------------------
Eval num_timesteps=4127424, episode_reward=946.25 +/- 293.81
Episode length: 527.80 +/- 41.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 946      |
| time/              |          |
|    total_timesteps | 4127424  |
---------------------------------
Eval num_timesteps=4129416, episode_reward=946.88 +/- 374.48
Episode length: 576.80 +/- 36.36
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 577          |
|    mean_reward          | 947          |
| time/                   |              |
|    total_timesteps      | 4129416      |
| train/                  |              |
|    approx_kl            | 0.0060296087 |
|    clip_fraction        | 0.0462       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.19        |
|    explained_variance   | 0.974        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0269      |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 1.47         |
|    value_loss           | 0.101        |
------------------------------------------
Eval num_timesteps=4131408, episode_reward=583.02 +/- 94.30
Episode length: 544.00 +/- 61.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 583      |
| time/              |          |
|    total_timesteps | 4131408  |
---------------------------------
Eval num_timesteps=4133400, episode_reward=976.57 +/- 459.95
Episode length: 598.20 +/- 70.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 598      |
|    mean_reward     | 977      |
| time/              |          |
|    total_timesteps | 4133400  |
---------------------------------
Eval num_timesteps=4135392, episode_reward=690.28 +/- 93.26
Episode length: 516.80 +/- 56.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 517      |
|    mean_reward     | 690      |
| time/              |          |
|    total_timesteps | 4135392  |
---------------------------------
Eval num_timesteps=4137384, episode_reward=990.04 +/- 406.58
Episode length: 493.60 +/- 67.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 990      |
| time/              |          |
|    total_timesteps | 4137384  |
---------------------------------
Eval num_timesteps=4139376, episode_reward=863.63 +/- 383.85
Episode length: 568.80 +/- 85.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 864      |
| time/              |          |
|    total_timesteps | 4139376  |
---------------------------------
Eval num_timesteps=4141368, episode_reward=772.21 +/- 184.11
Episode length: 537.00 +/- 63.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 772      |
| time/              |          |
|    total_timesteps | 4141368  |
---------------------------------
Eval num_timesteps=4143360, episode_reward=933.09 +/- 250.86
Episode length: 584.40 +/- 104.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 584      |
|    mean_reward     | 933      |
| time/              |          |
|    total_timesteps | 4143360  |
---------------------------------
Eval num_timesteps=4145352, episode_reward=929.94 +/- 418.16
Episode length: 587.00 +/- 86.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 930      |
| time/              |          |
|    total_timesteps | 4145352  |
---------------------------------
Eval num_timesteps=4147344, episode_reward=967.26 +/- 400.55
Episode length: 521.60 +/- 68.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 967      |
| time/              |          |
|    total_timesteps | 4147344  |
---------------------------------
Eval num_timesteps=4149336, episode_reward=734.21 +/- 210.08
Episode length: 607.60 +/- 105.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | 734      |
| time/              |          |
|    total_timesteps | 4149336  |
---------------------------------
Eval num_timesteps=4151328, episode_reward=969.51 +/- 367.58
Episode length: 562.20 +/- 48.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 970      |
| time/              |          |
|    total_timesteps | 4151328  |
---------------------------------
Eval num_timesteps=4153320, episode_reward=885.00 +/- 381.59
Episode length: 573.20 +/- 88.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 885      |
| time/              |          |
|    total_timesteps | 4153320  |
---------------------------------
Eval num_timesteps=4155312, episode_reward=1100.73 +/- 363.46
Episode length: 519.60 +/- 51.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 4155312  |
---------------------------------
Eval num_timesteps=4157304, episode_reward=714.87 +/- 73.46
Episode length: 641.80 +/- 124.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 642      |
|    mean_reward     | 715      |
| time/              |          |
|    total_timesteps | 4157304  |
---------------------------------
Eval num_timesteps=4159296, episode_reward=719.78 +/- 203.40
Episode length: 520.80 +/- 25.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | 720      |
| time/              |          |
|    total_timesteps | 4159296  |
---------------------------------
Eval num_timesteps=4161288, episode_reward=915.00 +/- 613.39
Episode length: 563.20 +/- 66.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | 915      |
| time/              |          |
|    total_timesteps | 4161288  |
---------------------------------
Eval num_timesteps=4163280, episode_reward=605.49 +/- 102.23
Episode length: 509.00 +/- 50.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 509      |
|    mean_reward     | 605      |
| time/              |          |
|    total_timesteps | 4163280  |
---------------------------------
Eval num_timesteps=4165272, episode_reward=579.90 +/- 175.21
Episode length: 602.60 +/- 141.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 4165272  |
---------------------------------
Eval num_timesteps=4167264, episode_reward=825.27 +/- 453.88
Episode length: 624.60 +/- 41.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 825      |
| time/              |          |
|    total_timesteps | 4167264  |
---------------------------------
Eval num_timesteps=4169256, episode_reward=784.96 +/- 304.71
Episode length: 534.40 +/- 43.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 785      |
| time/              |          |
|    total_timesteps | 4169256  |
---------------------------------
Eval num_timesteps=4171248, episode_reward=634.62 +/- 284.65
Episode length: 516.40 +/- 23.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 635      |
| time/              |          |
|    total_timesteps | 4171248  |
---------------------------------
Eval num_timesteps=4173240, episode_reward=667.16 +/- 472.55
Episode length: 544.20 +/- 93.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 667      |
| time/              |          |
|    total_timesteps | 4173240  |
---------------------------------
Eval num_timesteps=4175232, episode_reward=561.95 +/- 177.32
Episode length: 546.00 +/- 76.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 546      |
|    mean_reward     | 562      |
| time/              |          |
|    total_timesteps | 4175232  |
---------------------------------
Eval num_timesteps=4177224, episode_reward=730.92 +/- 138.00
Episode length: 608.20 +/- 126.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 608      |
|    mean_reward     | 731      |
| time/              |          |
|    total_timesteps | 4177224  |
---------------------------------
Eval num_timesteps=4179216, episode_reward=750.53 +/- 187.55
Episode length: 528.60 +/- 25.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 529        |
|    mean_reward          | 751        |
| time/                   |            |
|    total_timesteps      | 4179216    |
| train/                  |            |
|    approx_kl            | 0.00448356 |
|    clip_fraction        | 0.063      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0248    |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.0014    |
|    std                  | 1.47       |
|    value_loss           | 0.107      |
----------------------------------------
Eval num_timesteps=4181208, episode_reward=734.76 +/- 309.64
Episode length: 591.60 +/- 81.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 735      |
| time/              |          |
|    total_timesteps | 4181208  |
---------------------------------
Eval num_timesteps=4183200, episode_reward=598.83 +/- 141.96
Episode length: 576.20 +/- 71.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 599      |
| time/              |          |
|    total_timesteps | 4183200  |
---------------------------------
Eval num_timesteps=4185192, episode_reward=1010.23 +/- 346.34
Episode length: 533.00 +/- 59.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 533      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4185192  |
---------------------------------
Eval num_timesteps=4187184, episode_reward=791.20 +/- 383.50
Episode length: 554.40 +/- 82.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 791      |
| time/              |          |
|    total_timesteps | 4187184  |
---------------------------------
Eval num_timesteps=4189176, episode_reward=599.53 +/- 242.32
Episode length: 513.00 +/- 93.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 600      |
| time/              |          |
|    total_timesteps | 4189176  |
---------------------------------
Eval num_timesteps=4191168, episode_reward=969.85 +/- 546.06
Episode length: 585.20 +/- 64.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 970      |
| time/              |          |
|    total_timesteps | 4191168  |
---------------------------------
Eval num_timesteps=4193160, episode_reward=794.67 +/- 445.00
Episode length: 544.40 +/- 83.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 795      |
| time/              |          |
|    total_timesteps | 4193160  |
---------------------------------
Eval num_timesteps=4195152, episode_reward=719.06 +/- 328.46
Episode length: 516.20 +/- 81.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 719      |
| time/              |          |
|    total_timesteps | 4195152  |
---------------------------------
Eval num_timesteps=4197144, episode_reward=646.29 +/- 178.02
Episode length: 612.00 +/- 179.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 4197144  |
---------------------------------
Eval num_timesteps=4199136, episode_reward=701.34 +/- 166.98
Episode length: 583.20 +/- 39.91
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 701      |
| time/              |          |
|    total_timesteps | 4199136  |
---------------------------------
Eval num_timesteps=4201128, episode_reward=643.05 +/- 196.01
Episode length: 534.60 +/- 42.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 643      |
| time/              |          |
|    total_timesteps | 4201128  |
---------------------------------
Eval num_timesteps=4203120, episode_reward=940.23 +/- 319.76
Episode length: 549.20 +/- 33.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 940      |
| time/              |          |
|    total_timesteps | 4203120  |
---------------------------------
Eval num_timesteps=4205112, episode_reward=615.82 +/- 87.81
Episode length: 514.00 +/- 92.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 616      |
| time/              |          |
|    total_timesteps | 4205112  |
---------------------------------
Eval num_timesteps=4207104, episode_reward=1015.56 +/- 582.06
Episode length: 552.40 +/- 23.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 552      |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 4207104  |
---------------------------------
Eval num_timesteps=4209096, episode_reward=826.66 +/- 472.57
Episode length: 473.40 +/- 81.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 473      |
|    mean_reward     | 827      |
| time/              |          |
|    total_timesteps | 4209096  |
---------------------------------
Eval num_timesteps=4211088, episode_reward=762.31 +/- 162.04
Episode length: 590.80 +/- 78.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 762      |
| time/              |          |
|    total_timesteps | 4211088  |
---------------------------------
Eval num_timesteps=4213080, episode_reward=453.55 +/- 135.13
Episode length: 526.00 +/- 58.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 454      |
| time/              |          |
|    total_timesteps | 4213080  |
---------------------------------
Eval num_timesteps=4215072, episode_reward=696.88 +/- 145.26
Episode length: 499.20 +/- 46.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 499      |
|    mean_reward     | 697      |
| time/              |          |
|    total_timesteps | 4215072  |
---------------------------------
Eval num_timesteps=4217064, episode_reward=474.57 +/- 248.34
Episode length: 454.60 +/- 92.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 475      |
| time/              |          |
|    total_timesteps | 4217064  |
---------------------------------
Eval num_timesteps=4219056, episode_reward=861.88 +/- 302.10
Episode length: 545.20 +/- 47.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 862      |
| time/              |          |
|    total_timesteps | 4219056  |
---------------------------------
Eval num_timesteps=4221048, episode_reward=774.17 +/- 260.73
Episode length: 677.60 +/- 124.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 678      |
|    mean_reward     | 774      |
| time/              |          |
|    total_timesteps | 4221048  |
---------------------------------
Eval num_timesteps=4223040, episode_reward=801.00 +/- 110.84
Episode length: 522.20 +/- 57.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 801      |
| time/              |          |
|    total_timesteps | 4223040  |
---------------------------------
Eval num_timesteps=4225032, episode_reward=749.58 +/- 157.70
Episode length: 525.80 +/- 67.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 750      |
| time/              |          |
|    total_timesteps | 4225032  |
---------------------------------
Eval num_timesteps=4227024, episode_reward=938.85 +/- 464.92
Episode length: 506.00 +/- 42.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 506      |
|    mean_reward     | 939      |
| time/              |          |
|    total_timesteps | 4227024  |
---------------------------------
Eval num_timesteps=4229016, episode_reward=607.49 +/- 187.05
Episode length: 594.80 +/- 81.09
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 595         |
|    mean_reward          | 607         |
| time/                   |             |
|    total_timesteps      | 4229016     |
| train/                  |             |
|    approx_kl            | 0.004843709 |
|    clip_fraction        | 0.0589      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0286     |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00171    |
|    std                  | 1.48        |
|    value_loss           | 0.0996      |
-----------------------------------------
Eval num_timesteps=4231008, episode_reward=842.60 +/- 328.32
Episode length: 518.00 +/- 61.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 518      |
|    mean_reward     | 843      |
| time/              |          |
|    total_timesteps | 4231008  |
---------------------------------
Eval num_timesteps=4233000, episode_reward=993.12 +/- 409.31
Episode length: 546.80 +/- 116.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 993      |
| time/              |          |
|    total_timesteps | 4233000  |
---------------------------------
Eval num_timesteps=4234992, episode_reward=846.23 +/- 63.34
Episode length: 634.80 +/- 179.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 846      |
| time/              |          |
|    total_timesteps | 4234992  |
---------------------------------
Eval num_timesteps=4236984, episode_reward=957.71 +/- 247.52
Episode length: 584.80 +/- 51.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 958      |
| time/              |          |
|    total_timesteps | 4236984  |
---------------------------------
Eval num_timesteps=4238976, episode_reward=726.80 +/- 61.64
Episode length: 587.20 +/- 77.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 4238976  |
---------------------------------
Eval num_timesteps=4240968, episode_reward=827.98 +/- 258.59
Episode length: 572.80 +/- 62.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 828      |
| time/              |          |
|    total_timesteps | 4240968  |
---------------------------------
Eval num_timesteps=4242960, episode_reward=825.89 +/- 172.38
Episode length: 514.40 +/- 63.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 826      |
| time/              |          |
|    total_timesteps | 4242960  |
---------------------------------
Eval num_timesteps=4244952, episode_reward=713.53 +/- 344.99
Episode length: 550.40 +/- 150.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 714      |
| time/              |          |
|    total_timesteps | 4244952  |
---------------------------------
Eval num_timesteps=4246944, episode_reward=689.30 +/- 258.96
Episode length: 545.00 +/- 61.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 689      |
| time/              |          |
|    total_timesteps | 4246944  |
---------------------------------
Eval num_timesteps=4248936, episode_reward=812.89 +/- 282.08
Episode length: 531.00 +/- 16.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 813      |
| time/              |          |
|    total_timesteps | 4248936  |
---------------------------------
Eval num_timesteps=4250928, episode_reward=754.22 +/- 242.61
Episode length: 559.80 +/- 83.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | 754      |
| time/              |          |
|    total_timesteps | 4250928  |
---------------------------------
Eval num_timesteps=4252920, episode_reward=792.14 +/- 135.14
Episode length: 559.40 +/- 94.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 792      |
| time/              |          |
|    total_timesteps | 4252920  |
---------------------------------
Eval num_timesteps=4254912, episode_reward=805.08 +/- 184.72
Episode length: 627.40 +/- 47.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 805      |
| time/              |          |
|    total_timesteps | 4254912  |
---------------------------------
Eval num_timesteps=4256904, episode_reward=1113.21 +/- 493.17
Episode length: 548.20 +/- 74.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 4256904  |
---------------------------------
Eval num_timesteps=4258896, episode_reward=637.79 +/- 42.80
Episode length: 685.60 +/- 187.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 638      |
| time/              |          |
|    total_timesteps | 4258896  |
---------------------------------
Eval num_timesteps=4260888, episode_reward=1011.26 +/- 270.06
Episode length: 562.20 +/- 65.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4260888  |
---------------------------------
Eval num_timesteps=4262880, episode_reward=462.69 +/- 219.63
Episode length: 518.60 +/- 109.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 463      |
| time/              |          |
|    total_timesteps | 4262880  |
---------------------------------
Eval num_timesteps=4264872, episode_reward=928.41 +/- 356.44
Episode length: 636.60 +/- 261.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | 928      |
| time/              |          |
|    total_timesteps | 4264872  |
---------------------------------
Eval num_timesteps=4266864, episode_reward=898.30 +/- 286.12
Episode length: 562.80 +/- 43.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | 898      |
| time/              |          |
|    total_timesteps | 4266864  |
---------------------------------
Eval num_timesteps=4268856, episode_reward=678.84 +/- 82.75
Episode length: 593.40 +/- 43.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 593      |
|    mean_reward     | 679      |
| time/              |          |
|    total_timesteps | 4268856  |
---------------------------------
Eval num_timesteps=4270848, episode_reward=970.91 +/- 164.79
Episode length: 482.00 +/- 32.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 971      |
| time/              |          |
|    total_timesteps | 4270848  |
---------------------------------
Eval num_timesteps=4272840, episode_reward=888.69 +/- 291.46
Episode length: 567.40 +/- 54.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 567      |
|    mean_reward     | 889      |
| time/              |          |
|    total_timesteps | 4272840  |
---------------------------------
Eval num_timesteps=4274832, episode_reward=1077.15 +/- 500.49
Episode length: 783.20 +/- 263.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 783      |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 4274832  |
---------------------------------
Eval num_timesteps=4276824, episode_reward=978.92 +/- 338.03
Episode length: 547.40 +/- 54.77
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 547          |
|    mean_reward          | 979          |
| time/                   |              |
|    total_timesteps      | 4276824      |
| train/                  |              |
|    approx_kl            | 0.0073278844 |
|    clip_fraction        | 0.0533       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.26        |
|    explained_variance   | 0.968        |
|    learning_rate        | 0.001        |
|    loss                 | -0.019       |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00138     |
|    std                  | 1.49         |
|    value_loss           | 0.127        |
------------------------------------------
Eval num_timesteps=4278816, episode_reward=1087.36 +/- 335.42
Episode length: 556.20 +/- 74.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 4278816  |
---------------------------------
Eval num_timesteps=4280808, episode_reward=696.90 +/- 79.05
Episode length: 796.80 +/- 165.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 797      |
|    mean_reward     | 697      |
| time/              |          |
|    total_timesteps | 4280808  |
---------------------------------
Eval num_timesteps=4282800, episode_reward=1035.24 +/- 307.19
Episode length: 618.60 +/- 162.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 4282800  |
---------------------------------
Eval num_timesteps=4284792, episode_reward=938.35 +/- 421.29
Episode length: 655.40 +/- 105.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 655      |
|    mean_reward     | 938      |
| time/              |          |
|    total_timesteps | 4284792  |
---------------------------------
Eval num_timesteps=4286784, episode_reward=761.19 +/- 195.03
Episode length: 570.60 +/- 102.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 761      |
| time/              |          |
|    total_timesteps | 4286784  |
---------------------------------
Eval num_timesteps=4288776, episode_reward=1080.42 +/- 557.80
Episode length: 531.20 +/- 58.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 4288776  |
---------------------------------
Eval num_timesteps=4290768, episode_reward=877.54 +/- 264.07
Episode length: 676.20 +/- 126.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 676      |
|    mean_reward     | 878      |
| time/              |          |
|    total_timesteps | 4290768  |
---------------------------------
Eval num_timesteps=4292760, episode_reward=649.35 +/- 63.38
Episode length: 609.40 +/- 73.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 649      |
| time/              |          |
|    total_timesteps | 4292760  |
---------------------------------
Eval num_timesteps=4294752, episode_reward=706.02 +/- 487.31
Episode length: 587.00 +/- 185.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 706      |
| time/              |          |
|    total_timesteps | 4294752  |
---------------------------------
Eval num_timesteps=4296744, episode_reward=838.23 +/- 375.45
Episode length: 464.20 +/- 26.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 464      |
|    mean_reward     | 838      |
| time/              |          |
|    total_timesteps | 4296744  |
---------------------------------
Eval num_timesteps=4298736, episode_reward=1183.15 +/- 525.31
Episode length: 547.80 +/- 90.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 548      |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 4298736  |
---------------------------------
Eval num_timesteps=4300728, episode_reward=948.39 +/- 470.14
Episode length: 614.80 +/- 278.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 948      |
| time/              |          |
|    total_timesteps | 4300728  |
---------------------------------
Eval num_timesteps=4302720, episode_reward=908.47 +/- 454.74
Episode length: 530.20 +/- 78.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 908      |
| time/              |          |
|    total_timesteps | 4302720  |
---------------------------------
Eval num_timesteps=4304712, episode_reward=1426.78 +/- 319.65
Episode length: 647.20 +/- 237.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 647      |
|    mean_reward     | 1.43e+03 |
| time/              |          |
|    total_timesteps | 4304712  |
---------------------------------
Eval num_timesteps=4306704, episode_reward=893.29 +/- 215.91
Episode length: 580.60 +/- 71.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | 893      |
| time/              |          |
|    total_timesteps | 4306704  |
---------------------------------
Eval num_timesteps=4308696, episode_reward=901.64 +/- 248.56
Episode length: 545.40 +/- 44.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 545      |
|    mean_reward     | 902      |
| time/              |          |
|    total_timesteps | 4308696  |
---------------------------------
Eval num_timesteps=4310688, episode_reward=829.78 +/- 182.62
Episode length: 523.00 +/- 94.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 523      |
|    mean_reward     | 830      |
| time/              |          |
|    total_timesteps | 4310688  |
---------------------------------
Eval num_timesteps=4312680, episode_reward=600.61 +/- 104.88
Episode length: 549.20 +/- 143.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 4312680  |
---------------------------------
Eval num_timesteps=4314672, episode_reward=941.59 +/- 252.58
Episode length: 589.80 +/- 75.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 590      |
|    mean_reward     | 942      |
| time/              |          |
|    total_timesteps | 4314672  |
---------------------------------
Eval num_timesteps=4316664, episode_reward=814.88 +/- 224.28
Episode length: 630.20 +/- 172.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 815      |
| time/              |          |
|    total_timesteps | 4316664  |
---------------------------------
Eval num_timesteps=4318656, episode_reward=871.91 +/- 412.15
Episode length: 486.20 +/- 90.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 4318656  |
---------------------------------
Eval num_timesteps=4320648, episode_reward=976.60 +/- 432.30
Episode length: 543.80 +/- 66.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 977      |
| time/              |          |
|    total_timesteps | 4320648  |
---------------------------------
Eval num_timesteps=4322640, episode_reward=1007.35 +/- 257.94
Episode length: 595.40 +/- 65.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4322640  |
---------------------------------
Eval num_timesteps=4324632, episode_reward=1070.58 +/- 94.73
Episode length: 673.80 +/- 179.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 674      |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 4324632  |
---------------------------------
Eval num_timesteps=4326624, episode_reward=816.91 +/- 274.03
Episode length: 614.20 +/- 79.10
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 614          |
|    mean_reward          | 817          |
| time/                   |              |
|    total_timesteps      | 4326624      |
| train/                  |              |
|    approx_kl            | 0.0070972024 |
|    clip_fraction        | 0.0488       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.29        |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0156      |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00188     |
|    std                  | 1.5          |
|    value_loss           | 0.13         |
------------------------------------------
Eval num_timesteps=4328616, episode_reward=753.37 +/- 114.65
Episode length: 833.20 +/- 235.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 833      |
|    mean_reward     | 753      |
| time/              |          |
|    total_timesteps | 4328616  |
---------------------------------
Eval num_timesteps=4330608, episode_reward=815.50 +/- 270.64
Episode length: 636.40 +/- 100.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 636      |
|    mean_reward     | 815      |
| time/              |          |
|    total_timesteps | 4330608  |
---------------------------------
Eval num_timesteps=4332600, episode_reward=950.18 +/- 219.16
Episode length: 614.00 +/- 102.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 950      |
| time/              |          |
|    total_timesteps | 4332600  |
---------------------------------
Eval num_timesteps=4334592, episode_reward=1055.07 +/- 509.94
Episode length: 592.60 +/- 51.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 593      |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 4334592  |
---------------------------------
Eval num_timesteps=4336584, episode_reward=722.54 +/- 148.36
Episode length: 651.60 +/- 85.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 652      |
|    mean_reward     | 723      |
| time/              |          |
|    total_timesteps | 4336584  |
---------------------------------
Eval num_timesteps=4338576, episode_reward=691.19 +/- 40.23
Episode length: 652.80 +/- 30.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 653      |
|    mean_reward     | 691      |
| time/              |          |
|    total_timesteps | 4338576  |
---------------------------------
Eval num_timesteps=4340568, episode_reward=979.80 +/- 306.19
Episode length: 628.20 +/- 56.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 980      |
| time/              |          |
|    total_timesteps | 4340568  |
---------------------------------
Eval num_timesteps=4342560, episode_reward=824.98 +/- 236.95
Episode length: 554.00 +/- 49.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 825      |
| time/              |          |
|    total_timesteps | 4342560  |
---------------------------------
Eval num_timesteps=4344552, episode_reward=976.20 +/- 376.73
Episode length: 541.00 +/- 72.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 976      |
| time/              |          |
|    total_timesteps | 4344552  |
---------------------------------
Eval num_timesteps=4346544, episode_reward=777.08 +/- 228.72
Episode length: 568.60 +/- 68.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 777      |
| time/              |          |
|    total_timesteps | 4346544  |
---------------------------------
Eval num_timesteps=4348536, episode_reward=737.21 +/- 134.64
Episode length: 603.40 +/- 60.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | 737      |
| time/              |          |
|    total_timesteps | 4348536  |
---------------------------------
Eval num_timesteps=4350528, episode_reward=756.28 +/- 259.46
Episode length: 540.60 +/- 45.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 541      |
|    mean_reward     | 756      |
| time/              |          |
|    total_timesteps | 4350528  |
---------------------------------
Eval num_timesteps=4352520, episode_reward=944.06 +/- 237.70
Episode length: 701.60 +/- 148.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | 944      |
| time/              |          |
|    total_timesteps | 4352520  |
---------------------------------
Eval num_timesteps=4354512, episode_reward=1040.92 +/- 388.70
Episode length: 582.00 +/- 170.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 582      |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 4354512  |
---------------------------------
Eval num_timesteps=4356504, episode_reward=889.77 +/- 553.35
Episode length: 630.60 +/- 110.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 890      |
| time/              |          |
|    total_timesteps | 4356504  |
---------------------------------
Eval num_timesteps=4358496, episode_reward=965.14 +/- 295.07
Episode length: 730.80 +/- 163.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 731      |
|    mean_reward     | 965      |
| time/              |          |
|    total_timesteps | 4358496  |
---------------------------------
Eval num_timesteps=4360488, episode_reward=1115.64 +/- 1064.77
Episode length: 657.00 +/- 151.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 657      |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 4360488  |
---------------------------------
Eval num_timesteps=4362480, episode_reward=945.48 +/- 244.69
Episode length: 745.20 +/- 128.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 745      |
|    mean_reward     | 945      |
| time/              |          |
|    total_timesteps | 4362480  |
---------------------------------
Eval num_timesteps=4364472, episode_reward=1053.83 +/- 416.26
Episode length: 612.60 +/- 68.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 1.05e+03 |
| time/              |          |
|    total_timesteps | 4364472  |
---------------------------------
Eval num_timesteps=4366464, episode_reward=951.04 +/- 640.80
Episode length: 562.20 +/- 67.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 951      |
| time/              |          |
|    total_timesteps | 4366464  |
---------------------------------
Eval num_timesteps=4368456, episode_reward=1076.44 +/- 509.24
Episode length: 649.60 +/- 258.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 650      |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 4368456  |
---------------------------------
Eval num_timesteps=4370448, episode_reward=780.40 +/- 206.70
Episode length: 626.20 +/- 180.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 626      |
|    mean_reward     | 780      |
| time/              |          |
|    total_timesteps | 4370448  |
---------------------------------
Eval num_timesteps=4372440, episode_reward=751.81 +/- 139.05
Episode length: 575.80 +/- 52.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 752      |
| time/              |          |
|    total_timesteps | 4372440  |
---------------------------------
Eval num_timesteps=4374432, episode_reward=1105.72 +/- 598.68
Episode length: 618.00 +/- 96.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 618      |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 4374432  |
---------------------------------
Eval num_timesteps=4376424, episode_reward=699.45 +/- 79.43
Episode length: 711.00 +/- 143.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 711         |
|    mean_reward          | 699         |
| time/                   |             |
|    total_timesteps      | 4376424     |
| train/                  |             |
|    approx_kl            | 0.006894003 |
|    clip_fraction        | 0.0447      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0203     |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00187    |
|    std                  | 1.51        |
|    value_loss           | 0.121       |
-----------------------------------------
Eval num_timesteps=4378416, episode_reward=650.40 +/- 47.80
Episode length: 681.00 +/- 149.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 681      |
|    mean_reward     | 650      |
| time/              |          |
|    total_timesteps | 4378416  |
---------------------------------
Eval num_timesteps=4380408, episode_reward=1029.19 +/- 463.92
Episode length: 699.60 +/- 111.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 4380408  |
---------------------------------
Eval num_timesteps=4382400, episode_reward=1131.98 +/- 502.20
Episode length: 712.20 +/- 82.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 712      |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 4382400  |
---------------------------------
Eval num_timesteps=4384392, episode_reward=659.67 +/- 48.49
Episode length: 606.20 +/- 101.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | 660      |
| time/              |          |
|    total_timesteps | 4384392  |
---------------------------------
Eval num_timesteps=4386384, episode_reward=746.78 +/- 126.69
Episode length: 697.00 +/- 144.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | 747      |
| time/              |          |
|    total_timesteps | 4386384  |
---------------------------------
Eval num_timesteps=4388376, episode_reward=899.97 +/- 391.32
Episode length: 678.00 +/- 112.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 678      |
|    mean_reward     | 900      |
| time/              |          |
|    total_timesteps | 4388376  |
---------------------------------
Eval num_timesteps=4390368, episode_reward=683.32 +/- 193.94
Episode length: 713.20 +/- 155.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 713      |
|    mean_reward     | 683      |
| time/              |          |
|    total_timesteps | 4390368  |
---------------------------------
Eval num_timesteps=4392360, episode_reward=827.16 +/- 320.65
Episode length: 849.60 +/- 176.55
---------------------------------
| eval/              |          |
|    mean_ep_length  | 850      |
|    mean_reward     | 827      |
| time/              |          |
|    total_timesteps | 4392360  |
---------------------------------
Eval num_timesteps=4394352, episode_reward=672.44 +/- 103.65
Episode length: 629.80 +/- 74.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 672      |
| time/              |          |
|    total_timesteps | 4394352  |
---------------------------------
Eval num_timesteps=4396344, episode_reward=633.05 +/- 29.71
Episode length: 575.80 +/- 27.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 633      |
| time/              |          |
|    total_timesteps | 4396344  |
---------------------------------
Eval num_timesteps=4398336, episode_reward=1017.50 +/- 392.81
Episode length: 736.00 +/- 109.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 736      |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 4398336  |
---------------------------------
Eval num_timesteps=4400328, episode_reward=941.20 +/- 347.47
Episode length: 633.80 +/- 97.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 634      |
|    mean_reward     | 941      |
| time/              |          |
|    total_timesteps | 4400328  |
---------------------------------
Eval num_timesteps=4402320, episode_reward=818.85 +/- 262.71
Episode length: 609.00 +/- 103.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 819      |
| time/              |          |
|    total_timesteps | 4402320  |
---------------------------------
Eval num_timesteps=4404312, episode_reward=1017.46 +/- 566.19
Episode length: 630.60 +/- 131.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 4404312  |
---------------------------------
Eval num_timesteps=4406304, episode_reward=720.83 +/- 78.80
Episode length: 676.40 +/- 69.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 676      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 4406304  |
---------------------------------
Eval num_timesteps=4408296, episode_reward=984.48 +/- 573.38
Episode length: 713.00 +/- 152.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 713      |
|    mean_reward     | 984      |
| time/              |          |
|    total_timesteps | 4408296  |
---------------------------------
Eval num_timesteps=4410288, episode_reward=800.82 +/- 148.19
Episode length: 608.80 +/- 80.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 801      |
| time/              |          |
|    total_timesteps | 4410288  |
---------------------------------
Eval num_timesteps=4412280, episode_reward=749.31 +/- 103.71
Episode length: 715.80 +/- 149.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 716      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 4412280  |
---------------------------------
Eval num_timesteps=4414272, episode_reward=713.15 +/- 165.05
Episode length: 572.00 +/- 28.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 713      |
| time/              |          |
|    total_timesteps | 4414272  |
---------------------------------
Eval num_timesteps=4416264, episode_reward=726.61 +/- 95.98
Episode length: 653.60 +/- 45.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 654      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 4416264  |
---------------------------------
Eval num_timesteps=4418256, episode_reward=783.75 +/- 326.07
Episode length: 633.20 +/- 81.25
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 784      |
| time/              |          |
|    total_timesteps | 4418256  |
---------------------------------
Eval num_timesteps=4420248, episode_reward=1000.26 +/- 430.71
Episode length: 613.00 +/- 51.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 1e+03    |
| time/              |          |
|    total_timesteps | 4420248  |
---------------------------------
Eval num_timesteps=4422240, episode_reward=669.12 +/- 75.08
Episode length: 679.00 +/- 78.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 679      |
|    mean_reward     | 669      |
| time/              |          |
|    total_timesteps | 4422240  |
---------------------------------
Eval num_timesteps=4424232, episode_reward=666.42 +/- 76.20
Episode length: 590.00 +/- 59.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 590         |
|    mean_reward          | 666         |
| time/                   |             |
|    total_timesteps      | 4424232     |
| train/                  |             |
|    approx_kl            | 0.005700338 |
|    clip_fraction        | 0.0354      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0173     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00123    |
|    std                  | 1.52        |
|    value_loss           | 0.129       |
-----------------------------------------
Eval num_timesteps=4426224, episode_reward=942.33 +/- 431.10
Episode length: 660.20 +/- 110.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 660      |
|    mean_reward     | 942      |
| time/              |          |
|    total_timesteps | 4426224  |
---------------------------------
Eval num_timesteps=4428216, episode_reward=659.35 +/- 93.41
Episode length: 699.60 +/- 41.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 4428216  |
---------------------------------
Eval num_timesteps=4430208, episode_reward=710.03 +/- 128.07
Episode length: 611.60 +/- 82.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 612      |
|    mean_reward     | 710      |
| time/              |          |
|    total_timesteps | 4430208  |
---------------------------------
Eval num_timesteps=4432200, episode_reward=972.94 +/- 553.06
Episode length: 632.60 +/- 137.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 973      |
| time/              |          |
|    total_timesteps | 4432200  |
---------------------------------
Eval num_timesteps=4434192, episode_reward=1084.20 +/- 520.06
Episode length: 630.80 +/- 133.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 4434192  |
---------------------------------
Eval num_timesteps=4436184, episode_reward=686.14 +/- 115.63
Episode length: 682.60 +/- 131.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 683      |
|    mean_reward     | 686      |
| time/              |          |
|    total_timesteps | 4436184  |
---------------------------------
Eval num_timesteps=4438176, episode_reward=651.30 +/- 35.91
Episode length: 657.40 +/- 74.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 657      |
|    mean_reward     | 651      |
| time/              |          |
|    total_timesteps | 4438176  |
---------------------------------
Eval num_timesteps=4440168, episode_reward=704.98 +/- 100.41
Episode length: 663.60 +/- 98.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 664      |
|    mean_reward     | 705      |
| time/              |          |
|    total_timesteps | 4440168  |
---------------------------------
Eval num_timesteps=4442160, episode_reward=1007.15 +/- 456.46
Episode length: 633.00 +/- 35.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4442160  |
---------------------------------
Eval num_timesteps=4444152, episode_reward=685.75 +/- 120.05
Episode length: 627.20 +/- 69.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 686      |
| time/              |          |
|    total_timesteps | 4444152  |
---------------------------------
Eval num_timesteps=4446144, episode_reward=721.27 +/- 131.34
Episode length: 681.80 +/- 116.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 682      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 4446144  |
---------------------------------
Eval num_timesteps=4448136, episode_reward=643.17 +/- 60.72
Episode length: 730.40 +/- 65.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 730      |
|    mean_reward     | 643      |
| time/              |          |
|    total_timesteps | 4448136  |
---------------------------------
Eval num_timesteps=4450128, episode_reward=623.97 +/- 43.43
Episode length: 657.00 +/- 53.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 657      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 4450128  |
---------------------------------
Eval num_timesteps=4452120, episode_reward=800.01 +/- 254.68
Episode length: 720.40 +/- 138.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 720      |
|    mean_reward     | 800      |
| time/              |          |
|    total_timesteps | 4452120  |
---------------------------------
Eval num_timesteps=4454112, episode_reward=740.78 +/- 129.30
Episode length: 649.00 +/- 149.35
---------------------------------
| eval/              |          |
|    mean_ep_length  | 649      |
|    mean_reward     | 741      |
| time/              |          |
|    total_timesteps | 4454112  |
---------------------------------
Eval num_timesteps=4456104, episode_reward=697.52 +/- 24.48
Episode length: 656.20 +/- 87.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 656      |
|    mean_reward     | 698      |
| time/              |          |
|    total_timesteps | 4456104  |
---------------------------------
Eval num_timesteps=4458096, episode_reward=673.70 +/- 63.61
Episode length: 639.40 +/- 135.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 4458096  |
---------------------------------
Eval num_timesteps=4460088, episode_reward=677.62 +/- 64.90
Episode length: 659.40 +/- 211.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 659      |
|    mean_reward     | 678      |
| time/              |          |
|    total_timesteps | 4460088  |
---------------------------------
Eval num_timesteps=4462080, episode_reward=824.30 +/- 201.07
Episode length: 588.20 +/- 37.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 824      |
| time/              |          |
|    total_timesteps | 4462080  |
---------------------------------
Eval num_timesteps=4464072, episode_reward=977.43 +/- 526.90
Episode length: 561.20 +/- 54.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 977      |
| time/              |          |
|    total_timesteps | 4464072  |
---------------------------------
Eval num_timesteps=4466064, episode_reward=845.75 +/- 188.65
Episode length: 667.40 +/- 96.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 667      |
|    mean_reward     | 846      |
| time/              |          |
|    total_timesteps | 4466064  |
---------------------------------
Eval num_timesteps=4468056, episode_reward=656.04 +/- 111.03
Episode length: 609.60 +/- 63.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 656      |
| time/              |          |
|    total_timesteps | 4468056  |
---------------------------------
Eval num_timesteps=4470048, episode_reward=728.96 +/- 72.47
Episode length: 800.60 +/- 139.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 801      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 4470048  |
---------------------------------
Eval num_timesteps=4472040, episode_reward=875.67 +/- 178.68
Episode length: 572.20 +/- 38.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 572      |
|    mean_reward     | 876      |
| time/              |          |
|    total_timesteps | 4472040  |
---------------------------------
Eval num_timesteps=4474032, episode_reward=813.43 +/- 365.96
Episode length: 631.00 +/- 181.95
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 631        |
|    mean_reward          | 813        |
| time/                   |            |
|    total_timesteps      | 4474032    |
| train/                  |            |
|    approx_kl            | 0.00616771 |
|    clip_fraction        | 0.0356     |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0181    |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.00148   |
|    std                  | 1.52       |
|    value_loss           | 0.123      |
----------------------------------------
Eval num_timesteps=4476024, episode_reward=937.89 +/- 109.24
Episode length: 713.40 +/- 190.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 713      |
|    mean_reward     | 938      |
| time/              |          |
|    total_timesteps | 4476024  |
---------------------------------
Eval num_timesteps=4478016, episode_reward=1252.95 +/- 826.18
Episode length: 780.60 +/- 157.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 781      |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 4478016  |
---------------------------------
Eval num_timesteps=4480008, episode_reward=611.77 +/- 58.50
Episode length: 615.00 +/- 50.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 612      |
| time/              |          |
|    total_timesteps | 4480008  |
---------------------------------
Eval num_timesteps=4482000, episode_reward=872.04 +/- 291.94
Episode length: 685.00 +/- 166.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 685      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 4482000  |
---------------------------------
Eval num_timesteps=4483992, episode_reward=901.40 +/- 397.94
Episode length: 567.80 +/- 88.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 901      |
| time/              |          |
|    total_timesteps | 4483992  |
---------------------------------
Eval num_timesteps=4485984, episode_reward=1027.59 +/- 395.62
Episode length: 587.40 +/- 38.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 587      |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 4485984  |
---------------------------------
Eval num_timesteps=4487976, episode_reward=852.73 +/- 308.99
Episode length: 644.60 +/- 101.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 645      |
|    mean_reward     | 853      |
| time/              |          |
|    total_timesteps | 4487976  |
---------------------------------
Eval num_timesteps=4489968, episode_reward=755.75 +/- 148.54
Episode length: 624.60 +/- 94.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 756      |
| time/              |          |
|    total_timesteps | 4489968  |
---------------------------------
Eval num_timesteps=4491960, episode_reward=966.15 +/- 281.10
Episode length: 553.60 +/- 88.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 966      |
| time/              |          |
|    total_timesteps | 4491960  |
---------------------------------
Eval num_timesteps=4493952, episode_reward=616.16 +/- 57.95
Episode length: 752.40 +/- 95.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 752      |
|    mean_reward     | 616      |
| time/              |          |
|    total_timesteps | 4493952  |
---------------------------------
Eval num_timesteps=4495944, episode_reward=1196.34 +/- 590.79
Episode length: 755.20 +/- 215.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 755      |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 4495944  |
---------------------------------
Eval num_timesteps=4497936, episode_reward=984.61 +/- 380.72
Episode length: 566.20 +/- 80.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 985      |
| time/              |          |
|    total_timesteps | 4497936  |
---------------------------------
Eval num_timesteps=4499928, episode_reward=1064.58 +/- 522.20
Episode length: 580.60 +/- 75.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 4499928  |
---------------------------------
Eval num_timesteps=4501920, episode_reward=665.35 +/- 99.33
Episode length: 516.00 +/- 74.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 665      |
| time/              |          |
|    total_timesteps | 4501920  |
---------------------------------
Eval num_timesteps=4503912, episode_reward=952.21 +/- 378.58
Episode length: 605.40 +/- 90.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 605      |
|    mean_reward     | 952      |
| time/              |          |
|    total_timesteps | 4503912  |
---------------------------------
Eval num_timesteps=4505904, episode_reward=642.70 +/- 64.75
Episode length: 661.80 +/- 99.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 643      |
| time/              |          |
|    total_timesteps | 4505904  |
---------------------------------
Eval num_timesteps=4507896, episode_reward=752.39 +/- 272.19
Episode length: 566.00 +/- 53.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 752      |
| time/              |          |
|    total_timesteps | 4507896  |
---------------------------------
Eval num_timesteps=4509888, episode_reward=645.89 +/- 74.77
Episode length: 637.60 +/- 165.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 638      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 4509888  |
---------------------------------
Eval num_timesteps=4511880, episode_reward=1032.28 +/- 397.60
Episode length: 689.20 +/- 131.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 4511880  |
---------------------------------
Eval num_timesteps=4513872, episode_reward=809.57 +/- 390.64
Episode length: 561.00 +/- 41.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 810      |
| time/              |          |
|    total_timesteps | 4513872  |
---------------------------------
Eval num_timesteps=4515864, episode_reward=878.06 +/- 364.92
Episode length: 658.20 +/- 119.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 658      |
|    mean_reward     | 878      |
| time/              |          |
|    total_timesteps | 4515864  |
---------------------------------
Eval num_timesteps=4517856, episode_reward=681.14 +/- 147.06
Episode length: 573.20 +/- 74.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 681      |
| time/              |          |
|    total_timesteps | 4517856  |
---------------------------------
Eval num_timesteps=4519848, episode_reward=833.18 +/- 179.46
Episode length: 600.40 +/- 99.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 600      |
|    mean_reward     | 833      |
| time/              |          |
|    total_timesteps | 4519848  |
---------------------------------
Eval num_timesteps=4521840, episode_reward=1026.54 +/- 439.51
Episode length: 691.40 +/- 94.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 691      |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 4521840  |
---------------------------------
Eval num_timesteps=4523832, episode_reward=716.54 +/- 113.10
Episode length: 620.60 +/- 94.51
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 621          |
|    mean_reward          | 717          |
| time/                   |              |
|    total_timesteps      | 4523832      |
| train/                  |              |
|    approx_kl            | 0.0069491724 |
|    clip_fraction        | 0.049        |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.35        |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0256      |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.00116     |
|    std                  | 1.53         |
|    value_loss           | 0.106        |
------------------------------------------
Eval num_timesteps=4525824, episode_reward=738.75 +/- 133.91
Episode length: 583.40 +/- 47.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 4525824  |
---------------------------------
Eval num_timesteps=4527816, episode_reward=842.47 +/- 302.04
Episode length: 677.20 +/- 80.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 677      |
|    mean_reward     | 842      |
| time/              |          |
|    total_timesteps | 4527816  |
---------------------------------
Eval num_timesteps=4529808, episode_reward=774.67 +/- 119.41
Episode length: 703.40 +/- 174.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 703      |
|    mean_reward     | 775      |
| time/              |          |
|    total_timesteps | 4529808  |
---------------------------------
Eval num_timesteps=4531800, episode_reward=671.50 +/- 98.75
Episode length: 636.40 +/- 138.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 636      |
|    mean_reward     | 672      |
| time/              |          |
|    total_timesteps | 4531800  |
---------------------------------
Eval num_timesteps=4533792, episode_reward=672.18 +/- 80.92
Episode length: 720.80 +/- 98.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 721      |
|    mean_reward     | 672      |
| time/              |          |
|    total_timesteps | 4533792  |
---------------------------------
Eval num_timesteps=4535784, episode_reward=737.76 +/- 143.92
Episode length: 687.00 +/- 130.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 687      |
|    mean_reward     | 738      |
| time/              |          |
|    total_timesteps | 4535784  |
---------------------------------
Eval num_timesteps=4537776, episode_reward=902.81 +/- 617.59
Episode length: 798.80 +/- 71.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 799      |
|    mean_reward     | 903      |
| time/              |          |
|    total_timesteps | 4537776  |
---------------------------------
Eval num_timesteps=4539768, episode_reward=639.95 +/- 69.89
Episode length: 584.60 +/- 85.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 640      |
| time/              |          |
|    total_timesteps | 4539768  |
---------------------------------
Eval num_timesteps=4541760, episode_reward=1012.57 +/- 489.09
Episode length: 639.00 +/- 71.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4541760  |
---------------------------------
Eval num_timesteps=4543752, episode_reward=1263.24 +/- 529.78
Episode length: 618.40 +/- 54.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 618      |
|    mean_reward     | 1.26e+03 |
| time/              |          |
|    total_timesteps | 4543752  |
---------------------------------
Eval num_timesteps=4545744, episode_reward=1038.34 +/- 575.02
Episode length: 671.60 +/- 171.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 672      |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 4545744  |
---------------------------------
Eval num_timesteps=4547736, episode_reward=720.21 +/- 145.90
Episode length: 698.00 +/- 89.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 698      |
|    mean_reward     | 720      |
| time/              |          |
|    total_timesteps | 4547736  |
---------------------------------
Eval num_timesteps=4549728, episode_reward=653.66 +/- 58.99
Episode length: 710.20 +/- 81.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 710      |
|    mean_reward     | 654      |
| time/              |          |
|    total_timesteps | 4549728  |
---------------------------------
Eval num_timesteps=4551720, episode_reward=729.05 +/- 192.25
Episode length: 617.60 +/- 82.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 618      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 4551720  |
---------------------------------
Eval num_timesteps=4553712, episode_reward=1128.61 +/- 334.58
Episode length: 696.40 +/- 209.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 696      |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 4553712  |
---------------------------------
Eval num_timesteps=4555704, episode_reward=1100.19 +/- 416.78
Episode length: 583.20 +/- 124.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 4555704  |
---------------------------------
Eval num_timesteps=4557696, episode_reward=736.01 +/- 130.42
Episode length: 667.20 +/- 117.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 667      |
|    mean_reward     | 736      |
| time/              |          |
|    total_timesteps | 4557696  |
---------------------------------
Eval num_timesteps=4559688, episode_reward=1008.30 +/- 309.43
Episode length: 590.60 +/- 107.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4559688  |
---------------------------------
Eval num_timesteps=4561680, episode_reward=795.97 +/- 179.71
Episode length: 589.40 +/- 53.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 796      |
| time/              |          |
|    total_timesteps | 4561680  |
---------------------------------
Eval num_timesteps=4563672, episode_reward=1238.63 +/- 612.80
Episode length: 648.40 +/- 145.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 648      |
|    mean_reward     | 1.24e+03 |
| time/              |          |
|    total_timesteps | 4563672  |
---------------------------------
Eval num_timesteps=4565664, episode_reward=645.52 +/- 49.30
Episode length: 656.20 +/- 38.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 656      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 4565664  |
---------------------------------
Eval num_timesteps=4567656, episode_reward=737.97 +/- 69.89
Episode length: 584.60 +/- 83.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 585      |
|    mean_reward     | 738      |
| time/              |          |
|    total_timesteps | 4567656  |
---------------------------------
Eval num_timesteps=4569648, episode_reward=750.13 +/- 283.45
Episode length: 671.40 +/- 129.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | 750      |
| time/              |          |
|    total_timesteps | 4569648  |
---------------------------------
Eval num_timesteps=4571640, episode_reward=1356.85 +/- 580.24
Episode length: 733.80 +/- 133.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 734          |
|    mean_reward          | 1.36e+03     |
| time/                   |              |
|    total_timesteps      | 4571640      |
| train/                  |              |
|    approx_kl            | 0.0058275945 |
|    clip_fraction        | 0.0368       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.37        |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0181      |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.00136     |
|    std                  | 1.53         |
|    value_loss           | 0.125        |
------------------------------------------
Eval num_timesteps=4573632, episode_reward=621.38 +/- 54.36
Episode length: 562.80 +/- 86.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 563      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 4573632  |
---------------------------------
Eval num_timesteps=4575624, episode_reward=882.36 +/- 327.75
Episode length: 636.60 +/- 61.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | 882      |
| time/              |          |
|    total_timesteps | 4575624  |
---------------------------------
Eval num_timesteps=4577616, episode_reward=687.74 +/- 209.24
Episode length: 609.20 +/- 17.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 688      |
| time/              |          |
|    total_timesteps | 4577616  |
---------------------------------
Eval num_timesteps=4579608, episode_reward=667.54 +/- 72.92
Episode length: 728.00 +/- 137.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 728      |
|    mean_reward     | 668      |
| time/              |          |
|    total_timesteps | 4579608  |
---------------------------------
Eval num_timesteps=4581600, episode_reward=617.52 +/- 94.68
Episode length: 588.80 +/- 63.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 589      |
|    mean_reward     | 618      |
| time/              |          |
|    total_timesteps | 4581600  |
---------------------------------
Eval num_timesteps=4583592, episode_reward=850.31 +/- 241.32
Episode length: 699.40 +/- 137.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 699      |
|    mean_reward     | 850      |
| time/              |          |
|    total_timesteps | 4583592  |
---------------------------------
Eval num_timesteps=4585584, episode_reward=695.57 +/- 144.04
Episode length: 719.00 +/- 148.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 719      |
|    mean_reward     | 696      |
| time/              |          |
|    total_timesteps | 4585584  |
---------------------------------
Eval num_timesteps=4587576, episode_reward=753.70 +/- 142.25
Episode length: 680.00 +/- 146.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 680      |
|    mean_reward     | 754      |
| time/              |          |
|    total_timesteps | 4587576  |
---------------------------------
Eval num_timesteps=4589568, episode_reward=989.51 +/- 492.34
Episode length: 629.80 +/- 72.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 990      |
| time/              |          |
|    total_timesteps | 4589568  |
---------------------------------
Eval num_timesteps=4591560, episode_reward=887.14 +/- 418.87
Episode length: 633.20 +/- 149.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 887      |
| time/              |          |
|    total_timesteps | 4591560  |
---------------------------------
Eval num_timesteps=4593552, episode_reward=673.76 +/- 65.27
Episode length: 728.60 +/- 208.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 729      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 4593552  |
---------------------------------
Eval num_timesteps=4595544, episode_reward=880.30 +/- 535.06
Episode length: 591.20 +/- 88.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 880      |
| time/              |          |
|    total_timesteps | 4595544  |
---------------------------------
Eval num_timesteps=4597536, episode_reward=782.28 +/- 325.53
Episode length: 660.80 +/- 91.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 661      |
|    mean_reward     | 782      |
| time/              |          |
|    total_timesteps | 4597536  |
---------------------------------
Eval num_timesteps=4599528, episode_reward=666.36 +/- 77.02
Episode length: 715.00 +/- 60.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 715      |
|    mean_reward     | 666      |
| time/              |          |
|    total_timesteps | 4599528  |
---------------------------------
Eval num_timesteps=4601520, episode_reward=601.23 +/- 44.02
Episode length: 756.40 +/- 126.77
---------------------------------
| eval/              |          |
|    mean_ep_length  | 756      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 4601520  |
---------------------------------
Eval num_timesteps=4603512, episode_reward=720.54 +/- 103.79
Episode length: 627.20 +/- 171.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 627      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 4603512  |
---------------------------------
Eval num_timesteps=4605504, episode_reward=922.50 +/- 339.03
Episode length: 720.40 +/- 121.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 720      |
|    mean_reward     | 923      |
| time/              |          |
|    total_timesteps | 4605504  |
---------------------------------
Eval num_timesteps=4607496, episode_reward=894.90 +/- 506.92
Episode length: 661.40 +/- 80.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 661      |
|    mean_reward     | 895      |
| time/              |          |
|    total_timesteps | 4607496  |
---------------------------------
Eval num_timesteps=4609488, episode_reward=569.85 +/- 106.80
Episode length: 661.80 +/- 104.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 570      |
| time/              |          |
|    total_timesteps | 4609488  |
---------------------------------
Eval num_timesteps=4611480, episode_reward=619.91 +/- 40.91
Episode length: 624.80 +/- 57.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 625      |
|    mean_reward     | 620      |
| time/              |          |
|    total_timesteps | 4611480  |
---------------------------------
Eval num_timesteps=4613472, episode_reward=674.73 +/- 123.87
Episode length: 615.40 +/- 24.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 675      |
| time/              |          |
|    total_timesteps | 4613472  |
---------------------------------
Eval num_timesteps=4615464, episode_reward=634.80 +/- 37.71
Episode length: 662.80 +/- 124.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 663      |
|    mean_reward     | 635      |
| time/              |          |
|    total_timesteps | 4615464  |
---------------------------------
Eval num_timesteps=4617456, episode_reward=979.77 +/- 382.50
Episode length: 618.40 +/- 79.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 618      |
|    mean_reward     | 980      |
| time/              |          |
|    total_timesteps | 4617456  |
---------------------------------
Eval num_timesteps=4619448, episode_reward=682.29 +/- 125.10
Episode length: 603.00 +/- 130.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 603      |
|    mean_reward     | 682      |
| time/              |          |
|    total_timesteps | 4619448  |
---------------------------------
Eval num_timesteps=4621440, episode_reward=610.01 +/- 90.02
Episode length: 644.00 +/- 89.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 644         |
|    mean_reward          | 610         |
| time/                   |             |
|    total_timesteps      | 4621440     |
| train/                  |             |
|    approx_kl            | 0.004559938 |
|    clip_fraction        | 0.0363      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0349     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00125    |
|    std                  | 1.54        |
|    value_loss           | 0.0899      |
-----------------------------------------
Eval num_timesteps=4623432, episode_reward=663.06 +/- 34.22
Episode length: 710.80 +/- 147.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 711      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 4623432  |
---------------------------------
Eval num_timesteps=4625424, episode_reward=808.48 +/- 297.56
Episode length: 577.00 +/- 77.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | 808      |
| time/              |          |
|    total_timesteps | 4625424  |
---------------------------------
Eval num_timesteps=4627416, episode_reward=622.25 +/- 44.31
Episode length: 639.40 +/- 134.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 4627416  |
---------------------------------
Eval num_timesteps=4629408, episode_reward=869.57 +/- 361.47
Episode length: 696.80 +/- 116.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | 870      |
| time/              |          |
|    total_timesteps | 4629408  |
---------------------------------
Eval num_timesteps=4631400, episode_reward=662.52 +/- 111.68
Episode length: 615.80 +/- 64.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 616      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 4631400  |
---------------------------------
Eval num_timesteps=4633392, episode_reward=940.29 +/- 288.33
Episode length: 699.80 +/- 165.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 940      |
| time/              |          |
|    total_timesteps | 4633392  |
---------------------------------
Eval num_timesteps=4635384, episode_reward=960.53 +/- 358.25
Episode length: 614.00 +/- 93.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 961      |
| time/              |          |
|    total_timesteps | 4635384  |
---------------------------------
Eval num_timesteps=4637376, episode_reward=625.76 +/- 25.65
Episode length: 750.80 +/- 96.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 751      |
|    mean_reward     | 626      |
| time/              |          |
|    total_timesteps | 4637376  |
---------------------------------
Eval num_timesteps=4639368, episode_reward=812.85 +/- 369.72
Episode length: 676.40 +/- 96.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 676      |
|    mean_reward     | 813      |
| time/              |          |
|    total_timesteps | 4639368  |
---------------------------------
Eval num_timesteps=4641360, episode_reward=620.58 +/- 95.56
Episode length: 596.80 +/- 38.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 4641360  |
---------------------------------
Eval num_timesteps=4643352, episode_reward=684.95 +/- 70.30
Episode length: 619.80 +/- 95.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | 685      |
| time/              |          |
|    total_timesteps | 4643352  |
---------------------------------
Eval num_timesteps=4645344, episode_reward=608.81 +/- 55.92
Episode length: 593.00 +/- 111.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 593      |
|    mean_reward     | 609      |
| time/              |          |
|    total_timesteps | 4645344  |
---------------------------------
Eval num_timesteps=4647336, episode_reward=576.04 +/- 40.98
Episode length: 534.00 +/- 59.78
---------------------------------
| eval/              |          |
|    mean_ep_length  | 534      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 4647336  |
---------------------------------
Eval num_timesteps=4649328, episode_reward=618.76 +/- 41.62
Episode length: 635.20 +/- 107.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 619      |
| time/              |          |
|    total_timesteps | 4649328  |
---------------------------------
Eval num_timesteps=4651320, episode_reward=684.17 +/- 92.83
Episode length: 599.40 +/- 121.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 599      |
|    mean_reward     | 684      |
| time/              |          |
|    total_timesteps | 4651320  |
---------------------------------
Eval num_timesteps=4653312, episode_reward=655.50 +/- 67.11
Episode length: 595.20 +/- 92.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 656      |
| time/              |          |
|    total_timesteps | 4653312  |
---------------------------------
Eval num_timesteps=4655304, episode_reward=733.75 +/- 190.11
Episode length: 597.00 +/- 73.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 597      |
|    mean_reward     | 734      |
| time/              |          |
|    total_timesteps | 4655304  |
---------------------------------
Eval num_timesteps=4657296, episode_reward=702.65 +/- 156.20
Episode length: 620.00 +/- 89.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 620      |
|    mean_reward     | 703      |
| time/              |          |
|    total_timesteps | 4657296  |
---------------------------------
Eval num_timesteps=4659288, episode_reward=752.19 +/- 239.99
Episode length: 667.20 +/- 66.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 667      |
|    mean_reward     | 752      |
| time/              |          |
|    total_timesteps | 4659288  |
---------------------------------
Eval num_timesteps=4661280, episode_reward=600.84 +/- 78.29
Episode length: 698.60 +/- 125.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 699      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 4661280  |
---------------------------------
Eval num_timesteps=4663272, episode_reward=659.11 +/- 46.65
Episode length: 704.20 +/- 84.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 704      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 4663272  |
---------------------------------
Eval num_timesteps=4665264, episode_reward=762.53 +/- 119.37
Episode length: 646.60 +/- 162.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 647      |
|    mean_reward     | 763      |
| time/              |          |
|    total_timesteps | 4665264  |
---------------------------------
Eval num_timesteps=4667256, episode_reward=661.47 +/- 110.73
Episode length: 582.60 +/- 73.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 583      |
|    mean_reward     | 661      |
| time/              |          |
|    total_timesteps | 4667256  |
---------------------------------
Eval num_timesteps=4669248, episode_reward=779.98 +/- 237.87
Episode length: 623.40 +/- 59.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 780      |
| time/              |          |
|    total_timesteps | 4669248  |
---------------------------------
Eval num_timesteps=4671240, episode_reward=810.66 +/- 394.50
Episode length: 599.80 +/- 90.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 600         |
|    mean_reward          | 811         |
| time/                   |             |
|    total_timesteps      | 4671240     |
| train/                  |             |
|    approx_kl            | 0.004417305 |
|    clip_fraction        | 0.0338      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.39       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0346     |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00108    |
|    std                  | 1.54        |
|    value_loss           | 0.0913      |
-----------------------------------------
Eval num_timesteps=4673232, episode_reward=710.28 +/- 168.34
Episode length: 635.00 +/- 120.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 710      |
| time/              |          |
|    total_timesteps | 4673232  |
---------------------------------
Eval num_timesteps=4675224, episode_reward=721.33 +/- 229.66
Episode length: 602.40 +/- 114.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 4675224  |
---------------------------------
Eval num_timesteps=4677216, episode_reward=910.62 +/- 393.16
Episode length: 624.40 +/- 162.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 624      |
|    mean_reward     | 911      |
| time/              |          |
|    total_timesteps | 4677216  |
---------------------------------
Eval num_timesteps=4679208, episode_reward=647.51 +/- 70.17
Episode length: 527.20 +/- 56.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 527      |
|    mean_reward     | 648      |
| time/              |          |
|    total_timesteps | 4679208  |
---------------------------------
Eval num_timesteps=4681200, episode_reward=637.15 +/- 91.86
Episode length: 610.00 +/- 66.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 637      |
| time/              |          |
|    total_timesteps | 4681200  |
---------------------------------
Eval num_timesteps=4683192, episode_reward=683.60 +/- 204.74
Episode length: 604.40 +/- 63.07
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 684      |
| time/              |          |
|    total_timesteps | 4683192  |
---------------------------------
Eval num_timesteps=4685184, episode_reward=826.90 +/- 482.62
Episode length: 614.00 +/- 40.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 827      |
| time/              |          |
|    total_timesteps | 4685184  |
---------------------------------
Eval num_timesteps=4687176, episode_reward=661.96 +/- 92.35
Episode length: 553.20 +/- 33.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 662      |
| time/              |          |
|    total_timesteps | 4687176  |
---------------------------------
Eval num_timesteps=4689168, episode_reward=628.30 +/- 30.66
Episode length: 629.80 +/- 75.09
---------------------------------
| eval/              |          |
|    mean_ep_length  | 630      |
|    mean_reward     | 628      |
| time/              |          |
|    total_timesteps | 4689168  |
---------------------------------
Eval num_timesteps=4691160, episode_reward=598.16 +/- 41.39
Episode length: 614.40 +/- 88.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 598      |
| time/              |          |
|    total_timesteps | 4691160  |
---------------------------------
Eval num_timesteps=4693152, episode_reward=672.52 +/- 80.44
Episode length: 573.20 +/- 74.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 4693152  |
---------------------------------
Eval num_timesteps=4695144, episode_reward=590.08 +/- 85.81
Episode length: 546.80 +/- 51.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 590      |
| time/              |          |
|    total_timesteps | 4695144  |
---------------------------------
Eval num_timesteps=4697136, episode_reward=574.21 +/- 40.92
Episode length: 564.20 +/- 82.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 574      |
| time/              |          |
|    total_timesteps | 4697136  |
---------------------------------
Eval num_timesteps=4699128, episode_reward=890.67 +/- 593.14
Episode length: 578.20 +/- 54.37
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 891      |
| time/              |          |
|    total_timesteps | 4699128  |
---------------------------------
Eval num_timesteps=4701120, episode_reward=850.29 +/- 274.19
Episode length: 614.40 +/- 89.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 614      |
|    mean_reward     | 850      |
| time/              |          |
|    total_timesteps | 4701120  |
---------------------------------
Eval num_timesteps=4703112, episode_reward=639.33 +/- 122.23
Episode length: 569.60 +/- 57.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 639      |
| time/              |          |
|    total_timesteps | 4703112  |
---------------------------------
Eval num_timesteps=4705104, episode_reward=774.46 +/- 431.08
Episode length: 690.20 +/- 180.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 690      |
|    mean_reward     | 774      |
| time/              |          |
|    total_timesteps | 4705104  |
---------------------------------
Eval num_timesteps=4707096, episode_reward=703.46 +/- 227.17
Episode length: 634.00 +/- 88.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 634      |
|    mean_reward     | 703      |
| time/              |          |
|    total_timesteps | 4707096  |
---------------------------------
Eval num_timesteps=4709088, episode_reward=754.98 +/- 238.57
Episode length: 604.20 +/- 60.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 755      |
| time/              |          |
|    total_timesteps | 4709088  |
---------------------------------
Eval num_timesteps=4711080, episode_reward=571.35 +/- 27.44
Episode length: 591.80 +/- 71.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 592      |
|    mean_reward     | 571      |
| time/              |          |
|    total_timesteps | 4711080  |
---------------------------------
Eval num_timesteps=4713072, episode_reward=663.06 +/- 121.46
Episode length: 594.80 +/- 45.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 595      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 4713072  |
---------------------------------
Eval num_timesteps=4715064, episode_reward=570.68 +/- 56.92
Episode length: 651.20 +/- 69.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 651      |
|    mean_reward     | 571      |
| time/              |          |
|    total_timesteps | 4715064  |
---------------------------------
Eval num_timesteps=4717056, episode_reward=859.47 +/- 436.72
Episode length: 671.20 +/- 89.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | 859      |
| time/              |          |
|    total_timesteps | 4717056  |
---------------------------------
Eval num_timesteps=4719048, episode_reward=777.08 +/- 338.13
Episode length: 574.00 +/- 113.05
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 574          |
|    mean_reward          | 777          |
| time/                   |              |
|    total_timesteps      | 4719048      |
| train/                  |              |
|    approx_kl            | 0.0044022067 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.41        |
|    explained_variance   | 0.976        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0367      |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00109     |
|    std                  | 1.55         |
|    value_loss           | 0.085        |
------------------------------------------
Eval num_timesteps=4721040, episode_reward=674.29 +/- 61.94
Episode length: 485.80 +/- 31.31
---------------------------------
| eval/              |          |
|    mean_ep_length  | 486      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 4721040  |
---------------------------------
Eval num_timesteps=4723032, episode_reward=561.08 +/- 46.62
Episode length: 617.80 +/- 159.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 618      |
|    mean_reward     | 561      |
| time/              |          |
|    total_timesteps | 4723032  |
---------------------------------
Eval num_timesteps=4725024, episode_reward=884.15 +/- 348.19
Episode length: 648.40 +/- 127.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 648      |
|    mean_reward     | 884      |
| time/              |          |
|    total_timesteps | 4725024  |
---------------------------------
Eval num_timesteps=4727016, episode_reward=680.77 +/- 217.05
Episode length: 478.40 +/- 35.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 478      |
|    mean_reward     | 681      |
| time/              |          |
|    total_timesteps | 4727016  |
---------------------------------
Eval num_timesteps=4729008, episode_reward=724.36 +/- 164.19
Episode length: 543.60 +/- 62.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 724      |
| time/              |          |
|    total_timesteps | 4729008  |
---------------------------------
Eval num_timesteps=4731000, episode_reward=718.68 +/- 186.41
Episode length: 688.60 +/- 166.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | 719      |
| time/              |          |
|    total_timesteps | 4731000  |
---------------------------------
Eval num_timesteps=4732992, episode_reward=587.95 +/- 64.49
Episode length: 544.20 +/- 81.92
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 588      |
| time/              |          |
|    total_timesteps | 4732992  |
---------------------------------
Eval num_timesteps=4734984, episode_reward=734.46 +/- 46.11
Episode length: 522.40 +/- 82.52
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 734      |
| time/              |          |
|    total_timesteps | 4734984  |
---------------------------------
Eval num_timesteps=4736976, episode_reward=1163.36 +/- 574.66
Episode length: 576.40 +/- 53.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 576      |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 4736976  |
---------------------------------
Eval num_timesteps=4738968, episode_reward=652.71 +/- 54.87
Episode length: 569.60 +/- 52.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 570      |
|    mean_reward     | 653      |
| time/              |          |
|    total_timesteps | 4738968  |
---------------------------------
Eval num_timesteps=4740960, episode_reward=629.20 +/- 73.84
Episode length: 567.80 +/- 57.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 629      |
| time/              |          |
|    total_timesteps | 4740960  |
---------------------------------
Eval num_timesteps=4742952, episode_reward=983.46 +/- 495.27
Episode length: 549.60 +/- 51.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 983      |
| time/              |          |
|    total_timesteps | 4742952  |
---------------------------------
Eval num_timesteps=4744944, episode_reward=803.03 +/- 471.39
Episode length: 663.40 +/- 141.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 663      |
|    mean_reward     | 803      |
| time/              |          |
|    total_timesteps | 4744944  |
---------------------------------
Eval num_timesteps=4746936, episode_reward=699.38 +/- 53.54
Episode length: 746.40 +/- 309.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 746      |
|    mean_reward     | 699      |
| time/              |          |
|    total_timesteps | 4746936  |
---------------------------------
Eval num_timesteps=4748928, episode_reward=843.62 +/- 511.38
Episode length: 558.60 +/- 79.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 559      |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 4748928  |
---------------------------------
Eval num_timesteps=4750920, episode_reward=679.69 +/- 272.05
Episode length: 568.60 +/- 111.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 569      |
|    mean_reward     | 680      |
| time/              |          |
|    total_timesteps | 4750920  |
---------------------------------
Eval num_timesteps=4752912, episode_reward=884.15 +/- 344.22
Episode length: 701.80 +/- 229.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | 884      |
| time/              |          |
|    total_timesteps | 4752912  |
---------------------------------
Eval num_timesteps=4754904, episode_reward=900.99 +/- 535.76
Episode length: 578.40 +/- 28.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 901      |
| time/              |          |
|    total_timesteps | 4754904  |
---------------------------------
Eval num_timesteps=4756896, episode_reward=643.68 +/- 75.55
Episode length: 564.00 +/- 68.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 644      |
| time/              |          |
|    total_timesteps | 4756896  |
---------------------------------
Eval num_timesteps=4758888, episode_reward=732.28 +/- 205.69
Episode length: 519.40 +/- 43.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 519      |
|    mean_reward     | 732      |
| time/              |          |
|    total_timesteps | 4758888  |
---------------------------------
Eval num_timesteps=4760880, episode_reward=1009.57 +/- 569.11
Episode length: 532.00 +/- 33.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4760880  |
---------------------------------
Eval num_timesteps=4762872, episode_reward=574.67 +/- 49.69
Episode length: 513.60 +/- 81.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 575      |
| time/              |          |
|    total_timesteps | 4762872  |
---------------------------------
Eval num_timesteps=4764864, episode_reward=791.41 +/- 510.89
Episode length: 509.80 +/- 85.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 510      |
|    mean_reward     | 791      |
| time/              |          |
|    total_timesteps | 4764864  |
---------------------------------
Eval num_timesteps=4766856, episode_reward=851.25 +/- 301.76
Episode length: 507.00 +/- 51.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 851      |
| time/              |          |
|    total_timesteps | 4766856  |
---------------------------------
Eval num_timesteps=4768848, episode_reward=645.04 +/- 79.36
Episode length: 571.60 +/- 62.34
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 572          |
|    mean_reward          | 645          |
| time/                   |              |
|    total_timesteps      | 4768848      |
| train/                  |              |
|    approx_kl            | 0.0043586073 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.44        |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0359      |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.0012      |
|    std                  | 1.56         |
|    value_loss           | 0.0855       |
------------------------------------------
Eval num_timesteps=4770840, episode_reward=673.42 +/- 115.63
Episode length: 561.40 +/- 62.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 4770840  |
---------------------------------
Eval num_timesteps=4772832, episode_reward=808.89 +/- 121.58
Episode length: 526.20 +/- 36.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 809      |
| time/              |          |
|    total_timesteps | 4772832  |
---------------------------------
Eval num_timesteps=4774824, episode_reward=863.52 +/- 302.99
Episode length: 538.80 +/- 39.73
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | 864      |
| time/              |          |
|    total_timesteps | 4774824  |
---------------------------------
Eval num_timesteps=4776816, episode_reward=1006.37 +/- 568.08
Episode length: 557.20 +/- 86.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 557      |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 4776816  |
---------------------------------
Eval num_timesteps=4778808, episode_reward=609.54 +/- 41.01
Episode length: 581.20 +/- 26.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | 610      |
| time/              |          |
|    total_timesteps | 4778808  |
---------------------------------
Eval num_timesteps=4780800, episode_reward=568.90 +/- 35.77
Episode length: 564.40 +/- 33.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 4780800  |
---------------------------------
Eval num_timesteps=4782792, episode_reward=617.07 +/- 53.75
Episode length: 575.40 +/- 47.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 575      |
|    mean_reward     | 617      |
| time/              |          |
|    total_timesteps | 4782792  |
---------------------------------
Eval num_timesteps=4784784, episode_reward=845.17 +/- 371.06
Episode length: 707.60 +/- 253.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 708      |
|    mean_reward     | 845      |
| time/              |          |
|    total_timesteps | 4784784  |
---------------------------------
Eval num_timesteps=4786776, episode_reward=807.49 +/- 207.71
Episode length: 553.40 +/- 69.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 807      |
| time/              |          |
|    total_timesteps | 4786776  |
---------------------------------
Eval num_timesteps=4788768, episode_reward=584.24 +/- 54.22
Episode length: 596.20 +/- 114.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 596      |
|    mean_reward     | 584      |
| time/              |          |
|    total_timesteps | 4788768  |
---------------------------------
Eval num_timesteps=4790760, episode_reward=617.07 +/- 37.84
Episode length: 696.80 +/- 246.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | 617      |
| time/              |          |
|    total_timesteps | 4790760  |
---------------------------------
Eval num_timesteps=4792752, episode_reward=806.56 +/- 287.37
Episode length: 563.60 +/- 164.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 564      |
|    mean_reward     | 807      |
| time/              |          |
|    total_timesteps | 4792752  |
---------------------------------
Eval num_timesteps=4794744, episode_reward=824.46 +/- 147.52
Episode length: 505.20 +/- 63.74
---------------------------------
| eval/              |          |
|    mean_ep_length  | 505      |
|    mean_reward     | 824      |
| time/              |          |
|    total_timesteps | 4794744  |
---------------------------------
Eval num_timesteps=4796736, episode_reward=626.80 +/- 71.53
Episode length: 529.60 +/- 82.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 530      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 4796736  |
---------------------------------
Eval num_timesteps=4798728, episode_reward=691.21 +/- 144.26
Episode length: 549.40 +/- 119.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 691      |
| time/              |          |
|    total_timesteps | 4798728  |
---------------------------------
Eval num_timesteps=4800720, episode_reward=687.90 +/- 166.32
Episode length: 575.40 +/- 42.84
---------------------------------
| eval/              |          |
|    mean_ep_length  | 575      |
|    mean_reward     | 688      |
| time/              |          |
|    total_timesteps | 4800720  |
---------------------------------
Eval num_timesteps=4802712, episode_reward=634.14 +/- 98.02
Episode length: 553.00 +/- 57.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 553      |
|    mean_reward     | 634      |
| time/              |          |
|    total_timesteps | 4802712  |
---------------------------------
Eval num_timesteps=4804704, episode_reward=618.27 +/- 105.40
Episode length: 565.20 +/- 176.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 618      |
| time/              |          |
|    total_timesteps | 4804704  |
---------------------------------
Eval num_timesteps=4806696, episode_reward=819.56 +/- 310.00
Episode length: 549.80 +/- 62.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 550      |
|    mean_reward     | 820      |
| time/              |          |
|    total_timesteps | 4806696  |
---------------------------------
Eval num_timesteps=4808688, episode_reward=721.06 +/- 335.47
Episode length: 531.00 +/- 88.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 531      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 4808688  |
---------------------------------
Eval num_timesteps=4810680, episode_reward=884.63 +/- 532.09
Episode length: 699.60 +/- 234.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 885      |
| time/              |          |
|    total_timesteps | 4810680  |
---------------------------------
Eval num_timesteps=4812672, episode_reward=570.58 +/- 31.45
Episode length: 555.00 +/- 54.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 555      |
|    mean_reward     | 571      |
| time/              |          |
|    total_timesteps | 4812672  |
---------------------------------
Eval num_timesteps=4814664, episode_reward=603.08 +/- 62.60
Episode length: 559.80 +/- 82.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 560      |
|    mean_reward     | 603      |
| time/              |          |
|    total_timesteps | 4814664  |
---------------------------------
Eval num_timesteps=4816656, episode_reward=732.75 +/- 213.01
Episode length: 522.40 +/- 162.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 522      |
|    mean_reward     | 733      |
| time/              |          |
|    total_timesteps | 4816656  |
---------------------------------
Eval num_timesteps=4818648, episode_reward=871.52 +/- 499.92
Episode length: 556.60 +/- 74.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 557         |
|    mean_reward          | 872         |
| time/                   |             |
|    total_timesteps      | 4818648     |
| train/                  |             |
|    approx_kl            | 0.005697488 |
|    clip_fraction        | 0.0443      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0379     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.000228   |
|    std                  | 1.57        |
|    value_loss           | 0.0808      |
-----------------------------------------
Eval num_timesteps=4820640, episode_reward=664.66 +/- 75.84
Episode length: 513.80 +/- 53.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 514      |
|    mean_reward     | 665      |
| time/              |          |
|    total_timesteps | 4820640  |
---------------------------------
Eval num_timesteps=4822632, episode_reward=1017.16 +/- 478.72
Episode length: 610.00 +/- 131.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 4822632  |
---------------------------------
Eval num_timesteps=4824624, episode_reward=592.85 +/- 33.70
Episode length: 602.00 +/- 75.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 602      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 4824624  |
---------------------------------
Eval num_timesteps=4826616, episode_reward=1229.37 +/- 485.85
Episode length: 606.40 +/- 62.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 606      |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 4826616  |
---------------------------------
Eval num_timesteps=4828608, episode_reward=593.75 +/- 60.41
Episode length: 607.00 +/- 110.21
---------------------------------
| eval/              |          |
|    mean_ep_length  | 607      |
|    mean_reward     | 594      |
| time/              |          |
|    total_timesteps | 4828608  |
---------------------------------
Eval num_timesteps=4830600, episode_reward=646.25 +/- 56.79
Episode length: 565.80 +/- 18.83
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 4830600  |
---------------------------------
Eval num_timesteps=4832592, episode_reward=803.59 +/- 379.60
Episode length: 544.00 +/- 21.95
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 804      |
| time/              |          |
|    total_timesteps | 4832592  |
---------------------------------
Eval num_timesteps=4834584, episode_reward=570.77 +/- 144.64
Episode length: 614.80 +/- 123.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 571      |
| time/              |          |
|    total_timesteps | 4834584  |
---------------------------------
Eval num_timesteps=4836576, episode_reward=842.53 +/- 351.57
Episode length: 635.40 +/- 81.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 843      |
| time/              |          |
|    total_timesteps | 4836576  |
---------------------------------
Eval num_timesteps=4838568, episode_reward=934.35 +/- 419.05
Episode length: 640.80 +/- 117.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 641      |
|    mean_reward     | 934      |
| time/              |          |
|    total_timesteps | 4838568  |
---------------------------------
Eval num_timesteps=4840560, episode_reward=677.82 +/- 135.34
Episode length: 664.80 +/- 135.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 665      |
|    mean_reward     | 678      |
| time/              |          |
|    total_timesteps | 4840560  |
---------------------------------
Eval num_timesteps=4842552, episode_reward=867.93 +/- 291.40
Episode length: 613.40 +/- 183.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 613      |
|    mean_reward     | 868      |
| time/              |          |
|    total_timesteps | 4842552  |
---------------------------------
Eval num_timesteps=4844544, episode_reward=839.91 +/- 414.47
Episode length: 591.00 +/- 70.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 840      |
| time/              |          |
|    total_timesteps | 4844544  |
---------------------------------
Eval num_timesteps=4846536, episode_reward=659.32 +/- 93.27
Episode length: 642.60 +/- 91.89
---------------------------------
| eval/              |          |
|    mean_ep_length  | 643      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 4846536  |
---------------------------------
Eval num_timesteps=4848528, episode_reward=797.08 +/- 244.81
Episode length: 685.60 +/- 133.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 797      |
| time/              |          |
|    total_timesteps | 4848528  |
---------------------------------
Eval num_timesteps=4850520, episode_reward=729.93 +/- 119.72
Episode length: 636.20 +/- 170.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 636      |
|    mean_reward     | 730      |
| time/              |          |
|    total_timesteps | 4850520  |
---------------------------------
Eval num_timesteps=4852512, episode_reward=673.47 +/- 126.01
Episode length: 654.60 +/- 82.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 655      |
|    mean_reward     | 673      |
| time/              |          |
|    total_timesteps | 4852512  |
---------------------------------
Eval num_timesteps=4854504, episode_reward=684.54 +/- 94.18
Episode length: 529.40 +/- 30.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 529      |
|    mean_reward     | 685      |
| time/              |          |
|    total_timesteps | 4854504  |
---------------------------------
Eval num_timesteps=4856496, episode_reward=711.30 +/- 361.84
Episode length: 591.00 +/- 146.45
---------------------------------
| eval/              |          |
|    mean_ep_length  | 591      |
|    mean_reward     | 711      |
| time/              |          |
|    total_timesteps | 4856496  |
---------------------------------
Eval num_timesteps=4858488, episode_reward=867.32 +/- 376.98
Episode length: 611.00 +/- 174.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 611      |
|    mean_reward     | 867      |
| time/              |          |
|    total_timesteps | 4858488  |
---------------------------------
Eval num_timesteps=4860480, episode_reward=856.42 +/- 238.01
Episode length: 560.80 +/- 68.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 856      |
| time/              |          |
|    total_timesteps | 4860480  |
---------------------------------
Eval num_timesteps=4862472, episode_reward=619.48 +/- 119.38
Episode length: 510.60 +/- 74.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 511      |
|    mean_reward     | 619      |
| time/              |          |
|    total_timesteps | 4862472  |
---------------------------------
Eval num_timesteps=4864464, episode_reward=840.37 +/- 330.74
Episode length: 520.40 +/- 70.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 840      |
| time/              |          |
|    total_timesteps | 4864464  |
---------------------------------
Eval num_timesteps=4866456, episode_reward=681.09 +/- 189.85
Episode length: 646.80 +/- 92.12
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 647          |
|    mean_reward          | 681          |
| time/                   |              |
|    total_timesteps      | 4866456      |
| train/                  |              |
|    approx_kl            | 0.0046498915 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.48        |
|    explained_variance   | 0.979        |
|    learning_rate        | 0.001        |
|    loss                 | -0.0454      |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00114     |
|    std                  | 1.58         |
|    value_loss           | 0.0674       |
------------------------------------------
Eval num_timesteps=4868448, episode_reward=926.64 +/- 481.29
Episode length: 565.00 +/- 56.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 565      |
|    mean_reward     | 927      |
| time/              |          |
|    total_timesteps | 4868448  |
---------------------------------
Eval num_timesteps=4870440, episode_reward=698.31 +/- 184.79
Episode length: 578.40 +/- 27.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 698      |
| time/              |          |
|    total_timesteps | 4870440  |
---------------------------------
Eval num_timesteps=4872432, episode_reward=897.99 +/- 411.50
Episode length: 649.00 +/- 164.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 649      |
|    mean_reward     | 898      |
| time/              |          |
|    total_timesteps | 4872432  |
---------------------------------
Eval num_timesteps=4874424, episode_reward=786.91 +/- 226.36
Episode length: 539.40 +/- 39.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | 787      |
| time/              |          |
|    total_timesteps | 4874424  |
---------------------------------
Eval num_timesteps=4876416, episode_reward=724.74 +/- 345.17
Episode length: 528.40 +/- 78.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 528      |
|    mean_reward     | 725      |
| time/              |          |
|    total_timesteps | 4876416  |
---------------------------------
Eval num_timesteps=4878408, episode_reward=1253.33 +/- 527.31
Episode length: 610.20 +/- 74.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 610      |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 4878408  |
---------------------------------
Eval num_timesteps=4880400, episode_reward=701.86 +/- 129.88
Episode length: 549.20 +/- 45.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 549      |
|    mean_reward     | 702      |
| time/              |          |
|    total_timesteps | 4880400  |
---------------------------------
Eval num_timesteps=4882392, episode_reward=1085.69 +/- 651.26
Episode length: 744.20 +/- 159.64
---------------------------------
| eval/              |          |
|    mean_ep_length  | 744      |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 4882392  |
---------------------------------
Eval num_timesteps=4884384, episode_reward=903.43 +/- 337.13
Episode length: 557.60 +/- 67.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 558      |
|    mean_reward     | 903      |
| time/              |          |
|    total_timesteps | 4884384  |
---------------------------------
Eval num_timesteps=4886376, episode_reward=803.07 +/- 381.98
Episode length: 501.80 +/- 49.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 502      |
|    mean_reward     | 803      |
| time/              |          |
|    total_timesteps | 4886376  |
---------------------------------
Eval num_timesteps=4888368, episode_reward=653.44 +/- 112.76
Episode length: 640.80 +/- 117.13
---------------------------------
| eval/              |          |
|    mean_ep_length  | 641      |
|    mean_reward     | 653      |
| time/              |          |
|    total_timesteps | 4888368  |
---------------------------------
Eval num_timesteps=4890360, episode_reward=909.67 +/- 306.08
Episode length: 560.60 +/- 56.05
---------------------------------
| eval/              |          |
|    mean_ep_length  | 561      |
|    mean_reward     | 910      |
| time/              |          |
|    total_timesteps | 4890360  |
---------------------------------
Eval num_timesteps=4892352, episode_reward=912.55 +/- 512.94
Episode length: 625.80 +/- 131.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 626      |
|    mean_reward     | 913      |
| time/              |          |
|    total_timesteps | 4892352  |
---------------------------------
Eval num_timesteps=4894344, episode_reward=844.10 +/- 364.13
Episode length: 577.80 +/- 72.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 578      |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 4894344  |
---------------------------------
Eval num_timesteps=4896336, episode_reward=715.47 +/- 193.23
Episode length: 662.00 +/- 168.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 715      |
| time/              |          |
|    total_timesteps | 4896336  |
---------------------------------
Eval num_timesteps=4898328, episode_reward=951.40 +/- 392.01
Episode length: 695.40 +/- 178.38
---------------------------------
| eval/              |          |
|    mean_ep_length  | 695      |
|    mean_reward     | 951      |
| time/              |          |
|    total_timesteps | 4898328  |
---------------------------------
Eval num_timesteps=4900320, episode_reward=1149.65 +/- 597.37
Episode length: 687.20 +/- 207.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 687      |
|    mean_reward     | 1.15e+03 |
| time/              |          |
|    total_timesteps | 4900320  |
---------------------------------
Eval num_timesteps=4902312, episode_reward=805.71 +/- 250.83
Episode length: 603.60 +/- 181.76
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 806      |
| time/              |          |
|    total_timesteps | 4902312  |
---------------------------------
Eval num_timesteps=4904304, episode_reward=906.39 +/- 476.56
Episode length: 535.20 +/- 72.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 906      |
| time/              |          |
|    total_timesteps | 4904304  |
---------------------------------
Eval num_timesteps=4906296, episode_reward=754.83 +/- 391.09
Episode length: 682.60 +/- 224.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 683      |
|    mean_reward     | 755      |
| time/              |          |
|    total_timesteps | 4906296  |
---------------------------------
Eval num_timesteps=4908288, episode_reward=912.02 +/- 501.00
Episode length: 623.40 +/- 69.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 912      |
| time/              |          |
|    total_timesteps | 4908288  |
---------------------------------
Eval num_timesteps=4910280, episode_reward=915.75 +/- 301.51
Episode length: 628.60 +/- 126.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | 916      |
| time/              |          |
|    total_timesteps | 4910280  |
---------------------------------
Eval num_timesteps=4912272, episode_reward=634.66 +/- 53.33
Episode length: 695.00 +/- 168.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 695      |
|    mean_reward     | 635      |
| time/              |          |
|    total_timesteps | 4912272  |
---------------------------------
Eval num_timesteps=4914264, episode_reward=693.81 +/- 242.73
Episode length: 556.00 +/- 107.63
---------------------------------
| eval/              |          |
|    mean_ep_length  | 556      |
|    mean_reward     | 694      |
| time/              |          |
|    total_timesteps | 4914264  |
---------------------------------
Eval num_timesteps=4916256, episode_reward=952.33 +/- 308.13
Episode length: 589.60 +/- 186.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 590         |
|    mean_reward          | 952         |
| time/                   |             |
|    total_timesteps      | 4916256     |
| train/                  |             |
|    approx_kl            | 0.004272919 |
|    clip_fraction        | 0.0441      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.001       |
|    loss                 | -0.0371     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.00136    |
|    std                  | 1.59        |
|    value_loss           | 0.0867      |
-----------------------------------------
Eval num_timesteps=4918248, episode_reward=626.17 +/- 242.63
Episode length: 495.40 +/- 61.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | 626      |
| time/              |          |
|    total_timesteps | 4918248  |
---------------------------------
Eval num_timesteps=4920240, episode_reward=689.00 +/- 63.09
Episode length: 615.40 +/- 85.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 689      |
| time/              |          |
|    total_timesteps | 4920240  |
---------------------------------
Eval num_timesteps=4922232, episode_reward=829.38 +/- 424.76
Episode length: 577.40 +/- 37.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | 829      |
| time/              |          |
|    total_timesteps | 4922232  |
---------------------------------
Eval num_timesteps=4924224, episode_reward=675.69 +/- 212.86
Episode length: 540.40 +/- 77.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 540      |
|    mean_reward     | 676      |
| time/              |          |
|    total_timesteps | 4924224  |
---------------------------------
Eval num_timesteps=4926216, episode_reward=717.92 +/- 190.96
Episode length: 518.20 +/- 57.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 518      |
|    mean_reward     | 718      |
| time/              |          |
|    total_timesteps | 4926216  |
---------------------------------
Eval num_timesteps=4928208, episode_reward=977.19 +/- 395.40
Episode length: 599.20 +/- 143.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 599      |
|    mean_reward     | 977      |
| time/              |          |
|    total_timesteps | 4928208  |
---------------------------------
Eval num_timesteps=4930200, episode_reward=575.63 +/- 26.62
Episode length: 532.00 +/- 41.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 532      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 4930200  |
---------------------------------
Eval num_timesteps=4932192, episode_reward=676.59 +/- 150.16
Episode length: 512.40 +/- 84.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 512      |
|    mean_reward     | 677      |
| time/              |          |
|    total_timesteps | 4932192  |
---------------------------------
Eval num_timesteps=4934184, episode_reward=1181.45 +/- 532.95
Episode length: 606.60 +/- 110.67
---------------------------------
| eval/              |          |
|    mean_ep_length  | 607      |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 4934184  |
---------------------------------
Eval num_timesteps=4936176, episode_reward=732.49 +/- 233.17
Episode length: 565.80 +/- 44.06
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 732      |
| time/              |          |
|    total_timesteps | 4936176  |
---------------------------------
Eval num_timesteps=4938168, episode_reward=715.46 +/- 80.86
Episode length: 650.00 +/- 123.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 650      |
|    mean_reward     | 715      |
| time/              |          |
|    total_timesteps | 4938168  |
